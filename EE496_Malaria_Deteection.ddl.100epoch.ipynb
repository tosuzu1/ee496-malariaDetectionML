{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVi1d71PgYYW"
   },
   "source": [
    "This is the KERAS CNN implementation for the MALARIA CELL IMAGES DATASET\n",
    "\n",
    "Breakdown of this notebook:\n",
    "\n",
    "Loading the dataset: Load the data and import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QtfOemEYgPwh",
    "outputId": "83392fec-23c6-47a5-c14c-516368524e62"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# For CNN model creation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold , cross_val_score\n",
    "SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRgyHuQhk893"
   },
   "outputs": [],
   "source": [
    "infected = os.listdir('.\\\\cell_images\\\\cell_images\\\\Parasitized') \n",
    "uninfected = os.listdir('.\\\\cell_images\\\\cell_images\\\\Uninfected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "X-t95fumlkiG",
    "outputId": "f9ea2b8a-eee2-4ca5-dce1-83668f36eb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in infected:\n",
    "    try:\n",
    "    \n",
    "        image = cv2.imread(\".\\\\cell_images\\\\cell_images\\\\Parasitized\\\\\"+i)\n",
    "        image_array = Image.fromarray(image , 'RGB')\n",
    "        resize_img = image_array.resize((64 , 64))\n",
    "        data.append(np.array(resize_img))\n",
    "        label = to_categorical(1, num_classes=2)\n",
    "        labels.append(label)\n",
    "        \n",
    "    except AttributeError:\n",
    "        print('')\n",
    "    \n",
    "for u in uninfected:\n",
    "    try:\n",
    "        \n",
    "        image = cv2.imread(\".\\\\cell_images\\\\cell_images\\\\Uninfected\\\\\"+u)\n",
    "        image_array = Image.fromarray(image , 'RGB')\n",
    "        resize_img = image_array.resize((64 , 64))\n",
    "        data.append(np.array(resize_img))\n",
    "        label = to_categorical(0, num_classes=2)\n",
    "        labels.append(label)\n",
    "        \n",
    "    except AttributeError:\n",
    "        print('')\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "WSB6IS52HFcg",
    "outputId": "671fa62b-31f5-48cf-d1ca-4246d13b8b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BXEHl8GQhXDJ",
    "outputId": "0f1f5312-4c06-42a6-baf9-5b52d9c6bf79"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(data, test_size=0.2, random_state=1,shuffle = True)\n",
    "y_train, y_test = train_test_split(labels, test_size=0.2, random_state=1)\n",
    "\n",
    "x_train_ddl, x_validate_ddl = train_test_split(x_train, test_size=0.2, random_state=2,shuffle = True)\n",
    "y_train_ddl, y_validate_ddl = train_test_split(y_train, test_size=0.2, random_state=2)\n",
    "epoch_list = []\n",
    "for i in range(100):\n",
    "    epoch_list.append(i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n-oXJVMrhrea",
    "outputId": "a8e7d519-f81d-4822-a800-ad9af1198f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.3023 - accuracy: 0.8733\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.1665 - accuracy: 0.9375\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1301 - accuracy: 0.9533\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1006 - accuracy: 0.9640\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.0824 - accuracy: 0.9703\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.0592 - accuracy: 0.9787\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.0418 - accuracy: 0.9851\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.0253 - accuracy: 0.9915\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.0281 - accuracy: 0.9901\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.0218 - accuracy: 0.9921\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.0111 - accuracy: 0.9960\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.0150 - accuracy: 0.9949\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0101 - accuracy: 0.9963\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0091 - accuracy: 0.9973\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0119 - accuracy: 0.9959\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0069 - accuracy: 0.9975\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0176 - accuracy: 0.9942\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0155 - accuracy: 0.9944\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 3.5577e-04 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 9.6003e-05 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 6.3237e-05 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 4.7659e-05 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 3.7134e-05 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 2.9500e-05 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 2.3715e-05 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 1.9226e-05 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 1.5683e-05 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 1.2854e-05 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 1.0572e-05 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 8.7138e-06 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 7.1924e-06 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 5.9458e-06 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 4.9182e-06 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 4.0727e-06 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 3.3746e-06 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 2.7981e-06 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 2.3222e-06 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 1.9265e-06 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 1.5989e-06 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 1.3269e-06 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 1.1018e-06 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 9.1547e-07 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 7.6113e-07 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 6.3295e-07 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 5.2673e-07 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 4.3879e-07 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 3.6581e-07 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 3.0521e-07 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 2.5498e-07 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 2.1316e-07 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 1.7839e-07 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 1.4946e-07 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 1.2542e-07 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 1.0539e-07 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 8.8745e-08 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 7.4818e-08 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 6.3185e-08 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 5.3450e-08 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 4.5322e-08 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 3.8527e-08 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 3.2812e-08 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 2.8023e-08 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 2.3977e-08 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 2.0570e-08 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 1.7693e-08 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 1.5265e-08 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 1.3218e-08 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 1.1483e-08 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 1.0008e-08 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 8.7653e-09 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 7.7098e-09 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 6.8025e-09 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 6.0326e-09 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 5.3794e-09 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 4.8234e-09 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 4.3482e-09 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 3.9425e-09 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 3.5944e-09 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 3.2957e-09 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 3.0341e-09 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 2.8079e-09 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 2.6104e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 2.4366e-09 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 2.2837e-09 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 2.1509e-09 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 2.0329e-09 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 1.9278e-09 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 1.8336e-09 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 1.7488e-09 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 1.6735e-09 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 1.6046e-09 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 1.5412e-09 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 1.4847e-09 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 1.4323e-09 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 1.3846e-09 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 1.3402e-09 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 1.2994e-09 - accuracy: 1.0000\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 4s - loss: 0.2112 - accuracy: 0.9357\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1048 - accuracy: 0.9642\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.0695 - accuracy: 0.9768\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.0571 - accuracy: 0.9793\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.0412 - accuracy: 0.9855\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.0265 - accuracy: 0.9905\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.0242 - accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.0336 - accuracy: 0.9882\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0235 - accuracy: 0.9911\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0704 - accuracy: 0.9749\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 4s - loss: 0.0187 - accuracy: 0.9936\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0039 - accuracy: 0.9992\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 9.2596e-04 - accuracy: 0.9999\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 3.2074e-04 - accuracy: 1.0000\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 1.7167e-04 - accuracy: 1.0000\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 9.8918e-05 - accuracy: 1.0000\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 6.2271e-05 - accuracy: 1.0000\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 4.0156e-05 - accuracy: 1.0000\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 2.7632e-05 - accuracy: 1.0000\n",
      "Epoch 10/90\n",
      "17636/17636 - 2s - loss: 1.9752e-05 - accuracy: 1.0000\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 1.4561e-05 - accuracy: 1.0000\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 1.0908e-05 - accuracy: 1.0000\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 8.3839e-06 - accuracy: 1.0000\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 6.5421e-06 - accuracy: 1.0000\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 5.1407e-06 - accuracy: 1.0000\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 4.0998e-06 - accuracy: 1.0000\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 3.3048e-06 - accuracy: 1.0000\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 2.6922e-06 - accuracy: 1.0000\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 2.2134e-06 - accuracy: 1.0000\n",
      "Epoch 20/90\n",
      "17636/17636 - 2s - loss: 1.8266e-06 - accuracy: 1.0000\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 1.4852e-06 - accuracy: 1.0000\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 1.2378e-06 - accuracy: 1.0000\n",
      "Epoch 23/90\n",
      "17636/17636 - 2s - loss: 1.0360e-06 - accuracy: 1.0000\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 8.7115e-07 - accuracy: 1.0000\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 7.3499e-07 - accuracy: 1.0000\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 6.2459e-07 - accuracy: 1.0000\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 5.3139e-07 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 4.5453e-07 - accuracy: 1.0000\n",
      "Epoch 29/90\n",
      "17636/17636 - 2s - loss: 3.8731e-07 - accuracy: 1.0000\n",
      "Epoch 30/90\n",
      "17636/17636 - 2s - loss: 3.3268e-07 - accuracy: 1.0000\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 2.8599e-07 - accuracy: 1.0000\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 2.4682e-07 - accuracy: 1.0000\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 2.1131e-07 - accuracy: 1.0000\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 1.8274e-07 - accuracy: 1.0000\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 1.5839e-07 - accuracy: 1.0000\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 1.3776e-07 - accuracy: 1.0000\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 1.2002e-07 - accuracy: 1.0000\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 1.0473e-07 - accuracy: 1.0000\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 9.1000e-08 - accuracy: 1.0000\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 7.9247e-08 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 6.9452e-08 - accuracy: 1.0000\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 6.1065e-08 - accuracy: 1.0000\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 5.3744e-08 - accuracy: 1.0000\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 4.7389e-08 - accuracy: 1.0000\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 4.2057e-08 - accuracy: 1.0000\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 3.6970e-08 - accuracy: 1.0000\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 3.2781e-08 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 2.8819e-08 - accuracy: 1.0000\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 2.5686e-08 - accuracy: 1.0000\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 2.2905e-08 - accuracy: 1.0000\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 2.0479e-08 - accuracy: 1.0000\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 1.8371e-08 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 1.6502e-08 - accuracy: 1.0000\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 1.4847e-08 - accuracy: 1.0000\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 1.3401e-08 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 1.2135e-08 - accuracy: 1.0000\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 1.0982e-08 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "17636/17636 - 2s - loss: 9.9893e-09 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "17636/17636 - 2s - loss: 9.0989e-09 - accuracy: 1.0000\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 8.2995e-09 - accuracy: 1.0000\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 7.6004e-09 - accuracy: 1.0000\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 6.9784e-09 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 6.4136e-09 - accuracy: 1.0000\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 5.9152e-09 - accuracy: 1.0000\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 5.4711e-09 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 5.0803e-09 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 4.7283e-09 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 4.4100e-09 - accuracy: 1.0000\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 4.1239e-09 - accuracy: 1.0000\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 3.8661e-09 - accuracy: 1.0000\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 3.6327e-09 - accuracy: 1.0000\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 3.4204e-09 - accuracy: 1.0000\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 3.2253e-09 - accuracy: 1.0000\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 3.0490e-09 - accuracy: 1.0000\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 2.8897e-09 - accuracy: 1.0000\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 2.7430e-09 - accuracy: 1.0000\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 2.6097e-09 - accuracy: 1.0000\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 2.4888e-09 - accuracy: 1.0000\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 2.3772e-09 - accuracy: 1.0000\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 2.2769e-09 - accuracy: 1.0000\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 2.1837e-09 - accuracy: 1.0000\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 2.0970e-09 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 2.0210e-09 - accuracy: 1.0000\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 1.9480e-09 - accuracy: 1.0000\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 1.8802e-09 - accuracy: 1.0000\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 1.8150e-09 - accuracy: 1.0000\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 1.7557e-09 - accuracy: 1.0000\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 1.7008e-09 - accuracy: 1.0000\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 1.6507e-09 - accuracy: 1.0000\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 1.6040e-09 - accuracy: 1.0000\n",
      "5512/5512 [==============================] - 1s 117us/sample - loss: 0.8120 - accuracy: 0.9508\n",
      "Test_Accuracy: 95.08%\n",
      "5512/5512 [==============================] - 1s 94us/sample - loss: 0.8120 - accuracy: 0.9508\n",
      "4410/4410 [==============================] - 0s 93us/sample - loss: 0.6540 - accuracy: 0.9519\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22046/22046 - 5s - loss: 0.3208 - accuracy: 0.8639\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.1862 - accuracy: 0.9306\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1483 - accuracy: 0.9458\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1212 - accuracy: 0.9561\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.0921 - accuracy: 0.9658\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.0695 - accuracy: 0.9753\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.0514 - accuracy: 0.9822\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.0462 - accuracy: 0.9829\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.0318 - accuracy: 0.9892\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.0282 - accuracy: 0.9899\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.0211 - accuracy: 0.9927\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.0159 - accuracy: 0.9943\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.0154 - accuracy: 0.9943\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0166 - accuracy: 0.9934\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0156 - accuracy: 0.9946\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0166 - accuracy: 0.9943\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0142 - accuracy: 0.9947\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0195 - accuracy: 0.9938\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0170 - accuracy: 0.9939\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 7.9707e-04 - accuracy: 0.9998\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 2.3130e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 5.2976e-04 - accuracy: 0.9999\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0097 - accuracy: 0.9966\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 5.8271e-04 - accuracy: 0.9999\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 8.0339e-04 - accuracy: 0.9998\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 7.7924e-04 - accuracy: 0.9999\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 7.7722e-04 - accuracy: 0.9998\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 3.6055e-04 - accuracy: 0.9999\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 1.1811e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 9.1875e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 1.0913e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0103 - accuracy: 0.9965\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 7.8451e-04 - accuracy: 0.9997\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 2.5479e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 2.3750e-04 - accuracy: 0.9999\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 7.7996e-04 - accuracy: 0.9998\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9992\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 8.3540e-04 - accuracy: 0.9998\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 2.8444e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 7.7984e-04 - accuracy: 0.9998\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 9.9811e-04 - accuracy: 0.9998\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 4.2075e-04 - accuracy: 0.9999\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 6.3989e-04 - accuracy: 0.9998\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 7.9069e-04 - accuracy: 0.9999\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 9.0112e-04 - accuracy: 0.9997\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 8.1483e-04 - accuracy: 0.9998\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1206 - accuracy: 0.9622\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.0537 - accuracy: 0.9815\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.0575 - accuracy: 0.9804\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.0661 - accuracy: 0.9774\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.1702 - accuracy: 0.9370\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.0748 - accuracy: 0.9744\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.0685 - accuracy: 0.9757\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.0698 - accuracy: 0.9756\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0404 - accuracy: 0.9864\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0238 - accuracy: 0.9914\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 7.9598e-04 - accuracy: 0.9999\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 5.9010e-04 - accuracy: 0.9998\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 2.3840e-04 - accuracy: 1.0000\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 5.5956e-04 - accuracy: 0.9997\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 3.5127e-04 - accuracy: 0.9999\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 2.2781e-04 - accuracy: 1.0000\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 5.7595e-04 - accuracy: 0.9998\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 2.4189e-04 - accuracy: 0.9999\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 5.7870e-04 - accuracy: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 4.1172e-04 - accuracy: 0.9997\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 3.4971e-04 - accuracy: 0.9999\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 3.2760e-04 - accuracy: 0.9999\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 4.1333e-04 - accuracy: 0.9998\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 1.1059e-04 - accuracy: 0.9999\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 3.8582e-05 - accuracy: 1.0000\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 1.4886e-04 - accuracy: 0.9999\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 6.8394e-05 - accuracy: 1.0000\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 1.6235e-04 - accuracy: 0.9999\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 1.5283e-04 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 5.3671e-05 - accuracy: 1.0000\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 6.0568e-04 - accuracy: 0.9998\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 1.1685e-04 - accuracy: 0.9999\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 1.2247e-04 - accuracy: 0.9999\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 4.4226e-04 - accuracy: 0.9999\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 7.2733e-04 - accuracy: 0.9998\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 1.9128e-04 - accuracy: 0.9999\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 1.2891e-04 - accuracy: 0.9999\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 2.5630e-04 - accuracy: 0.9999\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 3.3708e-04 - accuracy: 0.9999\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 1.6864e-05 - accuracy: 1.0000\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 6.9491e-05 - accuracy: 1.0000\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 5.4704e-05 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 2.5173e-05 - accuracy: 1.0000\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 4.2175e-05 - accuracy: 1.0000\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 8.5374e-04 - accuracy: 0.9997\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 5.1635e-04 - accuracy: 0.9999\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 5.2358e-04 - accuracy: 0.9998\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 4.5244e-04 - accuracy: 0.9998\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 3.5436e-05 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 4.6113e-05 - accuracy: 1.0000\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 1.3378e-05 - accuracy: 1.0000\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 2.1354e-04 - accuracy: 0.9999\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 1.8820e-04 - accuracy: 0.9999\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 7.0970e-05 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 3.8436e-04 - accuracy: 0.9998\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 1.0619e-04 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 5.1287e-04 - accuracy: 0.9998\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 4.4550e-05 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 1.8118e-05 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 7.9510e-05 - accuracy: 0.9999\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 5.1934e-04 - accuracy: 0.9999\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 1.2996e-04 - accuracy: 0.9999\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 3.9245e-05 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 1.2462e-05 - accuracy: 1.0000\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 1.5632e-05 - accuracy: 1.0000\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 1.5300e-05 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 4.7431e-04 - accuracy: 0.9998\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 1.6516e-04 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 1.4944e-05 - accuracy: 1.0000\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 2.3956e-04 - accuracy: 0.9999\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 9.7145e-06 - accuracy: 1.0000\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 4.8782e-04 - accuracy: 0.9999\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 4.3894e-04 - accuracy: 0.9998\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 5.0244e-05 - accuracy: 1.0000\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 1.8107e-05 - accuracy: 1.0000\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 1.3930e-05 - accuracy: 1.0000\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 4.5612e-04 - accuracy: 0.9998\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 3.2420e-05 - accuracy: 1.0000\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 3.7194e-04 - accuracy: 0.9998\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 3.0177e-04 - accuracy: 0.9999\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 7.4342e-05 - accuracy: 0.9999\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 6.8045e-05 - accuracy: 1.0000\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 1.7514e-05 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 2.6334e-04 - accuracy: 0.9998\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 1.9521e-04 - accuracy: 0.9999\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 8.1488e-05 - accuracy: 0.9999\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 1.3797e-04 - accuracy: 0.9999\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 2.4778e-04 - accuracy: 0.9999\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 2.3355e-04 - accuracy: 0.9999\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 2.7092e-05 - accuracy: 1.0000\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 1.2746e-04 - accuracy: 0.9999\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.6243 - accuracy: 0.9490\n",
      "Test_Accuracy: 94.90%\n",
      "5512/5512 [==============================] - 0s 77us/sample - loss: 0.6243 - accuracy: 0.9490\n",
      "4410/4410 [==============================] - 0s 78us/sample - loss: 0.4823 - accuracy: 0.9587\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.3572 - accuracy: 0.8475\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.1993 - accuracy: 0.9264\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1658 - accuracy: 0.9401\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1393 - accuracy: 0.9502\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.1121 - accuracy: 0.9602\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.0878 - accuracy: 0.9684\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.0683 - accuracy: 0.9769\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.0551 - accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.0427 - accuracy: 0.9849\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.0331 - accuracy: 0.9880\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.0312 - accuracy: 0.9892\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.0192 - accuracy: 0.9936\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.0161 - accuracy: 0.9946\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0148 - accuracy: 0.9948\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0200 - accuracy: 0.9932\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0162 - accuracy: 0.9944\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0144 - accuracy: 0.9950\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0169 - accuracy: 0.9942\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0093 - accuracy: 0.9966\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0129 - accuracy: 0.9960\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0097 - accuracy: 0.9968\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0097 - accuracy: 0.9967\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0109 - accuracy: 0.9960\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0152 - accuracy: 0.9952\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0087 - accuracy: 0.9975\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0045 - accuracy: 0.9986\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0062 - accuracy: 0.9976\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0049 - accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0064 - accuracy: 0.9980\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0026 - accuracy: 0.9989\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0109 - accuracy: 0.9967\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0079 - accuracy: 0.9973\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 6.7416e-04 - accuracy: 0.9998\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0011 - accuracy: 0.9995\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 9.4902e-04 - accuracy: 0.9997\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 8.5448e-04 - accuracy: 0.9997\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 7.9979e-04 - accuracy: 0.9998\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 9.6099e-04 - accuracy: 0.9997\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 5.6568e-04 - accuracy: 0.9998\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1304 - accuracy: 0.9597\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.0615 - accuracy: 0.9781\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.0643 - accuracy: 0.9768\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.0535 - accuracy: 0.9805\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.0578 - accuracy: 0.9802\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.0493 - accuracy: 0.9823\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.0417 - accuracy: 0.9872\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.0257 - accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0218 - accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0156 - accuracy: 0.9944\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.0115 - accuracy: 0.9965\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9997\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 7.7179e-04 - accuracy: 0.9999\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 6.5909e-04 - accuracy: 0.9998\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 8.3449e-04 - accuracy: 0.9998\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 7.1971e-04 - accuracy: 0.9998\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 8.3889e-04 - accuracy: 0.9997\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 2.7229e-04 - accuracy: 0.9999\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 5.1806e-04 - accuracy: 0.9999\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 8.8406e-04 - accuracy: 0.9998\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 1.9449e-04 - accuracy: 0.9999\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 2.5459e-04 - accuracy: 0.9999\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 1.5413e-04 - accuracy: 0.9999\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 1.8146e-04 - accuracy: 1.0000\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 4.9355e-04 - accuracy: 0.9997\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 9.8913e-04 - accuracy: 0.9997\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 7.7808e-04 - accuracy: 0.9998\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 7.2135e-04 - accuracy: 0.9997\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 2.3994e-04 - accuracy: 0.9999\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 1.7426e-04 - accuracy: 0.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 8.2387e-05 - accuracy: 1.0000\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 1.0414e-04 - accuracy: 1.0000\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 5.8226e-04 - accuracy: 0.9998\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 1.1066e-04 - accuracy: 1.0000\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 4.7949e-05 - accuracy: 1.0000\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 4.2056e-05 - accuracy: 1.0000\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 1.4216e-04 - accuracy: 0.9999\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 4.4836e-04 - accuracy: 0.9998\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 1.8424e-04 - accuracy: 0.9999\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 2.0192e-04 - accuracy: 0.9999\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 2.6655e-04 - accuracy: 0.9999\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 2.9181e-04 - accuracy: 0.9998\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 1.4725e-04 - accuracy: 0.9999\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 4.9543e-04 - accuracy: 0.9998\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 1.2266e-04 - accuracy: 0.9999\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 9.1417e-04 - accuracy: 0.9997\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 3.9799e-04 - accuracy: 0.9998\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 3.7414e-04 - accuracy: 0.9998\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 8.9735e-05 - accuracy: 1.0000\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 4.6908e-05 - accuracy: 1.0000\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 1.3876e-04 - accuracy: 0.9999\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 7.8488e-04 - accuracy: 0.9998\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 6.4318e-04 - accuracy: 0.9998\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 3.7416e-04 - accuracy: 0.9999\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 6.0072e-04 - accuracy: 0.9998\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 5.6031e-04 - accuracy: 0.9998\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 6.6065e-04 - accuracy: 0.9997\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 9.6763e-05 - accuracy: 1.0000\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 1.0044e-04 - accuracy: 0.9999\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 6.3887e-05 - accuracy: 1.0000\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 7.0127e-05 - accuracy: 1.0000\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 4.6667e-04 - accuracy: 0.9998\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 3.3637e-04 - accuracy: 0.9999\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 1.1743e-04 - accuracy: 0.9999\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 3.6001e-05 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 1.3173e-04 - accuracy: 0.9999\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 3.1373e-04 - accuracy: 0.9999\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 6.9068e-05 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 1.1639e-04 - accuracy: 1.0000\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 3.9959e-04 - accuracy: 0.9998\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 1.1682e-04 - accuracy: 0.9999\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 3.4392e-04 - accuracy: 0.9999\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 1.4781e-04 - accuracy: 0.9999\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 3.2715e-05 - accuracy: 1.0000\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 8.3980e-05 - accuracy: 0.9999\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 2.0995e-04 - accuracy: 0.9999\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 1.9691e-04 - accuracy: 0.9999\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 3.7263e-04 - accuracy: 0.9998\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 2.5441e-04 - accuracy: 0.9999\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 7.5065e-04 - accuracy: 0.9998\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 6.9039e-05 - accuracy: 1.0000\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 7.5679e-05 - accuracy: 1.0000\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 8.9383e-04 - accuracy: 0.9998\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 5.1025e-05 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 2.0718e-04 - accuracy: 0.9999\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 2.4998e-04 - accuracy: 0.9999\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 7.0166e-05 - accuracy: 1.0000\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 6.1725e-04 - accuracy: 0.9998\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 3.3994e-04 - accuracy: 0.9998\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 4.6789e-05 - accuracy: 1.0000\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 1.0106e-04 - accuracy: 0.9999\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 1.5522e-04 - accuracy: 0.9999\n",
      "5512/5512 [==============================] - 1s 98us/sample - loss: 0.5572 - accuracy: 0.9523\n",
      "Test_Accuracy: 95.23%\n",
      "5512/5512 [==============================] - 0s 78us/sample - loss: 0.5572 - accuracy: 0.9523\n",
      "4410/4410 [==============================] - 0s 77us/sample - loss: 0.3580 - accuracy: 0.9637\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.4251 - accuracy: 0.8026\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.2076 - accuracy: 0.9217\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1730 - accuracy: 0.9348\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1458 - accuracy: 0.9459\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.1173 - accuracy: 0.9564\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.0961 - accuracy: 0.9654\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.0777 - accuracy: 0.9734\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.0732 - accuracy: 0.9736\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.0591 - accuracy: 0.9787\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.0487 - accuracy: 0.9825\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.0371 - accuracy: 0.9862\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.0358 - accuracy: 0.9877\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.0377 - accuracy: 0.9869\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0255 - accuracy: 0.9914\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0177 - accuracy: 0.9938\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0152 - accuracy: 0.9950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0150 - accuracy: 0.9954\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0146 - accuracy: 0.9946\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0140 - accuracy: 0.9957\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0199 - accuracy: 0.9926\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0127 - accuracy: 0.9950\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0090 - accuracy: 0.9978\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0140 - accuracy: 0.9954\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0108 - accuracy: 0.9958\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0145 - accuracy: 0.9957\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0056 - accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0072 - accuracy: 0.9975\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0066 - accuracy: 0.9979\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0049 - accuracy: 0.9982\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0128 - accuracy: 0.9962\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0075 - accuracy: 0.9972\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0060 - accuracy: 0.9976\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0037 - accuracy: 0.9985\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0058 - accuracy: 0.9978\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0078 - accuracy: 0.9975\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0050 - accuracy: 0.9982\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0023 - accuracy: 0.9990\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0018 - accuracy: 0.9992\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0021 - accuracy: 0.9991\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0017 - accuracy: 0.9993\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1366 - accuracy: 0.9575\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.0876 - accuracy: 0.9705\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.0814 - accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.0745 - accuracy: 0.9743\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.0501 - accuracy: 0.9832\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.0425 - accuracy: 0.9857\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.0361 - accuracy: 0.9868\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.0282 - accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0320 - accuracy: 0.9893\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0265 - accuracy: 0.9910\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 4s - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0030 - accuracy: 0.9991\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 5.0558e-04 - accuracy: 0.9999\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 5.1810e-04 - accuracy: 0.9999\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 9.5385e-04 - accuracy: 0.9998\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 9.1156e-04 - accuracy: 0.9997\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 8.2884e-04 - accuracy: 0.9997\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 4.4408e-04 - accuracy: 0.9998\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 2.6082e-04 - accuracy: 0.9999\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 6.1188e-04 - accuracy: 0.9998\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 5.5178e-04 - accuracy: 0.9999\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 6.4742e-04 - accuracy: 0.9998\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 5.9431e-04 - accuracy: 0.9998\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 6.9690e-04 - accuracy: 0.9998\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 3.8317e-04 - accuracy: 0.9999\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 2.2608e-04 - accuracy: 0.9999\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 4.1616e-04 - accuracy: 0.9998\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 8.6590e-04 - accuracy: 0.9996\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 8.2873e-04 - accuracy: 0.9997\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 1.7273e-04 - accuracy: 0.9999\n",
      "Epoch 35/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17636/17636 - 3s - loss: 5.1906e-04 - accuracy: 0.9998\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 3.3684e-04 - accuracy: 0.9999\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 8.9362e-04 - accuracy: 0.9997\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 8.9105e-04 - accuracy: 0.9999\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 7.9522e-04 - accuracy: 0.9998\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 7.9587e-05 - accuracy: 1.0000\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 1.1207e-04 - accuracy: 0.9999\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 2.2261e-04 - accuracy: 0.9999\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 5.7931e-04 - accuracy: 0.9997\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 1.7736e-04 - accuracy: 1.0000\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 8.5057e-04 - accuracy: 0.9998\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 6.5578e-04 - accuracy: 0.9998\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 8.2599e-04 - accuracy: 0.9997\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 7.6403e-04 - accuracy: 0.9996\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 4.4186e-04 - accuracy: 0.9998\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 7.4662e-04 - accuracy: 0.9998\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 6.0541e-05 - accuracy: 1.0000\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 5.9627e-04 - accuracy: 0.9997\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 4.1889e-04 - accuracy: 0.9998\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 6.0136e-04 - accuracy: 0.9998\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 1.8803e-04 - accuracy: 0.9999\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 8.6851e-04 - accuracy: 0.9997\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 6.9697e-04 - accuracy: 0.9997\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 5.0462e-04 - accuracy: 0.9999\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 1.0798e-04 - accuracy: 1.0000\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 2.2816e-04 - accuracy: 0.9998\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 3.5410e-04 - accuracy: 0.9998\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 6.2698e-04 - accuracy: 0.9998\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 3.6258e-04 - accuracy: 0.9999\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 2.5055e-04 - accuracy: 0.9999\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 3.7898e-04 - accuracy: 0.9999\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 6.3894e-04 - accuracy: 0.9998\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 5.8537e-04 - accuracy: 0.9997\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 2.6507e-04 - accuracy: 0.9999\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 6.3590e-04 - accuracy: 0.9998\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 8.4163e-04 - accuracy: 0.9998\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 8.4251e-04 - accuracy: 0.9998\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 4.3367e-04 - accuracy: 0.9998\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 3.5833e-04 - accuracy: 0.9999\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 4.8089e-04 - accuracy: 0.9997\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 6.6305e-04 - accuracy: 0.9997\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 3.6097e-04 - accuracy: 0.9999\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 7.3752e-05 - accuracy: 1.0000\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 2.8745e-04 - accuracy: 0.9999\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 6.2971e-04 - accuracy: 0.9998\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 1.3074e-04 - accuracy: 0.9999\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 4.5260e-04 - accuracy: 0.9998\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 8.3451e-04 - accuracy: 0.9997\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 7.0720e-04 - accuracy: 0.9999\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 6.4361e-04 - accuracy: 0.9998\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0015 - accuracy: 0.9995\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.5905 - accuracy: 0.9472\n",
      "Test_Accuracy: 94.72%\n",
      "5512/5512 [==============================] - 0s 78us/sample - loss: 0.5905 - accuracy: 0.9472\n",
      "4410/4410 [==============================] - 0s 78us/sample - loss: 0.4075 - accuracy: 0.9533\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.3813 - accuracy: 0.8384\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.2191 - accuracy: 0.9172\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1861 - accuracy: 0.9306\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1625 - accuracy: 0.9409\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.1432 - accuracy: 0.9468\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1296 - accuracy: 0.9510\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1094 - accuracy: 0.9592\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.0954 - accuracy: 0.9649\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.0829 - accuracy: 0.9703\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.0750 - accuracy: 0.9727\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.0613 - accuracy: 0.9785\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.0531 - accuracy: 0.9815\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.0413 - accuracy: 0.9856\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0363 - accuracy: 0.9866\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0346 - accuracy: 0.9883\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0271 - accuracy: 0.9912\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0262 - accuracy: 0.9905\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0222 - accuracy: 0.9922\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0208 - accuracy: 0.9921\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0215 - accuracy: 0.9923\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0171 - accuracy: 0.9936\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0169 - accuracy: 0.9940\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0210 - accuracy: 0.9928\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0139 - accuracy: 0.9952\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22046/22046 - 3s - loss: 0.0117 - accuracy: 0.9958\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0117 - accuracy: 0.9956\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0119 - accuracy: 0.9963\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0084 - accuracy: 0.9974\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0137 - accuracy: 0.9955\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0125 - accuracy: 0.9955\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0122 - accuracy: 0.9959\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0090 - accuracy: 0.9973\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0068 - accuracy: 0.9975\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0077 - accuracy: 0.9973\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0065 - accuracy: 0.9976\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0077 - accuracy: 0.9973\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0062 - accuracy: 0.9978\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0028 - accuracy: 0.9988\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0010 - accuracy: 0.9999\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 7.9261e-04 - accuracy: 0.9998\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0034 - accuracy: 0.9989\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 4s - loss: 0.1449 - accuracy: 0.9537\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.0968 - accuracy: 0.9648\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.0919 - accuracy: 0.9672\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1050 - accuracy: 0.9627\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.0628 - accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.0890 - accuracy: 0.9683\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.0804 - accuracy: 0.9714\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.0674 - accuracy: 0.9752\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0504 - accuracy: 0.9821\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0364 - accuracy: 0.9871\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.0314 - accuracy: 0.9894\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0162 - accuracy: 0.9940\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0082 - accuracy: 0.9968\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0043 - accuracy: 0.9989\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0045 - accuracy: 0.9988\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 7.5990e-04 - accuracy: 0.9998\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 7.8470e-04 - accuracy: 0.9998\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 9.4266e-04 - accuracy: 0.9997\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 7.9960e-04 - accuracy: 0.9998\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 7.3690e-04 - accuracy: 0.9997\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 5.6617e-04 - accuracy: 0.9998\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 6.7905e-04 - accuracy: 0.9998\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 8.0197e-04 - accuracy: 0.9998\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 8.8765e-04 - accuracy: 0.9997\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 9.3791e-04 - accuracy: 0.9997\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 6.8125e-04 - accuracy: 0.9998\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 8.8113e-04 - accuracy: 0.9997\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 4.2641e-04 - accuracy: 0.9999\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 3.0131e-04 - accuracy: 1.0000\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 1.6843e-04 - accuracy: 1.0000\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 6.8229e-04 - accuracy: 0.9997\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 4.6075e-04 - accuracy: 0.9999\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 7.7555e-04 - accuracy: 0.9997\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 9.8563e-04 - accuracy: 0.9995\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 5.5149e-04 - accuracy: 0.9998\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 5.7003e-04 - accuracy: 0.9998\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 8.8062e-04 - accuracy: 0.9996\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 9.3768e-04 - accuracy: 0.9996\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 9.5229e-04 - accuracy: 0.9997\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 6.5343e-04 - accuracy: 0.9999\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 6.4525e-04 - accuracy: 0.9998\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 7.6305e-04 - accuracy: 0.9998\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 3.8439e-04 - accuracy: 0.9999\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 4.8139e-04 - accuracy: 0.9998\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 7.5483e-04 - accuracy: 0.9998\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 3.4624e-04 - accuracy: 0.9998\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 4.5499e-04 - accuracy: 0.9999\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.4802 - accuracy: 0.9523\n",
      "Test_Accuracy: 95.23%\n",
      "5512/5512 [==============================] - 0s 81us/sample - loss: 0.4802 - accuracy: 0.9523\n",
      "4410/4410 [==============================] - 0s 86us/sample - loss: 0.3438 - accuracy: 0.9583\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.4474 - accuracy: 0.7967\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.2239 - accuracy: 0.9168\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1886 - accuracy: 0.9317\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1616 - accuracy: 0.9401\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.1402 - accuracy: 0.9497\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1261 - accuracy: 0.9560\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1061 - accuracy: 0.9611\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.0958 - accuracy: 0.9658\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.0859 - accuracy: 0.9696\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.0744 - accuracy: 0.9733\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.0658 - accuracy: 0.9778\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.0597 - accuracy: 0.9784\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.0554 - accuracy: 0.9799\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0425 - accuracy: 0.9844\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0396 - accuracy: 0.9861\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0347 - accuracy: 0.9869\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0306 - accuracy: 0.9892\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0412 - accuracy: 0.9861\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0284 - accuracy: 0.9899\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0238 - accuracy: 0.9915\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0233 - accuracy: 0.9916\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0226 - accuracy: 0.9919\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0164 - accuracy: 0.9946\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0197 - accuracy: 0.9930\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0198 - accuracy: 0.9926\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0209 - accuracy: 0.9926\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0204 - accuracy: 0.9934\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0160 - accuracy: 0.9944\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0155 - accuracy: 0.9941\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0159 - accuracy: 0.9940\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0143 - accuracy: 0.9950\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0153 - accuracy: 0.9947\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0144 - accuracy: 0.9954\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0132 - accuracy: 0.9951\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0135 - accuracy: 0.9953\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22046/22046 - 3s - loss: 0.0092 - accuracy: 0.9964\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0068 - accuracy: 0.9980\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0086 - accuracy: 0.9975\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0121 - accuracy: 0.9958\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0109 - accuracy: 0.9968\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0096 - accuracy: 0.9963\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0098 - accuracy: 0.9967\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0114 - accuracy: 0.9958\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0099 - accuracy: 0.9966\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0081 - accuracy: 0.9973\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0082 - accuracy: 0.9970\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0064 - accuracy: 0.9980\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0091 - accuracy: 0.9970\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0068 - accuracy: 0.9976\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9979\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0052 - accuracy: 0.9981\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0046 - accuracy: 0.9983\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0070 - accuracy: 0.9979\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0060 - accuracy: 0.9978\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0078 - accuracy: 0.9975\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0051 - accuracy: 0.9986\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0035 - accuracy: 0.9985\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0030 - accuracy: 0.9990\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 4s - loss: 0.1536 - accuracy: 0.9488\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.0985 - accuracy: 0.9667\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.0993 - accuracy: 0.9650\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1162 - accuracy: 0.9578\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.0863 - accuracy: 0.9698\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.0653 - accuracy: 0.9775\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.0572 - accuracy: 0.9805\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.1242 - accuracy: 0.9561\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0704 - accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0508 - accuracy: 0.9821\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.0266 - accuracy: 0.9912\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0181 - accuracy: 0.9937\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0142 - accuracy: 0.9950\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0129 - accuracy: 0.9954\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0112 - accuracy: 0.9964\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0101 - accuracy: 0.9965\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0067 - accuracy: 0.9978\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0043 - accuracy: 0.9981\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0035 - accuracy: 0.9985\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 9.5046e-04 - accuracy: 0.9997\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9992\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9989\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0029 - accuracy: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 8.2040e-04 - accuracy: 0.9998\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 8.1543e-04 - accuracy: 0.9996\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0023 - accuracy: 0.9989\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 7.9756e-04 - accuracy: 0.9997\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9994\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 9.7340e-04 - accuracy: 0.9996\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0029 - accuracy: 0.9989\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.4038 - accuracy: 0.9523\n",
      "Test_Accuracy: 95.23%\n",
      "5512/5512 [==============================] - 0s 75us/sample - loss: 0.4038 - accuracy: 0.9523\n",
      "4410/4410 [==============================] - 0s 75us/sample - loss: 0.3123 - accuracy: 0.9592\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.4862 - accuracy: 0.7755\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.2203 - accuracy: 0.9172\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1859 - accuracy: 0.9320\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1634 - accuracy: 0.9418\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.1504 - accuracy: 0.9467\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1352 - accuracy: 0.9519\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1261 - accuracy: 0.9539\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.1115 - accuracy: 0.9604\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.1031 - accuracy: 0.9629\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.0909 - accuracy: 0.9673\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.0849 - accuracy: 0.9696\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.0742 - accuracy: 0.9733\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.0636 - accuracy: 0.9766\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0621 - accuracy: 0.9776\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0553 - accuracy: 0.9804\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0543 - accuracy: 0.9798\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0435 - accuracy: 0.9848\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0402 - accuracy: 0.9866\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0362 - accuracy: 0.9873\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0351 - accuracy: 0.9874\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0277 - accuracy: 0.9907\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0312 - accuracy: 0.9890\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0239 - accuracy: 0.9917\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0253 - accuracy: 0.9907\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0230 - accuracy: 0.9925\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0244 - accuracy: 0.9916\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0196 - accuracy: 0.9927\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0203 - accuracy: 0.9926\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0216 - accuracy: 0.9924\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0151 - accuracy: 0.9950\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0189 - accuracy: 0.9934\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0165 - accuracy: 0.9943\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0152 - accuracy: 0.9949\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0134 - accuracy: 0.9947\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0167 - accuracy: 0.9944\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0141 - accuracy: 0.9953\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0120 - accuracy: 0.9955\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0125 - accuracy: 0.9957\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0161 - accuracy: 0.9946\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0115 - accuracy: 0.9959\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0076 - accuracy: 0.9979\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0084 - accuracy: 0.9972\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0124 - accuracy: 0.9956\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0144 - accuracy: 0.9945\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0086 - accuracy: 0.9970\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0098 - accuracy: 0.9971\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0114 - accuracy: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0084 - accuracy: 0.9974\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0103 - accuracy: 0.9964\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0103 - accuracy: 0.9968\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0085 - accuracy: 0.9970\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0081 - accuracy: 0.9974\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0054 - accuracy: 0.9979\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0087 - accuracy: 0.9968\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0055 - accuracy: 0.9985\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0065 - accuracy: 0.9978\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0061 - accuracy: 0.9978\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0060 - accuracy: 0.9976\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0055 - accuracy: 0.9983\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0066 - accuracy: 0.9976\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0071 - accuracy: 0.9977\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1395 - accuracy: 0.9555\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1128 - accuracy: 0.9603\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1061 - accuracy: 0.9612\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1029 - accuracy: 0.9640\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.0884 - accuracy: 0.9687\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.0611 - accuracy: 0.9789\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.0513 - accuracy: 0.9820\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.0487 - accuracy: 0.9822\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0813 - accuracy: 0.9702\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0502 - accuracy: 0.9828\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 4s - loss: 0.0300 - accuracy: 0.9901\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0208 - accuracy: 0.9935\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0145 - accuracy: 0.9950\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0117 - accuracy: 0.9960\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0081 - accuracy: 0.9969\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0101 - accuracy: 0.9967\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0076 - accuracy: 0.9974\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.0068 - accuracy: 0.9975\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0061 - accuracy: 0.9978\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0042 - accuracy: 0.9984\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0057 - accuracy: 0.9984\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0060 - accuracy: 0.9980\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0052 - accuracy: 0.9980\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9991\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 8.3791e-04 - accuracy: 0.9997\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9992\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9993\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0024 - accuracy: 0.9997\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 8.9271e-04 - accuracy: 0.9998\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 6.4900e-04 - accuracy: 0.9997\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0015 - accuracy: 0.9993\n",
      "5512/5512 [==============================] - 1s 94us/sample - loss: 0.3839 - accuracy: 0.9546\n",
      "Test_Accuracy: 95.46%\n",
      "5512/5512 [==============================] - 0s 75us/sample - loss: 0.3839 - accuracy: 0.9546\n",
      "4410/4410 [==============================] - 0s 77us/sample - loss: 0.2546 - accuracy: 0.9615\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.4090 - accuracy: 0.8257\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.2297 - accuracy: 0.9161\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1953 - accuracy: 0.9289\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1704 - accuracy: 0.9408\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.1562 - accuracy: 0.9447\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1414 - accuracy: 0.9501\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1326 - accuracy: 0.9530\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.1209 - accuracy: 0.9575\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.1138 - accuracy: 0.9595\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.1060 - accuracy: 0.9623\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.0962 - accuracy: 0.9654\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.0875 - accuracy: 0.9688\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.0829 - accuracy: 0.9710\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0735 - accuracy: 0.9738\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0672 - accuracy: 0.9761\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0584 - accuracy: 0.9787\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0597 - accuracy: 0.9785\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0541 - accuracy: 0.9809\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0498 - accuracy: 0.9822\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0456 - accuracy: 0.9838\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0423 - accuracy: 0.9849\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0402 - accuracy: 0.9855\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0360 - accuracy: 0.9866\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0357 - accuracy: 0.9875\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0361 - accuracy: 0.9868\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0250 - accuracy: 0.9918\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0291 - accuracy: 0.9897\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0227 - accuracy: 0.9923\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0239 - accuracy: 0.9913\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0204 - accuracy: 0.9927\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0226 - accuracy: 0.9922\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0217 - accuracy: 0.9920\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0183 - accuracy: 0.9936\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0247 - accuracy: 0.9913\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0161 - accuracy: 0.9944\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0140 - accuracy: 0.9953\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0181 - accuracy: 0.9932\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0160 - accuracy: 0.9945\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0137 - accuracy: 0.9953\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0187 - accuracy: 0.9929\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0224 - accuracy: 0.9929\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0174 - accuracy: 0.9943\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0155 - accuracy: 0.9948\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0140 - accuracy: 0.9952\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0140 - accuracy: 0.9954\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0141 - accuracy: 0.9954\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0125 - accuracy: 0.9955\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0120 - accuracy: 0.9957\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0117 - accuracy: 0.9960\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0119 - accuracy: 0.9956\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0108 - accuracy: 0.9961\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0123 - accuracy: 0.9964\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0115 - accuracy: 0.9963\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0113 - accuracy: 0.9958\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0130 - accuracy: 0.9962\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0096 - accuracy: 0.9967\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0097 - accuracy: 0.9966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0120 - accuracy: 0.9962\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0076 - accuracy: 0.9974\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0124 - accuracy: 0.9957\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0080 - accuracy: 0.9972\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0078 - accuracy: 0.9971\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0078 - accuracy: 0.9974\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0088 - accuracy: 0.9971\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0102 - accuracy: 0.9968\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0083 - accuracy: 0.9975\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0087 - accuracy: 0.9969\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0079 - accuracy: 0.9971\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0075 - accuracy: 0.9973\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0141 - accuracy: 0.9954\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0118 - accuracy: 0.9962\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0086 - accuracy: 0.9970\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0075 - accuracy: 0.9971\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0070 - accuracy: 0.9973\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0068 - accuracy: 0.9978\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1621 - accuracy: 0.9454\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1442 - accuracy: 0.9504\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1203 - accuracy: 0.9583\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1244 - accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.0977 - accuracy: 0.9669\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.0788 - accuracy: 0.9739\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.0781 - accuracy: 0.9722\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.0779 - accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0658 - accuracy: 0.9774\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0665 - accuracy: 0.9761\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.0449 - accuracy: 0.9836\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0346 - accuracy: 0.9879\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0290 - accuracy: 0.9903\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0264 - accuracy: 0.9910\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0212 - accuracy: 0.9925\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0203 - accuracy: 0.9936\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0166 - accuracy: 0.9944\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0169 - accuracy: 0.9944\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0140 - accuracy: 0.9948\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.0125 - accuracy: 0.9960\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0135 - accuracy: 0.9951\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0123 - accuracy: 0.9951\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.0112 - accuracy: 0.9963\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0127 - accuracy: 0.9958\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0095 - accuracy: 0.9968\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.0079 - accuracy: 0.9969\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0125 - accuracy: 0.9952\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0082 - accuracy: 0.9977\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0078 - accuracy: 0.9974\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0081 - accuracy: 0.9971\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0054 - accuracy: 0.9978\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0052 - accuracy: 0.9985\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0067 - accuracy: 0.9979\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.0049 - accuracy: 0.9982\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0055 - accuracy: 0.9983\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 86/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17636/17636 - 3s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0062 - accuracy: 0.9985\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0020 - accuracy: 0.9992\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.3589 - accuracy: 0.9537\n",
      "Test_Accuracy: 95.37%\n",
      "5512/5512 [==============================] - 0s 77us/sample - loss: 0.3589 - accuracy: 0.9537\n",
      "4410/4410 [==============================] - 0s 77us/sample - loss: 0.2434 - accuracy: 0.9596\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.4694 - accuracy: 0.7925\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.2336 - accuracy: 0.9154\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.1961 - accuracy: 0.9296\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.1827 - accuracy: 0.9330\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.1741 - accuracy: 0.9373\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1592 - accuracy: 0.9439\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1484 - accuracy: 0.9468\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.1368 - accuracy: 0.9519\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.1291 - accuracy: 0.9542\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.1227 - accuracy: 0.9567\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.1165 - accuracy: 0.9585\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.1129 - accuracy: 0.9594\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.1029 - accuracy: 0.9631\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.0971 - accuracy: 0.9655\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.0905 - accuracy: 0.9686\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0882 - accuracy: 0.9682\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0806 - accuracy: 0.9710\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0763 - accuracy: 0.9726\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0677 - accuracy: 0.9764\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0701 - accuracy: 0.9739\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0635 - accuracy: 0.9772\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0604 - accuracy: 0.9795\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0555 - accuracy: 0.9804\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0523 - accuracy: 0.9816\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0495 - accuracy: 0.9821\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0444 - accuracy: 0.9840\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0463 - accuracy: 0.9838\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0378 - accuracy: 0.9870\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0380 - accuracy: 0.9875\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0362 - accuracy: 0.9868\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0401 - accuracy: 0.9861\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0350 - accuracy: 0.9882\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0320 - accuracy: 0.9891\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0310 - accuracy: 0.9890\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0291 - accuracy: 0.9897\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0254 - accuracy: 0.9914\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0274 - accuracy: 0.9898\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0301 - accuracy: 0.9893\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0297 - accuracy: 0.9890\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0273 - accuracy: 0.9912\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0284 - accuracy: 0.9902\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0252 - accuracy: 0.9915\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0259 - accuracy: 0.9908\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0245 - accuracy: 0.9921\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0224 - accuracy: 0.9926\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0211 - accuracy: 0.9932\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0231 - accuracy: 0.9921\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0253 - accuracy: 0.9913\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0184 - accuracy: 0.9932\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0218 - accuracy: 0.9923\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0493 - accuracy: 0.9828\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0386 - accuracy: 0.9865\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0276 - accuracy: 0.9897\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0237 - accuracy: 0.9910\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0226 - accuracy: 0.9922\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0275 - accuracy: 0.9905\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0204 - accuracy: 0.9926\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0199 - accuracy: 0.9931\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0177 - accuracy: 0.9937\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0172 - accuracy: 0.9943\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0196 - accuracy: 0.9932\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0193 - accuracy: 0.9932\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0156 - accuracy: 0.9947\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0172 - accuracy: 0.9943\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0145 - accuracy: 0.9947\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0198 - accuracy: 0.9934\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0180 - accuracy: 0.9940\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0130 - accuracy: 0.9956\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0145 - accuracy: 0.9953\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0132 - accuracy: 0.9962\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0125 - accuracy: 0.9960\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0110 - accuracy: 0.9959\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0139 - accuracy: 0.9946\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0150 - accuracy: 0.9948\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0144 - accuracy: 0.9952\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0133 - accuracy: 0.9952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0175 - accuracy: 0.9948\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0094 - accuracy: 0.9968\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0147 - accuracy: 0.9950\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0147 - accuracy: 0.9951\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0125 - accuracy: 0.9964\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0099 - accuracy: 0.9963\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0120 - accuracy: 0.9954\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0159 - accuracy: 0.9946\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0188 - accuracy: 0.9941\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0101 - accuracy: 0.9961\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0132 - accuracy: 0.9956\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0163 - accuracy: 0.9941\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0130 - accuracy: 0.9963\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0130 - accuracy: 0.9956\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1568 - accuracy: 0.9448\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1539 - accuracy: 0.9444\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1258 - accuracy: 0.9573\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1368 - accuracy: 0.9509\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.1372 - accuracy: 0.9523\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.1064 - accuracy: 0.9630\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.1342 - accuracy: 0.9511\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.1259 - accuracy: 0.9551\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.1027 - accuracy: 0.9641\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0859 - accuracy: 0.9705\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.0548 - accuracy: 0.9824\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0521 - accuracy: 0.9818\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0457 - accuracy: 0.9841\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0430 - accuracy: 0.9842\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0409 - accuracy: 0.9860\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0393 - accuracy: 0.9872\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0368 - accuracy: 0.9875\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0332 - accuracy: 0.9891\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0327 - accuracy: 0.9881\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.0286 - accuracy: 0.9912\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0312 - accuracy: 0.9892\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0259 - accuracy: 0.9909\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.0271 - accuracy: 0.9912\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0251 - accuracy: 0.9910\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0218 - accuracy: 0.9932\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.0239 - accuracy: 0.9917\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0204 - accuracy: 0.9927\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0248 - accuracy: 0.9915\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0212 - accuracy: 0.9929\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0186 - accuracy: 0.9934\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0175 - accuracy: 0.9943\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0182 - accuracy: 0.9933\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0152 - accuracy: 0.9954\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0182 - accuracy: 0.9938\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0177 - accuracy: 0.9943\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0156 - accuracy: 0.9948\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0143 - accuracy: 0.9950\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0144 - accuracy: 0.9952\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0151 - accuracy: 0.9949\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0127 - accuracy: 0.9959\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0124 - accuracy: 0.9956\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0125 - accuracy: 0.9960\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0145 - accuracy: 0.9946\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0126 - accuracy: 0.9954\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0106 - accuracy: 0.9967\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0127 - accuracy: 0.9953\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0131 - accuracy: 0.9956\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0132 - accuracy: 0.9959\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0119 - accuracy: 0.9964\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0112 - accuracy: 0.9964\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0121 - accuracy: 0.9958\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0109 - accuracy: 0.9960\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0119 - accuracy: 0.9960\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0103 - accuracy: 0.9964\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0116 - accuracy: 0.9962\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0103 - accuracy: 0.9966\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.0087 - accuracy: 0.9973\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0103 - accuracy: 0.9969\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0071 - accuracy: 0.9977\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0104 - accuracy: 0.9967\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0093 - accuracy: 0.9966\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0083 - accuracy: 0.9972\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0083 - accuracy: 0.9977\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0064 - accuracy: 0.9980\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0075 - accuracy: 0.9971\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0091 - accuracy: 0.9973\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0101 - accuracy: 0.9967\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0061 - accuracy: 0.9978\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0087 - accuracy: 0.9970\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0062 - accuracy: 0.9978\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0074 - accuracy: 0.9973\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0060 - accuracy: 0.9978\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0052 - accuracy: 0.9980\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0061 - accuracy: 0.9979\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0059 - accuracy: 0.9982\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.3353 - accuracy: 0.9554\n",
      "Test_Accuracy: 95.54%\n",
      "5512/5512 [==============================] - 0s 78us/sample - loss: 0.3353 - accuracy: 0.9554\n",
      "4410/4410 [==============================] - 0s 75us/sample - loss: 0.2454 - accuracy: 0.9567\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22046/22046 - 4s - loss: 0.5941 - accuracy: 0.7194\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.2792 - accuracy: 0.8923\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.2306 - accuracy: 0.9163\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.2081 - accuracy: 0.9248\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.1941 - accuracy: 0.9296\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1832 - accuracy: 0.9343\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1752 - accuracy: 0.9362\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.1663 - accuracy: 0.9403\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.1511 - accuracy: 0.9467\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.1392 - accuracy: 0.9503\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.1333 - accuracy: 0.9526\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.1203 - accuracy: 0.9557\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.1152 - accuracy: 0.9599\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.1133 - accuracy: 0.9602\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.1064 - accuracy: 0.9621\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.0977 - accuracy: 0.9662\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.0890 - accuracy: 0.9687\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.0896 - accuracy: 0.9687\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.0877 - accuracy: 0.9681\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.0771 - accuracy: 0.9719\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.0838 - accuracy: 0.9702\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.0700 - accuracy: 0.9756\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.0684 - accuracy: 0.9755\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.0666 - accuracy: 0.9765\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.0602 - accuracy: 0.9785\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0699 - accuracy: 0.9757\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0550 - accuracy: 0.9802\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0526 - accuracy: 0.9818\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0483 - accuracy: 0.9825\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0465 - accuracy: 0.9841\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0492 - accuracy: 0.9830\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0447 - accuracy: 0.9847\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0430 - accuracy: 0.9847\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0440 - accuracy: 0.9838\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0407 - accuracy: 0.9858\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0393 - accuracy: 0.9862\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0369 - accuracy: 0.9872\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0349 - accuracy: 0.9878\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0380 - accuracy: 0.9868\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0331 - accuracy: 0.9888\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0350 - accuracy: 0.9870\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0348 - accuracy: 0.9880\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0320 - accuracy: 0.9885\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0343 - accuracy: 0.9878\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0307 - accuracy: 0.9890\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0368 - accuracy: 0.9871\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0295 - accuracy: 0.9901\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0308 - accuracy: 0.9888\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0289 - accuracy: 0.9895\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0263 - accuracy: 0.9902\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0260 - accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0289 - accuracy: 0.9912\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0259 - accuracy: 0.9913\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0230 - accuracy: 0.9920\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0218 - accuracy: 0.9922\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0245 - accuracy: 0.9917\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0258 - accuracy: 0.9910\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0231 - accuracy: 0.9927\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0221 - accuracy: 0.9925\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0206 - accuracy: 0.9930\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0203 - accuracy: 0.9927\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0280 - accuracy: 0.9907\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0211 - accuracy: 0.9932\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0210 - accuracy: 0.9929\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0188 - accuracy: 0.9944\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0180 - accuracy: 0.9932\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0217 - accuracy: 0.9922\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0192 - accuracy: 0.9941\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0195 - accuracy: 0.9936\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0191 - accuracy: 0.9939\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0150 - accuracy: 0.9944\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0167 - accuracy: 0.9940\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0189 - accuracy: 0.9936\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0169 - accuracy: 0.9941\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0186 - accuracy: 0.9942\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0177 - accuracy: 0.9941\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0144 - accuracy: 0.9949\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0166 - accuracy: 0.9946\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0137 - accuracy: 0.9954\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0150 - accuracy: 0.9949\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0133 - accuracy: 0.9955\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0150 - accuracy: 0.9950\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0173 - accuracy: 0.9941\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0160 - accuracy: 0.9944\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0127 - accuracy: 0.9960\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0124 - accuracy: 0.9954\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0172 - accuracy: 0.9944\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0169 - accuracy: 0.9946\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0163 - accuracy: 0.9946\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0177 - accuracy: 0.9948\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0135 - accuracy: 0.9953\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0103 - accuracy: 0.9964\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0121 - accuracy: 0.9960\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 4s - loss: 0.1557 - accuracy: 0.9471\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1309 - accuracy: 0.9557\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1268 - accuracy: 0.9579\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1099 - accuracy: 0.9626\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.1027 - accuracy: 0.9652\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.1338 - accuracy: 0.9536\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.1008 - accuracy: 0.9647\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.0925 - accuracy: 0.9681\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.0947 - accuracy: 0.9665\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.0793 - accuracy: 0.9732\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.0554 - accuracy: 0.9815\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0484 - accuracy: 0.9827\n",
      "Epoch 3/90\n",
      "17636/17636 - 2s - loss: 0.0454 - accuracy: 0.9849\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0452 - accuracy: 0.9849\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0417 - accuracy: 0.9861\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0354 - accuracy: 0.9875\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0333 - accuracy: 0.9879\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0325 - accuracy: 0.9891\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0330 - accuracy: 0.9890\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.0311 - accuracy: 0.9897\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0290 - accuracy: 0.9896\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0251 - accuracy: 0.9911\n",
      "Epoch 13/90\n",
      "17636/17636 - 2s - loss: 0.0274 - accuracy: 0.9913\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0235 - accuracy: 0.9923\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0255 - accuracy: 0.9909\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.0278 - accuracy: 0.9900\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0234 - accuracy: 0.9917\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0236 - accuracy: 0.9922\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0226 - accuracy: 0.9925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0197 - accuracy: 0.9935\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0192 - accuracy: 0.9936\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0194 - accuracy: 0.9929\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0156 - accuracy: 0.9942\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0186 - accuracy: 0.9933\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0159 - accuracy: 0.9941\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0136 - accuracy: 0.9949\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0168 - accuracy: 0.9940\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0153 - accuracy: 0.9948\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0164 - accuracy: 0.9947\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0141 - accuracy: 0.9952\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0152 - accuracy: 0.9948\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0185 - accuracy: 0.9932\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0154 - accuracy: 0.9940\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0155 - accuracy: 0.9954\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0130 - accuracy: 0.9957\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0124 - accuracy: 0.9954\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0117 - accuracy: 0.9963\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0131 - accuracy: 0.9959\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0138 - accuracy: 0.9955\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0128 - accuracy: 0.9955\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.0143 - accuracy: 0.9955\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0105 - accuracy: 0.9963\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0135 - accuracy: 0.9952\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0111 - accuracy: 0.9964\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0118 - accuracy: 0.9960\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0110 - accuracy: 0.9964\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.0129 - accuracy: 0.9962\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0097 - accuracy: 0.9965\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0125 - accuracy: 0.9959\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0097 - accuracy: 0.9968\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0093 - accuracy: 0.9972\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0098 - accuracy: 0.9963\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0088 - accuracy: 0.9969\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0079 - accuracy: 0.9974\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0069 - accuracy: 0.9973\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0104 - accuracy: 0.9968\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0081 - accuracy: 0.9969\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0099 - accuracy: 0.9971\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0081 - accuracy: 0.9978\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0076 - accuracy: 0.9974\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0070 - accuracy: 0.9980\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0087 - accuracy: 0.9971\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0095 - accuracy: 0.9971\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0086 - accuracy: 0.9969\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0090 - accuracy: 0.9971\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0067 - accuracy: 0.9976\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0076 - accuracy: 0.9974\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0095 - accuracy: 0.9967\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0074 - accuracy: 0.9972\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0062 - accuracy: 0.9981\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0064 - accuracy: 0.9983\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0056 - accuracy: 0.9981\n",
      "5512/5512 [==============================] - 1s 98us/sample - loss: 0.3923 - accuracy: 0.9514\n",
      "Test_Accuracy: 95.14%\n",
      "5512/5512 [==============================] - 0s 76us/sample - loss: 0.3923 - accuracy: 0.9514\n",
      "4410/4410 [==============================] - 0s 77us/sample - loss: 0.2775 - accuracy: 0.9587\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.6677 - accuracy: 0.6786\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.3076 - accuracy: 0.8814\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.2489 - accuracy: 0.9064\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.2241 - accuracy: 0.9166\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.2118 - accuracy: 0.9235\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1997 - accuracy: 0.9267\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1920 - accuracy: 0.9315\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.1882 - accuracy: 0.9327\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.1782 - accuracy: 0.9355\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.1714 - accuracy: 0.9381\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.1685 - accuracy: 0.9391\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.1596 - accuracy: 0.9408\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.1564 - accuracy: 0.9450\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.1482 - accuracy: 0.9474\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.1402 - accuracy: 0.9494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.1392 - accuracy: 0.9503\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.1359 - accuracy: 0.9519\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.1270 - accuracy: 0.9552\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.1224 - accuracy: 0.9562\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.1216 - accuracy: 0.9572\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.1182 - accuracy: 0.9569\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.1134 - accuracy: 0.9594\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.1096 - accuracy: 0.9594\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.1006 - accuracy: 0.9648\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.1029 - accuracy: 0.9627\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0928 - accuracy: 0.9673\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0944 - accuracy: 0.9656\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0893 - accuracy: 0.9692\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0843 - accuracy: 0.9690\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0848 - accuracy: 0.9703\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0780 - accuracy: 0.9714\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0769 - accuracy: 0.9723\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0753 - accuracy: 0.9727\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0729 - accuracy: 0.9734\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0682 - accuracy: 0.9767\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0626 - accuracy: 0.9775\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0647 - accuracy: 0.9766\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0596 - accuracy: 0.9797\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0570 - accuracy: 0.9799\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0578 - accuracy: 0.9797\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0561 - accuracy: 0.9795\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0581 - accuracy: 0.9801\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0522 - accuracy: 0.9811\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0495 - accuracy: 0.9824\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0539 - accuracy: 0.9815\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0486 - accuracy: 0.9831\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0447 - accuracy: 0.9835\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0416 - accuracy: 0.9854\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0461 - accuracy: 0.9844\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0428 - accuracy: 0.9851\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0398 - accuracy: 0.9853\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0411 - accuracy: 0.9857\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0413 - accuracy: 0.9855\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0394 - accuracy: 0.9869\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0336 - accuracy: 0.9877\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0353 - accuracy: 0.9873\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0367 - accuracy: 0.9875\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0323 - accuracy: 0.9883\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0365 - accuracy: 0.9876\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0367 - accuracy: 0.9865\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0345 - accuracy: 0.9878\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0316 - accuracy: 0.9892\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0341 - accuracy: 0.9873\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0307 - accuracy: 0.9890\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0329 - accuracy: 0.9884\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0313 - accuracy: 0.9884\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0349 - accuracy: 0.9873\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0268 - accuracy: 0.9908\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0270 - accuracy: 0.9903\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0318 - accuracy: 0.9892\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0324 - accuracy: 0.9885\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0293 - accuracy: 0.9897\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0254 - accuracy: 0.9908\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0307 - accuracy: 0.9894\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0315 - accuracy: 0.9891\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0267 - accuracy: 0.9910\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0312 - accuracy: 0.9889\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0242 - accuracy: 0.9916\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0257 - accuracy: 0.9911\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0215 - accuracy: 0.9923\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0267 - accuracy: 0.9906\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0237 - accuracy: 0.9918\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0235 - accuracy: 0.9924\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0239 - accuracy: 0.9914\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0203 - accuracy: 0.9934\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0276 - accuracy: 0.9910\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0217 - accuracy: 0.9918\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0222 - accuracy: 0.9928\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0222 - accuracy: 0.9923\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0233 - accuracy: 0.9914\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0195 - accuracy: 0.9929\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0225 - accuracy: 0.9918\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0196 - accuracy: 0.9933\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0244 - accuracy: 0.9922\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0205 - accuracy: 0.9925\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0339 - accuracy: 0.9877\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0218 - accuracy: 0.9915\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0201 - accuracy: 0.9930\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0200 - accuracy: 0.9932\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1533 - accuracy: 0.9487\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1460 - accuracy: 0.9502\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1362 - accuracy: 0.9529\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1399 - accuracy: 0.9503\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.2077 - accuracy: 0.9241\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.1693 - accuracy: 0.9421\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.1554 - accuracy: 0.9463\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.4920 - accuracy: 0.7311\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.5108 - accuracy: 0.7453\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.2276 - accuracy: 0.9189\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.1811 - accuracy: 0.9379\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.1687 - accuracy: 0.9439\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.1591 - accuracy: 0.9451\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.1543 - accuracy: 0.9460\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.1467 - accuracy: 0.9506\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.1420 - accuracy: 0.9525\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.1308 - accuracy: 0.9548\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.1298 - accuracy: 0.9566\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.1281 - accuracy: 0.9561\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.1191 - accuracy: 0.9594\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.1180 - accuracy: 0.9597\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.1163 - accuracy: 0.9594\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.1127 - accuracy: 0.9617\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.1065 - accuracy: 0.9625\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0981 - accuracy: 0.9654\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.1004 - accuracy: 0.9645\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0985 - accuracy: 0.9646\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0994 - accuracy: 0.9660\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0934 - accuracy: 0.9671\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0918 - accuracy: 0.9684\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0870 - accuracy: 0.9701\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0851 - accuracy: 0.9698\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0908 - accuracy: 0.9665\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0869 - accuracy: 0.9705\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0794 - accuracy: 0.9724\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0757 - accuracy: 0.9730\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0784 - accuracy: 0.9719\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0722 - accuracy: 0.9748\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0706 - accuracy: 0.9745\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0692 - accuracy: 0.9758\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0718 - accuracy: 0.9757\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0657 - accuracy: 0.9762\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0648 - accuracy: 0.9762\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0616 - accuracy: 0.9787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0618 - accuracy: 0.9782\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0626 - accuracy: 0.9785\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0598 - accuracy: 0.9780\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0570 - accuracy: 0.9807\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0566 - accuracy: 0.9806\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0558 - accuracy: 0.9801\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.0547 - accuracy: 0.9807\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0507 - accuracy: 0.9821\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0482 - accuracy: 0.9827\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0523 - accuracy: 0.9822\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0493 - accuracy: 0.9826\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0492 - accuracy: 0.9828\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0479 - accuracy: 0.9835\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0426 - accuracy: 0.9852\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0468 - accuracy: 0.9839\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0405 - accuracy: 0.9861\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0414 - accuracy: 0.9849\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.0406 - accuracy: 0.9860\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0418 - accuracy: 0.9850\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0402 - accuracy: 0.9858\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0411 - accuracy: 0.9851\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0428 - accuracy: 0.9853\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0420 - accuracy: 0.9859\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0366 - accuracy: 0.9874\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0361 - accuracy: 0.9870\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0357 - accuracy: 0.9871\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0352 - accuracy: 0.9870\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0361 - accuracy: 0.9879\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0361 - accuracy: 0.9875\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0310 - accuracy: 0.9899\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0339 - accuracy: 0.9879\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0331 - accuracy: 0.9885\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0279 - accuracy: 0.9896\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0337 - accuracy: 0.9893\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0338 - accuracy: 0.9877\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0376 - accuracy: 0.9866\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0333 - accuracy: 0.9880\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0302 - accuracy: 0.9891\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0286 - accuracy: 0.9891\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0294 - accuracy: 0.9899\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0295 - accuracy: 0.9899\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0253 - accuracy: 0.9922\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.0280 - accuracy: 0.9901\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0251 - accuracy: 0.9911\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0269 - accuracy: 0.9909\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0270 - accuracy: 0.9910\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0231 - accuracy: 0.9918\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0274 - accuracy: 0.9908\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0247 - accuracy: 0.9912\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0224 - accuracy: 0.9930\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0222 - accuracy: 0.9920\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0245 - accuracy: 0.9914\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0256 - accuracy: 0.9921\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0256 - accuracy: 0.9910\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0242 - accuracy: 0.9926\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0246 - accuracy: 0.9919\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.2344 - accuracy: 0.9523\n",
      "Test_Accuracy: 95.23%\n",
      "5512/5512 [==============================] - 0s 77us/sample - loss: 0.2344 - accuracy: 0.9523\n",
      "4410/4410 [==============================] - 0s 84us/sample - loss: 0.1808 - accuracy: 0.9565\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "22046/22046 - 4s - loss: 0.6994 - accuracy: 0.6600\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.3494 - accuracy: 0.8592\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.2477 - accuracy: 0.9093\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.2224 - accuracy: 0.9198\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.2053 - accuracy: 0.9260\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1972 - accuracy: 0.9291\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1907 - accuracy: 0.9325\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.1801 - accuracy: 0.9342\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.1740 - accuracy: 0.9400\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.1678 - accuracy: 0.9401\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.1647 - accuracy: 0.9411\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.1582 - accuracy: 0.9443\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.1481 - accuracy: 0.9490\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.1442 - accuracy: 0.9493\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.1382 - accuracy: 0.9526\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.1315 - accuracy: 0.9556\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.1336 - accuracy: 0.9531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.1248 - accuracy: 0.9566\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.1193 - accuracy: 0.9585\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.1205 - accuracy: 0.9588\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.1122 - accuracy: 0.9607\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.1122 - accuracy: 0.9599\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.1064 - accuracy: 0.9643\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.1046 - accuracy: 0.9627\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.1007 - accuracy: 0.9654\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.0991 - accuracy: 0.9651\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.0965 - accuracy: 0.9665\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.0958 - accuracy: 0.9658\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.0902 - accuracy: 0.9688\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.0880 - accuracy: 0.9697\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.0871 - accuracy: 0.9693\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.0817 - accuracy: 0.9712\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0818 - accuracy: 0.9715\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0793 - accuracy: 0.9715\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0755 - accuracy: 0.9729\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0737 - accuracy: 0.9746\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0687 - accuracy: 0.9750\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0680 - accuracy: 0.9761\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0743 - accuracy: 0.9740\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0657 - accuracy: 0.9766\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0648 - accuracy: 0.9771\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0664 - accuracy: 0.9771\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0579 - accuracy: 0.9794\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0587 - accuracy: 0.9789\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0552 - accuracy: 0.9805\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0552 - accuracy: 0.9807\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0564 - accuracy: 0.9804\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0549 - accuracy: 0.9821\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0528 - accuracy: 0.9811\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0529 - accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0517 - accuracy: 0.9810\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0505 - accuracy: 0.9817\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0479 - accuracy: 0.9834\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0522 - accuracy: 0.9821\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0478 - accuracy: 0.9826\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0470 - accuracy: 0.9833\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0497 - accuracy: 0.9823\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0456 - accuracy: 0.9846\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0461 - accuracy: 0.9839\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0463 - accuracy: 0.9826\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0454 - accuracy: 0.9841\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0447 - accuracy: 0.9844\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0443 - accuracy: 0.9846\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0409 - accuracy: 0.9858\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0410 - accuracy: 0.9858\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0373 - accuracy: 0.9864\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0402 - accuracy: 0.9864\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0423 - accuracy: 0.9845\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0388 - accuracy: 0.9873\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0398 - accuracy: 0.9864\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0356 - accuracy: 0.9883\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0355 - accuracy: 0.9886\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0364 - accuracy: 0.9863\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0331 - accuracy: 0.9884\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0360 - accuracy: 0.9877\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0355 - accuracy: 0.9873\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0357 - accuracy: 0.9868\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0392 - accuracy: 0.9864\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0354 - accuracy: 0.9877\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0341 - accuracy: 0.9880\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0385 - accuracy: 0.9868\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0363 - accuracy: 0.9871\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0328 - accuracy: 0.9884\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0295 - accuracy: 0.9891\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0304 - accuracy: 0.9903\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0305 - accuracy: 0.9896\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0310 - accuracy: 0.9893\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0297 - accuracy: 0.9899\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0287 - accuracy: 0.9908\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0303 - accuracy: 0.9898\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0334 - accuracy: 0.9888\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0316 - accuracy: 0.9888\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0272 - accuracy: 0.9904\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0242 - accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0308 - accuracy: 0.9890\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0255 - accuracy: 0.9908\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0282 - accuracy: 0.9901\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0292 - accuracy: 0.9898\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0322 - accuracy: 0.9892\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0331 - accuracy: 0.9884\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1718 - accuracy: 0.9398\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1487 - accuracy: 0.9504\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1439 - accuracy: 0.9529\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1356 - accuracy: 0.9538\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.1260 - accuracy: 0.9565\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.1278 - accuracy: 0.9559\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.1250 - accuracy: 0.9589\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.1176 - accuracy: 0.9603\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.1140 - accuracy: 0.9621\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.1107 - accuracy: 0.9634\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.0914 - accuracy: 0.9700\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.0833 - accuracy: 0.9710\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0765 - accuracy: 0.9746\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0771 - accuracy: 0.9748\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0711 - accuracy: 0.9752\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0715 - accuracy: 0.9762\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0655 - accuracy: 0.9777\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0672 - accuracy: 0.9771\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0640 - accuracy: 0.9785\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.0626 - accuracy: 0.9789\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0609 - accuracy: 0.9799\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0583 - accuracy: 0.9811\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.0569 - accuracy: 0.9802\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0542 - accuracy: 0.9817\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0585 - accuracy: 0.9804\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.0503 - accuracy: 0.9838\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0528 - accuracy: 0.9811\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0489 - accuracy: 0.9834\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0510 - accuracy: 0.9815\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0482 - accuracy: 0.9824\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0462 - accuracy: 0.9837\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0480 - accuracy: 0.9829\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0406 - accuracy: 0.9856\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0442 - accuracy: 0.9854\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0434 - accuracy: 0.9848\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0452 - accuracy: 0.9843\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0462 - accuracy: 0.9838\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0416 - accuracy: 0.9861\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0397 - accuracy: 0.9856\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0415 - accuracy: 0.9858\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0395 - accuracy: 0.9865\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0377 - accuracy: 0.9868\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0380 - accuracy: 0.9875\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0418 - accuracy: 0.9859\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0414 - accuracy: 0.9845\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0392 - accuracy: 0.9858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0364 - accuracy: 0.9868\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0386 - accuracy: 0.9872\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0396 - accuracy: 0.9868\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0352 - accuracy: 0.9878\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.0341 - accuracy: 0.9875\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0304 - accuracy: 0.9893\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0311 - accuracy: 0.9884\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0369 - accuracy: 0.9865\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0313 - accuracy: 0.9895\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0340 - accuracy: 0.9889\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0308 - accuracy: 0.9893\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0310 - accuracy: 0.9891\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0290 - accuracy: 0.9895\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0286 - accuracy: 0.9900\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0277 - accuracy: 0.9899\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.0279 - accuracy: 0.9893\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0278 - accuracy: 0.9894\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0292 - accuracy: 0.9896\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0289 - accuracy: 0.9902\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0268 - accuracy: 0.9908\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0295 - accuracy: 0.9900\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0267 - accuracy: 0.9904\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0269 - accuracy: 0.9913\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0269 - accuracy: 0.9911\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0250 - accuracy: 0.9911\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0272 - accuracy: 0.9908\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0246 - accuracy: 0.9922\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0262 - accuracy: 0.9916\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0256 - accuracy: 0.9910\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0240 - accuracy: 0.9917\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0228 - accuracy: 0.9919\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0267 - accuracy: 0.9916\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0254 - accuracy: 0.9913\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0238 - accuracy: 0.9913\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0246 - accuracy: 0.9925\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0250 - accuracy: 0.9923\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0231 - accuracy: 0.9910\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0233 - accuracy: 0.9915\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0204 - accuracy: 0.9930\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0230 - accuracy: 0.9919\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.0244 - accuracy: 0.9921\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0211 - accuracy: 0.9925\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0214 - accuracy: 0.9929\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0239 - accuracy: 0.9919\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0258 - accuracy: 0.9911\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0243 - accuracy: 0.9921\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0211 - accuracy: 0.9929\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0232 - accuracy: 0.9921\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0235 - accuracy: 0.9921\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0175 - accuracy: 0.9941\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0195 - accuracy: 0.9935\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0199 - accuracy: 0.9930\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0207 - accuracy: 0.9930\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0208 - accuracy: 0.9931\n",
      "5512/5512 [==============================] - 1s 95us/sample - loss: 0.2338 - accuracy: 0.9481\n",
      "Test_Accuracy: 94.81%\n",
      "5512/5512 [==============================] - 0s 77us/sample - loss: 0.2338 - accuracy: 0.9481\n",
      "4410/4410 [==============================] - 0s 74us/sample - loss: 0.1803 - accuracy: 0.9517\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.5886 - accuracy: 0.7406\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.2889 - accuracy: 0.8929\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.2382 - accuracy: 0.9128\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.2147 - accuracy: 0.9227\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.2030 - accuracy: 0.9275\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.1926 - accuracy: 0.9317\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.1870 - accuracy: 0.9346\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.1793 - accuracy: 0.9380\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.1754 - accuracy: 0.9401\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.1699 - accuracy: 0.9403\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.1607 - accuracy: 0.9468\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.1563 - accuracy: 0.9476\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.1543 - accuracy: 0.9459\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.1465 - accuracy: 0.9503\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.1461 - accuracy: 0.9493\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.1382 - accuracy: 0.9529\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.1361 - accuracy: 0.9543\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.1293 - accuracy: 0.9561\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.1307 - accuracy: 0.9561\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.1261 - accuracy: 0.9563\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.1263 - accuracy: 0.9569\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.1224 - accuracy: 0.9584\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.1202 - accuracy: 0.9591\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.1186 - accuracy: 0.9594\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.1177 - accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.1155 - accuracy: 0.9593\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.1107 - accuracy: 0.9618\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.1063 - accuracy: 0.9642\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.1051 - accuracy: 0.9639\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.1018 - accuracy: 0.9659\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.1017 - accuracy: 0.9646\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22046/22046 - 3s - loss: 0.1018 - accuracy: 0.9647\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.0950 - accuracy: 0.9669\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.0980 - accuracy: 0.9655\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.0916 - accuracy: 0.9687\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.0910 - accuracy: 0.9687\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.0878 - accuracy: 0.9709\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.0881 - accuracy: 0.9696\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.0849 - accuracy: 0.9710\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.0860 - accuracy: 0.9692\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.0843 - accuracy: 0.9708\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.0806 - accuracy: 0.9710\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.0756 - accuracy: 0.9730\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.0783 - accuracy: 0.9725\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.0764 - accuracy: 0.9723\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.0739 - accuracy: 0.9735\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.0780 - accuracy: 0.9723\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.0713 - accuracy: 0.9751\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0700 - accuracy: 0.9756\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0759 - accuracy: 0.9736\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0699 - accuracy: 0.9751\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.0708 - accuracy: 0.9751\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0671 - accuracy: 0.9758\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.0667 - accuracy: 0.9756\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.0652 - accuracy: 0.9781\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0656 - accuracy: 0.9765\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.0607 - accuracy: 0.9781\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0615 - accuracy: 0.9796\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0657 - accuracy: 0.9769\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0665 - accuracy: 0.9764\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.0619 - accuracy: 0.9784\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0576 - accuracy: 0.9800\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0571 - accuracy: 0.9796\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0586 - accuracy: 0.9792\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0570 - accuracy: 0.9814\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0544 - accuracy: 0.9824\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0594 - accuracy: 0.9787\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0573 - accuracy: 0.9796\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0552 - accuracy: 0.9795\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0582 - accuracy: 0.9801\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0562 - accuracy: 0.9809\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0524 - accuracy: 0.9805\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0547 - accuracy: 0.9823\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0550 - accuracy: 0.9812\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0499 - accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0555 - accuracy: 0.9813\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0561 - accuracy: 0.9802\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0525 - accuracy: 0.9814\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0482 - accuracy: 0.9821\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0502 - accuracy: 0.9826\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0489 - accuracy: 0.9834\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0469 - accuracy: 0.9836\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0522 - accuracy: 0.9821\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0475 - accuracy: 0.9841\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0491 - accuracy: 0.9830\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0474 - accuracy: 0.9834\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0445 - accuracy: 0.9841\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0411 - accuracy: 0.9851\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0465 - accuracy: 0.9851\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0483 - accuracy: 0.9830\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0445 - accuracy: 0.9846\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0553 - accuracy: 0.9801\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0537 - accuracy: 0.9816\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0457 - accuracy: 0.9835\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0478 - accuracy: 0.9833\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0426 - accuracy: 0.9856\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0397 - accuracy: 0.9862\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0446 - accuracy: 0.9848\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0425 - accuracy: 0.9856\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0424 - accuracy: 0.9858\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 4s - loss: 0.1657 - accuracy: 0.9445\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1559 - accuracy: 0.9495\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1579 - accuracy: 0.9475\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1617 - accuracy: 0.9474\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.1609 - accuracy: 0.9454\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.1413 - accuracy: 0.9512\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.1370 - accuracy: 0.9528\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.1436 - accuracy: 0.9503\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.1296 - accuracy: 0.9566\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.1256 - accuracy: 0.9596\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.1079 - accuracy: 0.9635\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.1011 - accuracy: 0.9666\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.0992 - accuracy: 0.9671\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.0951 - accuracy: 0.9683\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.0941 - accuracy: 0.9669\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.0882 - accuracy: 0.9709\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.0883 - accuracy: 0.9704\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.0874 - accuracy: 0.9712\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.0868 - accuracy: 0.9695\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.0777 - accuracy: 0.9744\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.0828 - accuracy: 0.9713\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.0772 - accuracy: 0.9742\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.0766 - accuracy: 0.9735\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.0753 - accuracy: 0.9739\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.0770 - accuracy: 0.9735\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.0754 - accuracy: 0.9753\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.0744 - accuracy: 0.9745\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.0726 - accuracy: 0.9757\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.0732 - accuracy: 0.9764\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.0661 - accuracy: 0.9765\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0677 - accuracy: 0.9773\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0677 - accuracy: 0.9762\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.0632 - accuracy: 0.9789\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0677 - accuracy: 0.9768\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0622 - accuracy: 0.9784\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0632 - accuracy: 0.9773\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0612 - accuracy: 0.9804\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0627 - accuracy: 0.9787\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0626 - accuracy: 0.9777\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0606 - accuracy: 0.9790\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0600 - accuracy: 0.9800\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0592 - accuracy: 0.9790\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0568 - accuracy: 0.9799\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0580 - accuracy: 0.9801\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0555 - accuracy: 0.9804\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0557 - accuracy: 0.9808\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0565 - accuracy: 0.9817\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0501 - accuracy: 0.9829\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0534 - accuracy: 0.9816\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0529 - accuracy: 0.9823\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.0499 - accuracy: 0.9823\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0509 - accuracy: 0.9828\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0490 - accuracy: 0.9837\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0510 - accuracy: 0.9821\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0494 - accuracy: 0.9833\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0569 - accuracy: 0.9803\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0466 - accuracy: 0.9839\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0495 - accuracy: 0.9827\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0476 - accuracy: 0.9825\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0472 - accuracy: 0.9839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0489 - accuracy: 0.9840\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.0435 - accuracy: 0.9852\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0423 - accuracy: 0.9851\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0439 - accuracy: 0.9850\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0427 - accuracy: 0.9847\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0441 - accuracy: 0.9857\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0434 - accuracy: 0.9851\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0445 - accuracy: 0.9854\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0427 - accuracy: 0.9861\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0452 - accuracy: 0.9848\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0409 - accuracy: 0.9860\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0369 - accuracy: 0.9885\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0380 - accuracy: 0.9860\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0411 - accuracy: 0.9863\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0388 - accuracy: 0.9870\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0389 - accuracy: 0.9867\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0393 - accuracy: 0.9872\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0374 - accuracy: 0.9875\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0394 - accuracy: 0.9864\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0385 - accuracy: 0.9865\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0388 - accuracy: 0.9859\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0448 - accuracy: 0.9843\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0452 - accuracy: 0.9839\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0388 - accuracy: 0.9869\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0394 - accuracy: 0.9854\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0359 - accuracy: 0.9875\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.0370 - accuracy: 0.9870\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0354 - accuracy: 0.9877\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0372 - accuracy: 0.9879\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0351 - accuracy: 0.9880\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0349 - accuracy: 0.9880\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0355 - accuracy: 0.9866\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0364 - accuracy: 0.9885\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0356 - accuracy: 0.9879\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0340 - accuracy: 0.9885\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0366 - accuracy: 0.9874\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0355 - accuracy: 0.9884\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0341 - accuracy: 0.9887\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0322 - accuracy: 0.9891\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0314 - accuracy: 0.9884\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.2040 - accuracy: 0.9548\n",
      "Test_Accuracy: 95.48%\n",
      "5512/5512 [==============================] - 0s 75us/sample - loss: 0.2040 - accuracy: 0.9548\n",
      "4410/4410 [==============================] - 0s 78us/sample - loss: 0.1644 - accuracy: 0.9567\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.6776 - accuracy: 0.6857\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.3418 - accuracy: 0.8688\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.2747 - accuracy: 0.8960\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.2423 - accuracy: 0.9120\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.2246 - accuracy: 0.9184\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.2151 - accuracy: 0.9233\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.2054 - accuracy: 0.9274\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.1959 - accuracy: 0.9313\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.1929 - accuracy: 0.9323\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.1889 - accuracy: 0.9348\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.1868 - accuracy: 0.9357\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.1837 - accuracy: 0.9356\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.1808 - accuracy: 0.9382\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.1720 - accuracy: 0.9402\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.1694 - accuracy: 0.9424\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.1625 - accuracy: 0.9445\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.1656 - accuracy: 0.9451\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.1614 - accuracy: 0.9447\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.1563 - accuracy: 0.9477\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.1623 - accuracy: 0.9445\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.1547 - accuracy: 0.9469\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.1480 - accuracy: 0.9495\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.1444 - accuracy: 0.9505\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.1412 - accuracy: 0.9527\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.1397 - accuracy: 0.9524\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.1408 - accuracy: 0.9515\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.1357 - accuracy: 0.9551\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.1328 - accuracy: 0.9560\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.1347 - accuracy: 0.9535\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.1332 - accuracy: 0.9557\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.1283 - accuracy: 0.9563\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.1292 - accuracy: 0.9561\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.1228 - accuracy: 0.9579\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.1245 - accuracy: 0.9586\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.1233 - accuracy: 0.9586\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.1202 - accuracy: 0.9596\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.1235 - accuracy: 0.9570\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.1181 - accuracy: 0.9591\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.1170 - accuracy: 0.9610\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.1191 - accuracy: 0.9594\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.1150 - accuracy: 0.9613\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.1128 - accuracy: 0.9613\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.1124 - accuracy: 0.9608\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.1087 - accuracy: 0.9624\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.1075 - accuracy: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.1051 - accuracy: 0.9642\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.1036 - accuracy: 0.9638\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.1054 - accuracy: 0.9643\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.0985 - accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.0998 - accuracy: 0.9650\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.0991 - accuracy: 0.9658\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.1010 - accuracy: 0.9654\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.0974 - accuracy: 0.9658\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.1115 - accuracy: 0.9622\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.1016 - accuracy: 0.9636\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.0995 - accuracy: 0.9658\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.1018 - accuracy: 0.9650\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.0969 - accuracy: 0.9662\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.0915 - accuracy: 0.9678\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.0919 - accuracy: 0.9683\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.1016 - accuracy: 0.9639\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.0899 - accuracy: 0.9693\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.0872 - accuracy: 0.9696\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.0884 - accuracy: 0.9692\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.0875 - accuracy: 0.9697\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.0895 - accuracy: 0.9700\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.0896 - accuracy: 0.9682\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.0882 - accuracy: 0.9691\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.0852 - accuracy: 0.9709\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.0833 - accuracy: 0.9702\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.0858 - accuracy: 0.9695\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.0859 - accuracy: 0.9705\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.0825 - accuracy: 0.9720\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.0804 - accuracy: 0.9725\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.0802 - accuracy: 0.9726\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.0772 - accuracy: 0.9734\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.0784 - accuracy: 0.9725\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.0770 - accuracy: 0.9722\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.0758 - accuracy: 0.9732\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.0796 - accuracy: 0.9735\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.0743 - accuracy: 0.9738\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.0715 - accuracy: 0.9752\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.0717 - accuracy: 0.9750\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.0744 - accuracy: 0.9736\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.0728 - accuracy: 0.9731\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.0763 - accuracy: 0.9750\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.0687 - accuracy: 0.9769\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.0688 - accuracy: 0.9764\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.0722 - accuracy: 0.9753\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.0683 - accuracy: 0.9759\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.0625 - accuracy: 0.9789\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0709 - accuracy: 0.9756\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.0680 - accuracy: 0.9760\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0700 - accuracy: 0.9754\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0697 - accuracy: 0.9754\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.0664 - accuracy: 0.9770\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0672 - accuracy: 0.9761\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.0675 - accuracy: 0.9768\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.0662 - accuracy: 0.9768\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0699 - accuracy: 0.9750\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.1882 - accuracy: 0.9381\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1936 - accuracy: 0.9363\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1800 - accuracy: 0.9402\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1758 - accuracy: 0.9414\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.1683 - accuracy: 0.9435\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.1610 - accuracy: 0.9478\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.1665 - accuracy: 0.9441\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.1644 - accuracy: 0.9438\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.1538 - accuracy: 0.9486\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.1619 - accuracy: 0.9448\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.1324 - accuracy: 0.9568\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.1276 - accuracy: 0.9573\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.1268 - accuracy: 0.9591\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.1197 - accuracy: 0.9605\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.1205 - accuracy: 0.9610\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.1174 - accuracy: 0.9614\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.1159 - accuracy: 0.9606\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.1185 - accuracy: 0.9604\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.1186 - accuracy: 0.9614\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.1139 - accuracy: 0.9630\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.1105 - accuracy: 0.9631\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.1108 - accuracy: 0.9623\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.1084 - accuracy: 0.9627\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.1058 - accuracy: 0.9635\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.1048 - accuracy: 0.9635\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.1038 - accuracy: 0.9650\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.1010 - accuracy: 0.9653\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.1024 - accuracy: 0.9659\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.1042 - accuracy: 0.9640\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.1001 - accuracy: 0.9665\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.0985 - accuracy: 0.9654\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.0972 - accuracy: 0.9683\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.1002 - accuracy: 0.9666\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.0990 - accuracy: 0.9652\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.0938 - accuracy: 0.9687\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.0951 - accuracy: 0.9685\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.0946 - accuracy: 0.9687\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.0927 - accuracy: 0.9690\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.0924 - accuracy: 0.9693\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.0933 - accuracy: 0.9681\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.0963 - accuracy: 0.9663\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.0928 - accuracy: 0.9680\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.0882 - accuracy: 0.9699\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.0912 - accuracy: 0.9682\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.0890 - accuracy: 0.9697\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.0897 - accuracy: 0.9680\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.0890 - accuracy: 0.9697\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.0899 - accuracy: 0.9697\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.0873 - accuracy: 0.9711\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.0847 - accuracy: 0.9706\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.0847 - accuracy: 0.9702\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.0847 - accuracy: 0.9710\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.0821 - accuracy: 0.9727\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.0834 - accuracy: 0.9711\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.0825 - accuracy: 0.9713\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.0859 - accuracy: 0.9702\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.0808 - accuracy: 0.9728\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.0819 - accuracy: 0.9722\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.0789 - accuracy: 0.9737\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.0786 - accuracy: 0.9744\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.0751 - accuracy: 0.9745\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.0741 - accuracy: 0.9741\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.0776 - accuracy: 0.9745\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.0767 - accuracy: 0.9731\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.0755 - accuracy: 0.9739\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.0743 - accuracy: 0.9728\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0805 - accuracy: 0.9740\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0801 - accuracy: 0.9727\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0766 - accuracy: 0.9725\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0737 - accuracy: 0.9740\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.0744 - accuracy: 0.9736\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.0772 - accuracy: 0.9736\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0710 - accuracy: 0.9759\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0731 - accuracy: 0.9747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0704 - accuracy: 0.9756\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0709 - accuracy: 0.9764\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0708 - accuracy: 0.9758\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0707 - accuracy: 0.9761\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0714 - accuracy: 0.9747\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0706 - accuracy: 0.9757\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0707 - accuracy: 0.9747\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0664 - accuracy: 0.9775\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0671 - accuracy: 0.9775\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0630 - accuracy: 0.9771\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0676 - accuracy: 0.9774\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0661 - accuracy: 0.9779\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.0710 - accuracy: 0.9761\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0678 - accuracy: 0.9769\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0682 - accuracy: 0.9757\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0658 - accuracy: 0.9761\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0650 - accuracy: 0.9761\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0634 - accuracy: 0.9790\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0641 - accuracy: 0.9768\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0577 - accuracy: 0.9800\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0663 - accuracy: 0.9773\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0682 - accuracy: 0.9754\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0633 - accuracy: 0.9786\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0629 - accuracy: 0.9781\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0629 - accuracy: 0.9787\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0613 - accuracy: 0.9781\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.2100 - accuracy: 0.9456\n",
      "Test_Accuracy: 94.56%\n",
      "5512/5512 [==============================] - 0s 75us/sample - loss: 0.2100 - accuracy: 0.9456\n",
      "4410/4410 [==============================] - 0s 74us/sample - loss: 0.1846 - accuracy: 0.9478\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.8206 - accuracy: 0.6005\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.4759 - accuracy: 0.7826\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.3073 - accuracy: 0.8839\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.2596 - accuracy: 0.9047\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.2398 - accuracy: 0.9139\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.2303 - accuracy: 0.9186\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.2168 - accuracy: 0.9238\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.2152 - accuracy: 0.9228\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.2078 - accuracy: 0.9267\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.1980 - accuracy: 0.9325\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.1938 - accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.1912 - accuracy: 0.9364\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.1855 - accuracy: 0.9380\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.1821 - accuracy: 0.9389\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.1800 - accuracy: 0.9406\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.1782 - accuracy: 0.9400\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.1750 - accuracy: 0.9418\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.1684 - accuracy: 0.9447\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.1682 - accuracy: 0.9457\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.1623 - accuracy: 0.9465\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.1619 - accuracy: 0.9471\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.1593 - accuracy: 0.9470\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.1574 - accuracy: 0.9482\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.1543 - accuracy: 0.9502\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.1550 - accuracy: 0.9497\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.1528 - accuracy: 0.9489\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.1544 - accuracy: 0.9502\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.1486 - accuracy: 0.9515\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.1488 - accuracy: 0.9518\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.1507 - accuracy: 0.9495\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.1498 - accuracy: 0.9526\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.1466 - accuracy: 0.9507\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.1443 - accuracy: 0.9523\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.1436 - accuracy: 0.9515\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.1418 - accuracy: 0.9524\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.1418 - accuracy: 0.9528\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.1375 - accuracy: 0.9543\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.1393 - accuracy: 0.9537\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.1380 - accuracy: 0.9548\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.1383 - accuracy: 0.9527\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.1358 - accuracy: 0.9551\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.1379 - accuracy: 0.9556\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.1361 - accuracy: 0.9560\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.1341 - accuracy: 0.9555\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.1321 - accuracy: 0.9558\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.1337 - accuracy: 0.9561\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.1309 - accuracy: 0.9563\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.1328 - accuracy: 0.9557\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.1304 - accuracy: 0.9566\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.1281 - accuracy: 0.9563\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.1280 - accuracy: 0.9590\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.1277 - accuracy: 0.9574\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.1282 - accuracy: 0.9575\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.1241 - accuracy: 0.9584\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.1254 - accuracy: 0.9589\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.1275 - accuracy: 0.9573\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.1227 - accuracy: 0.9594\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.1236 - accuracy: 0.9571\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.1235 - accuracy: 0.9596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.1226 - accuracy: 0.9600\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.1259 - accuracy: 0.9585\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.1154 - accuracy: 0.9617\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.1173 - accuracy: 0.9588\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.1166 - accuracy: 0.9596\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.1159 - accuracy: 0.9606\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.1178 - accuracy: 0.9609\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.1107 - accuracy: 0.9638\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.1188 - accuracy: 0.9605\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.1147 - accuracy: 0.9609\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.1152 - accuracy: 0.9610\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.1123 - accuracy: 0.9618\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.1154 - accuracy: 0.9615\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.1115 - accuracy: 0.9629\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.1087 - accuracy: 0.9631\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.1122 - accuracy: 0.9621\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.1119 - accuracy: 0.9612\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.1104 - accuracy: 0.9615\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.1071 - accuracy: 0.9629\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.1094 - accuracy: 0.9633\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.1068 - accuracy: 0.9633\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.1088 - accuracy: 0.9641\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.1066 - accuracy: 0.9641\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.1012 - accuracy: 0.9657\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.1022 - accuracy: 0.9645\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.1031 - accuracy: 0.9643\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.1018 - accuracy: 0.9653\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.1041 - accuracy: 0.9651\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.1016 - accuracy: 0.9672\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.1021 - accuracy: 0.9652\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.1017 - accuracy: 0.9650\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.1024 - accuracy: 0.9648\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.0990 - accuracy: 0.9659\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.1002 - accuracy: 0.9656\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.0949 - accuracy: 0.9671\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.0996 - accuracy: 0.9657\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.1034 - accuracy: 0.9659\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.0974 - accuracy: 0.9661\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.1008 - accuracy: 0.9648\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.1009 - accuracy: 0.9664\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.0954 - accuracy: 0.9670\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 4s - loss: 0.2001 - accuracy: 0.9322\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.1993 - accuracy: 0.9345\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.1834 - accuracy: 0.9403\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.1855 - accuracy: 0.9401\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.1886 - accuracy: 0.9384\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.1779 - accuracy: 0.9414\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.1736 - accuracy: 0.9431\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.1667 - accuracy: 0.9464\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.1607 - accuracy: 0.9452\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.1712 - accuracy: 0.9443\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.1499 - accuracy: 0.9523\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.1458 - accuracy: 0.9523\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.1413 - accuracy: 0.9535\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.1353 - accuracy: 0.9566\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.1375 - accuracy: 0.9553\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.1329 - accuracy: 0.9570\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.1293 - accuracy: 0.9577\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.1312 - accuracy: 0.9579\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.1285 - accuracy: 0.9579\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.1275 - accuracy: 0.9579\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.1267 - accuracy: 0.9578\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.1282 - accuracy: 0.9582\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.1291 - accuracy: 0.9573\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.1270 - accuracy: 0.9595\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.1204 - accuracy: 0.9604\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.1223 - accuracy: 0.9613\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.1209 - accuracy: 0.9614\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.1207 - accuracy: 0.9595\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.1186 - accuracy: 0.9615\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.1202 - accuracy: 0.9617\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.1189 - accuracy: 0.9607\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.1180 - accuracy: 0.9606\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.1179 - accuracy: 0.9604\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.1199 - accuracy: 0.9604\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.1148 - accuracy: 0.9631\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.1163 - accuracy: 0.9620\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.1107 - accuracy: 0.9643\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.1169 - accuracy: 0.9613\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.1138 - accuracy: 0.9631\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.1143 - accuracy: 0.9644\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.1125 - accuracy: 0.9620\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.1126 - accuracy: 0.9617\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.1113 - accuracy: 0.9619\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.1117 - accuracy: 0.9623\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.1100 - accuracy: 0.9634\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.1141 - accuracy: 0.9627\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.1094 - accuracy: 0.9642\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.1077 - accuracy: 0.9643\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.1094 - accuracy: 0.9638\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.1069 - accuracy: 0.9650\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.1071 - accuracy: 0.9646\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.1104 - accuracy: 0.9619\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.1084 - accuracy: 0.9645\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.1048 - accuracy: 0.9648\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.1092 - accuracy: 0.9645\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.1035 - accuracy: 0.9651\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.1023 - accuracy: 0.9646\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.1061 - accuracy: 0.9635\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.1032 - accuracy: 0.9643\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.1044 - accuracy: 0.9635\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.1083 - accuracy: 0.9647\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.1042 - accuracy: 0.9650\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.1030 - accuracy: 0.9656\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.1032 - accuracy: 0.9651\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.1006 - accuracy: 0.9647\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.1007 - accuracy: 0.9665\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.0992 - accuracy: 0.9656\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.0997 - accuracy: 0.9656\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.0974 - accuracy: 0.9652\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.0997 - accuracy: 0.9666\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.1027 - accuracy: 0.9648\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.1000 - accuracy: 0.9668\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.0959 - accuracy: 0.9674\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.0958 - accuracy: 0.9681\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.0955 - accuracy: 0.9685\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.0971 - accuracy: 0.9673\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.0992 - accuracy: 0.9681\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.0961 - accuracy: 0.9670\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.0939 - accuracy: 0.9663\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.0915 - accuracy: 0.9701\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.0918 - accuracy: 0.9677\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.0930 - accuracy: 0.9689\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.0938 - accuracy: 0.9677\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.0960 - accuracy: 0.9678\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.0931 - accuracy: 0.9684\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.0943 - accuracy: 0.9689\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.0908 - accuracy: 0.9694\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.0933 - accuracy: 0.9693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.0901 - accuracy: 0.9678\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.0960 - accuracy: 0.9669\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.0937 - accuracy: 0.9681\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.0915 - accuracy: 0.9685\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.0894 - accuracy: 0.9704\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.0882 - accuracy: 0.9697\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.0900 - accuracy: 0.9677\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.0877 - accuracy: 0.9699\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.0874 - accuracy: 0.9707\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.0914 - accuracy: 0.9694\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.0862 - accuracy: 0.9718\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.0873 - accuracy: 0.9697\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.1607 - accuracy: 0.9536\n",
      "Test_Accuracy: 95.36%\n",
      "5512/5512 [==============================] - 0s 77us/sample - loss: 0.1607 - accuracy: 0.9536\n",
      "4410/4410 [==============================] - 0s 77us/sample - loss: 0.1380 - accuracy: 0.9522\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.8706 - accuracy: 0.5905\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.5452 - accuracy: 0.7336\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.3649 - accuracy: 0.8595\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.3075 - accuracy: 0.8856\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.2725 - accuracy: 0.9014\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.2577 - accuracy: 0.9058\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.2426 - accuracy: 0.9139\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.2284 - accuracy: 0.9190\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.2258 - accuracy: 0.9208\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.2185 - accuracy: 0.9236\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.2136 - accuracy: 0.9262\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.2061 - accuracy: 0.9280\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.2001 - accuracy: 0.9318\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.1983 - accuracy: 0.9321\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.1955 - accuracy: 0.9342\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.1933 - accuracy: 0.9365\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.1896 - accuracy: 0.9378\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.1864 - accuracy: 0.9385\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.1879 - accuracy: 0.9381\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.1828 - accuracy: 0.9407\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.1865 - accuracy: 0.9392\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.1814 - accuracy: 0.9404\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.1739 - accuracy: 0.9435\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.1770 - accuracy: 0.9428\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.1760 - accuracy: 0.9427\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.1766 - accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.1757 - accuracy: 0.9425\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.1789 - accuracy: 0.9420\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.1779 - accuracy: 0.9431\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.1803 - accuracy: 0.9406\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.1756 - accuracy: 0.9416\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.1742 - accuracy: 0.9439\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.1656 - accuracy: 0.9472\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.1689 - accuracy: 0.9449\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.1680 - accuracy: 0.9470\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.1630 - accuracy: 0.9463\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.1664 - accuracy: 0.9474\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.1607 - accuracy: 0.9473\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.1674 - accuracy: 0.9458\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.1648 - accuracy: 0.9479\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.1639 - accuracy: 0.9477\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.1662 - accuracy: 0.9467\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.1614 - accuracy: 0.9499\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.1623 - accuracy: 0.9474\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.1626 - accuracy: 0.9481\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.1648 - accuracy: 0.9486\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.1589 - accuracy: 0.9505\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.1612 - accuracy: 0.9475\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.1635 - accuracy: 0.9487\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.1617 - accuracy: 0.9474\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.1568 - accuracy: 0.9487\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.1546 - accuracy: 0.9499\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.1549 - accuracy: 0.9501\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.1559 - accuracy: 0.9487\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.1529 - accuracy: 0.9512\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.1531 - accuracy: 0.9512\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.1558 - accuracy: 0.9490\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.1554 - accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.1530 - accuracy: 0.9506\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.1515 - accuracy: 0.9510\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.1519 - accuracy: 0.9515\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.1543 - accuracy: 0.9503\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.1512 - accuracy: 0.9523\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.1499 - accuracy: 0.9511\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.1523 - accuracy: 0.9495\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.1481 - accuracy: 0.9515\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.1504 - accuracy: 0.9520\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.1510 - accuracy: 0.9516\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.1473 - accuracy: 0.9520\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.1463 - accuracy: 0.9518\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.1440 - accuracy: 0.9518\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.1485 - accuracy: 0.9530\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.1476 - accuracy: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.1461 - accuracy: 0.9518\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.1469 - accuracy: 0.9532\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.1463 - accuracy: 0.9535\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.1449 - accuracy: 0.9532\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.1464 - accuracy: 0.9520\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.1422 - accuracy: 0.9538\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.1424 - accuracy: 0.9541\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.1434 - accuracy: 0.9539\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.1402 - accuracy: 0.9554\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.1447 - accuracy: 0.9538\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.1436 - accuracy: 0.9533\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.1427 - accuracy: 0.9547\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.1447 - accuracy: 0.9534\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.1393 - accuracy: 0.9552\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.1379 - accuracy: 0.9550\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.1381 - accuracy: 0.9548\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.1447 - accuracy: 0.9534\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.1389 - accuracy: 0.9547\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.1372 - accuracy: 0.9561\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.1347 - accuracy: 0.9560\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.1378 - accuracy: 0.9541\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.1373 - accuracy: 0.9543\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.1390 - accuracy: 0.9548\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.1359 - accuracy: 0.9556\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.1366 - accuracy: 0.9558\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.1362 - accuracy: 0.9553\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.1383 - accuracy: 0.9541\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.2194 - accuracy: 0.9262\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.2242 - accuracy: 0.9238\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.2156 - accuracy: 0.9274\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.2229 - accuracy: 0.9262\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.2142 - accuracy: 0.9267\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.1989 - accuracy: 0.9359\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.1969 - accuracy: 0.9348\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.1918 - accuracy: 0.9388\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.1893 - accuracy: 0.9383\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.1970 - accuracy: 0.9345\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.1758 - accuracy: 0.9442\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.1681 - accuracy: 0.9472\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.1686 - accuracy: 0.9458\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.1623 - accuracy: 0.9483\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.1613 - accuracy: 0.9490\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.1600 - accuracy: 0.9483\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.1551 - accuracy: 0.9500\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.1578 - accuracy: 0.9509\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.1534 - accuracy: 0.9520\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.1565 - accuracy: 0.9503\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.1546 - accuracy: 0.9505\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.1520 - accuracy: 0.9528\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.1481 - accuracy: 0.9522\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.1507 - accuracy: 0.9524\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.1460 - accuracy: 0.9540\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.1459 - accuracy: 0.9537\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.1492 - accuracy: 0.9532\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.1495 - accuracy: 0.9529\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.1457 - accuracy: 0.9524\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.1479 - accuracy: 0.9527\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.1477 - accuracy: 0.9531\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.1482 - accuracy: 0.9519\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.1485 - accuracy: 0.9519\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.1505 - accuracy: 0.9521\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.1456 - accuracy: 0.9549\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.1423 - accuracy: 0.9545\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.1417 - accuracy: 0.9537\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.1427 - accuracy: 0.9538\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.1412 - accuracy: 0.9549\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.1405 - accuracy: 0.9561\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.1420 - accuracy: 0.9544\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.1409 - accuracy: 0.9542\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.1373 - accuracy: 0.9566\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.1387 - accuracy: 0.9551\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.1427 - accuracy: 0.9531\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.1421 - accuracy: 0.9542\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.1403 - accuracy: 0.9540\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.1380 - accuracy: 0.9565\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.1386 - accuracy: 0.9561\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.1384 - accuracy: 0.9549\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.1369 - accuracy: 0.9558\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.1426 - accuracy: 0.9538\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.1368 - accuracy: 0.9554\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.1378 - accuracy: 0.9563\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.1369 - accuracy: 0.9572\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.1335 - accuracy: 0.9564\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.1398 - accuracy: 0.9546\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.1379 - accuracy: 0.9559\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.1331 - accuracy: 0.9568\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.1349 - accuracy: 0.9555\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.1354 - accuracy: 0.9562\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.1344 - accuracy: 0.9554\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.1303 - accuracy: 0.9572\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.1291 - accuracy: 0.9580\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.1325 - accuracy: 0.9574\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.1296 - accuracy: 0.9583\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.1359 - accuracy: 0.9559\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.1338 - accuracy: 0.9559\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.1310 - accuracy: 0.9557\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.1316 - accuracy: 0.9565\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.1297 - accuracy: 0.9575\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.1325 - accuracy: 0.9571\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.1326 - accuracy: 0.9555\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.1300 - accuracy: 0.9584\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.1271 - accuracy: 0.9592\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.1283 - accuracy: 0.9582\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.1277 - accuracy: 0.9580\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.1315 - accuracy: 0.9579\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.1294 - accuracy: 0.9577\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.1270 - accuracy: 0.9585\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.1284 - accuracy: 0.9568\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.1270 - accuracy: 0.9595\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.1259 - accuracy: 0.9586\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.1299 - accuracy: 0.9580\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.1293 - accuracy: 0.9570\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.1294 - accuracy: 0.9574\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.1300 - accuracy: 0.9564\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.1288 - accuracy: 0.9579\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.1230 - accuracy: 0.9591\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.1284 - accuracy: 0.9592\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.1276 - accuracy: 0.9578\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.1292 - accuracy: 0.9575\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.1280 - accuracy: 0.9581\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.1261 - accuracy: 0.9595\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.1259 - accuracy: 0.9582\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.1229 - accuracy: 0.9586\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.1234 - accuracy: 0.9592\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.1201 - accuracy: 0.9600\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.1245 - accuracy: 0.9578\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.1203 - accuracy: 0.9613\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.2013 - accuracy: 0.9318\n",
      "Test_Accuracy: 93.18%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5512/5512 [==============================] - 0s 75us/sample - loss: 0.2013 - accuracy: 0.9318\n",
      "4410/4410 [==============================] - 0s 76us/sample - loss: 0.1939 - accuracy: 0.9302\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 0.9457 - accuracy: 0.5626\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.5675 - accuracy: 0.7182\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.4034 - accuracy: 0.8326\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.3198 - accuracy: 0.8837\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.2912 - accuracy: 0.8939\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.2653 - accuracy: 0.9082\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.2547 - accuracy: 0.9126\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.2479 - accuracy: 0.9122\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.2405 - accuracy: 0.9145\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.2350 - accuracy: 0.9183\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.2318 - accuracy: 0.9183\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.2275 - accuracy: 0.9208\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.2264 - accuracy: 0.9209\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.2223 - accuracy: 0.9222\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.2181 - accuracy: 0.9259\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.2168 - accuracy: 0.9261\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.2083 - accuracy: 0.9291\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.2107 - accuracy: 0.9305\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.2067 - accuracy: 0.9328\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.2082 - accuracy: 0.9312\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.2026 - accuracy: 0.9349\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.1973 - accuracy: 0.9347\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.1957 - accuracy: 0.9370\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.1928 - accuracy: 0.9370\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.1923 - accuracy: 0.9386\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.1932 - accuracy: 0.9375\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.1937 - accuracy: 0.9389\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.1899 - accuracy: 0.9394\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.1866 - accuracy: 0.9411\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.1870 - accuracy: 0.9400\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.1866 - accuracy: 0.9411\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.1873 - accuracy: 0.9414\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.1875 - accuracy: 0.9411\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.1840 - accuracy: 0.9413\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.1834 - accuracy: 0.9418\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.1840 - accuracy: 0.9423\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.1806 - accuracy: 0.9435\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.1869 - accuracy: 0.9405\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.1812 - accuracy: 0.9420\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.1778 - accuracy: 0.9447\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.1784 - accuracy: 0.9445\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.1770 - accuracy: 0.9460\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.1792 - accuracy: 0.9440\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.1745 - accuracy: 0.9457\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.1783 - accuracy: 0.9443\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.1771 - accuracy: 0.9463\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.1769 - accuracy: 0.9432\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.1737 - accuracy: 0.9459\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.1742 - accuracy: 0.9457\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.1701 - accuracy: 0.9467\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.1712 - accuracy: 0.9462\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.1718 - accuracy: 0.9458\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.1712 - accuracy: 0.9476\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.1744 - accuracy: 0.9451\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.1708 - accuracy: 0.9468\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.1693 - accuracy: 0.9461\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.1682 - accuracy: 0.9473\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.1653 - accuracy: 0.9472\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.1659 - accuracy: 0.9471\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.1669 - accuracy: 0.9483\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.1666 - accuracy: 0.9458\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.1663 - accuracy: 0.9501\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.1698 - accuracy: 0.9470\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.1637 - accuracy: 0.9477\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.1662 - accuracy: 0.9482\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.1644 - accuracy: 0.9488\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.1615 - accuracy: 0.9506\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.1595 - accuracy: 0.9493\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.1619 - accuracy: 0.9493\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.1621 - accuracy: 0.9488\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.1627 - accuracy: 0.9485\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.1614 - accuracy: 0.9503\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.1614 - accuracy: 0.9493\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.1597 - accuracy: 0.9495\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.1582 - accuracy: 0.9509\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.1614 - accuracy: 0.9486\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.1574 - accuracy: 0.9498\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.1577 - accuracy: 0.9506\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.1593 - accuracy: 0.9498\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.1591 - accuracy: 0.9503\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.1560 - accuracy: 0.9507\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.1556 - accuracy: 0.9497\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.1580 - accuracy: 0.9496\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.1532 - accuracy: 0.9504\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.1532 - accuracy: 0.9509\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.1482 - accuracy: 0.9524\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22046/22046 - 3s - loss: 0.1568 - accuracy: 0.9497\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.1547 - accuracy: 0.9512\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.1567 - accuracy: 0.9502\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.1511 - accuracy: 0.9519\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.1532 - accuracy: 0.9518\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.1544 - accuracy: 0.9526\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.1549 - accuracy: 0.9513\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.1515 - accuracy: 0.9523\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.1544 - accuracy: 0.9522\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.1503 - accuracy: 0.9529\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.1514 - accuracy: 0.9514\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.1496 - accuracy: 0.9526\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.1487 - accuracy: 0.9523\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.1502 - accuracy: 0.9513\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 4s - loss: 0.2409 - accuracy: 0.9207\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.2375 - accuracy: 0.9240\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.2176 - accuracy: 0.9307\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.2420 - accuracy: 0.9190\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.2548 - accuracy: 0.9170\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.2266 - accuracy: 0.9280\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.2154 - accuracy: 0.9317\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.2123 - accuracy: 0.9343\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.2093 - accuracy: 0.9344\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.2061 - accuracy: 0.9351\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.1907 - accuracy: 0.9394\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.1872 - accuracy: 0.9396\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.1826 - accuracy: 0.9436\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.1834 - accuracy: 0.9426\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.1783 - accuracy: 0.9435\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.1778 - accuracy: 0.9444\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.1730 - accuracy: 0.9452\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.1773 - accuracy: 0.9447\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.1714 - accuracy: 0.9456\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.1727 - accuracy: 0.9451\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.1750 - accuracy: 0.9469\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.1730 - accuracy: 0.9450\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.1694 - accuracy: 0.9483\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.1696 - accuracy: 0.9464\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.1720 - accuracy: 0.9467\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.1683 - accuracy: 0.9474\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.1720 - accuracy: 0.9458\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.1712 - accuracy: 0.9469\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.1706 - accuracy: 0.9465\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.1690 - accuracy: 0.9477\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.1699 - accuracy: 0.9466\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.1656 - accuracy: 0.9481\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.1667 - accuracy: 0.9467\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.1661 - accuracy: 0.9494\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.1657 - accuracy: 0.9481\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.1647 - accuracy: 0.9473\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.1656 - accuracy: 0.9481\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.1624 - accuracy: 0.9496\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.1667 - accuracy: 0.9476\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.1675 - accuracy: 0.9478\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.1679 - accuracy: 0.9475\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.1663 - accuracy: 0.9487\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.1668 - accuracy: 0.9486\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.1620 - accuracy: 0.9477\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.1646 - accuracy: 0.9478\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.1635 - accuracy: 0.9477\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.1612 - accuracy: 0.9502\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.1655 - accuracy: 0.9481\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.1645 - accuracy: 0.9488\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.1630 - accuracy: 0.9494\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.1652 - accuracy: 0.9483\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.1620 - accuracy: 0.9493\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.1612 - accuracy: 0.9485\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.1623 - accuracy: 0.9492\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.1635 - accuracy: 0.9474\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.1658 - accuracy: 0.9482\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.1599 - accuracy: 0.9485\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.1601 - accuracy: 0.9488\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.1604 - accuracy: 0.9501\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.1602 - accuracy: 0.9502\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.1620 - accuracy: 0.9490\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.1594 - accuracy: 0.9492\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.1663 - accuracy: 0.9481\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.1589 - accuracy: 0.9511\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.1614 - accuracy: 0.9489\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.1602 - accuracy: 0.9496\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.1596 - accuracy: 0.9502\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.1601 - accuracy: 0.9511\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.1838 - accuracy: 0.9458\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.1647 - accuracy: 0.9500\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.1584 - accuracy: 0.9495\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.1578 - accuracy: 0.9513\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.1603 - accuracy: 0.9480\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.1610 - accuracy: 0.9502\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.1561 - accuracy: 0.9513\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.1583 - accuracy: 0.9502\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.1584 - accuracy: 0.9505\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.1585 - accuracy: 0.9508\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.1556 - accuracy: 0.9507\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.1588 - accuracy: 0.9518\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.1609 - accuracy: 0.9498\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.1583 - accuracy: 0.9500\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.1569 - accuracy: 0.9517\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.1573 - accuracy: 0.9493\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.1577 - accuracy: 0.9492\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.1594 - accuracy: 0.9502\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.1593 - accuracy: 0.9498\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.1535 - accuracy: 0.9516\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.1534 - accuracy: 0.9512\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.1528 - accuracy: 0.9508\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.1548 - accuracy: 0.9507\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.1540 - accuracy: 0.9511\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.1576 - accuracy: 0.9502\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.1556 - accuracy: 0.9497\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.1525 - accuracy: 0.9510\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.1589 - accuracy: 0.9495\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.1560 - accuracy: 0.9500\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.1573 - accuracy: 0.9495\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.1530 - accuracy: 0.9502\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.1578 - accuracy: 0.9523\n",
      "5512/5512 [==============================] - 1s 103us/sample - loss: 0.2678 - accuracy: 0.9078\n",
      "Test_Accuracy: 90.78%\n",
      "5512/5512 [==============================] - 0s 85us/sample - loss: 0.2678 - accuracy: 0.9078\n",
      "4410/4410 [==============================] - 0s 75us/sample - loss: 0.2732 - accuracy: 0.9063\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22046/22046 - 4s - loss: 1.0479 - accuracy: 0.5288\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.6638 - accuracy: 0.6193\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.5956 - accuracy: 0.6910\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.4787 - accuracy: 0.7906\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.3938 - accuracy: 0.8464\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.3405 - accuracy: 0.8766\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.3009 - accuracy: 0.8944\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.2772 - accuracy: 0.9016\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.2690 - accuracy: 0.9057\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.2586 - accuracy: 0.9096\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.2571 - accuracy: 0.9101\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.2490 - accuracy: 0.9131\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.2403 - accuracy: 0.9180\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.2384 - accuracy: 0.9172\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.2367 - accuracy: 0.9195\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.2330 - accuracy: 0.9185\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.2305 - accuracy: 0.9213\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.2299 - accuracy: 0.9232\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.2243 - accuracy: 0.9242\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.2227 - accuracy: 0.9262\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.2283 - accuracy: 0.9236\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.2234 - accuracy: 0.9257\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.2181 - accuracy: 0.9288\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.2157 - accuracy: 0.9280\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.2143 - accuracy: 0.9287\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.2197 - accuracy: 0.9270\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.2096 - accuracy: 0.9320\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.2122 - accuracy: 0.9299\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.2081 - accuracy: 0.9323\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.2111 - accuracy: 0.9329\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.2080 - accuracy: 0.9326\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.2082 - accuracy: 0.9326\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.2049 - accuracy: 0.9329\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.2080 - accuracy: 0.9292\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.2070 - accuracy: 0.9340\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.2039 - accuracy: 0.9339\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.2031 - accuracy: 0.9342\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.2057 - accuracy: 0.9333\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.2006 - accuracy: 0.9350\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.2009 - accuracy: 0.9359\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.2024 - accuracy: 0.9346\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.2004 - accuracy: 0.9369\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.1980 - accuracy: 0.9365\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.1981 - accuracy: 0.9381\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.1983 - accuracy: 0.9376\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.1968 - accuracy: 0.9374\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.1970 - accuracy: 0.9380\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.1980 - accuracy: 0.9379\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.1944 - accuracy: 0.9390\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.1944 - accuracy: 0.9370\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.1968 - accuracy: 0.9381\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.1965 - accuracy: 0.9376\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.1938 - accuracy: 0.9390\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.1928 - accuracy: 0.9381\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.1938 - accuracy: 0.9398\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.1926 - accuracy: 0.9394\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.1944 - accuracy: 0.9387\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.1948 - accuracy: 0.9403\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.1928 - accuracy: 0.9380\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.1924 - accuracy: 0.9402\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.1909 - accuracy: 0.9404\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.1900 - accuracy: 0.9396\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.1871 - accuracy: 0.9422\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.1891 - accuracy: 0.9410\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.1903 - accuracy: 0.9405\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.1862 - accuracy: 0.9409\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.1903 - accuracy: 0.9398\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.1873 - accuracy: 0.9420\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.1847 - accuracy: 0.9402\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.1842 - accuracy: 0.9413\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.1854 - accuracy: 0.9409\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.1849 - accuracy: 0.9415\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.1889 - accuracy: 0.9425\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.1864 - accuracy: 0.9426\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.1898 - accuracy: 0.9397\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.1846 - accuracy: 0.9417\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.1882 - accuracy: 0.9394\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.1860 - accuracy: 0.9433\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.1845 - accuracy: 0.9423\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.1809 - accuracy: 0.9438\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.1834 - accuracy: 0.9428\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.1864 - accuracy: 0.9410\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.1828 - accuracy: 0.9436\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.1826 - accuracy: 0.9433\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.1830 - accuracy: 0.9428\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.1805 - accuracy: 0.9433\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.1841 - accuracy: 0.9432\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.1833 - accuracy: 0.9433\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.1806 - accuracy: 0.9428\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.1840 - accuracy: 0.9414\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.1802 - accuracy: 0.9427\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.1792 - accuracy: 0.9428\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.1775 - accuracy: 0.9449\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.1828 - accuracy: 0.9433\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.1798 - accuracy: 0.9440\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.1792 - accuracy: 0.9437\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.1805 - accuracy: 0.9439\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.1853 - accuracy: 0.9417\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.1786 - accuracy: 0.9449\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.1773 - accuracy: 0.9449\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.2669 - accuracy: 0.9130\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.2517 - accuracy: 0.9178\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.2539 - accuracy: 0.9133\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.2533 - accuracy: 0.9134\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.2533 - accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.2489 - accuracy: 0.9149\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.2395 - accuracy: 0.9204\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.2424 - accuracy: 0.9183\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.2291 - accuracy: 0.9246\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.2280 - accuracy: 0.9248\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.2063 - accuracy: 0.9341\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.2090 - accuracy: 0.9326\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.2009 - accuracy: 0.9353\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.2022 - accuracy: 0.9353\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.1975 - accuracy: 0.9365\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.1929 - accuracy: 0.9377\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.1949 - accuracy: 0.9385\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.1923 - accuracy: 0.9387\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.1905 - accuracy: 0.9393\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.1890 - accuracy: 0.9395\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.1944 - accuracy: 0.9367\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.1867 - accuracy: 0.9406\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.1880 - accuracy: 0.9405\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.1863 - accuracy: 0.9412\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.1898 - accuracy: 0.9414\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.1862 - accuracy: 0.9399\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.1894 - accuracy: 0.9394\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.1896 - accuracy: 0.9422\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.1862 - accuracy: 0.9412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.1882 - accuracy: 0.9421\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.1847 - accuracy: 0.9422\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.1852 - accuracy: 0.9414\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.1877 - accuracy: 0.9404\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.1824 - accuracy: 0.9411\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.1856 - accuracy: 0.9438\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.1842 - accuracy: 0.9436\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.1808 - accuracy: 0.9423\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.1799 - accuracy: 0.9432\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.1845 - accuracy: 0.9422\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.1817 - accuracy: 0.9440\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.1792 - accuracy: 0.9434\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.1787 - accuracy: 0.9460\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.1802 - accuracy: 0.9434\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.1831 - accuracy: 0.9436\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.1821 - accuracy: 0.9435\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.1775 - accuracy: 0.9436\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.1780 - accuracy: 0.9461\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.1783 - accuracy: 0.9451\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.1777 - accuracy: 0.9440\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.1782 - accuracy: 0.9431\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.1767 - accuracy: 0.9442\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.1760 - accuracy: 0.9462\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.1750 - accuracy: 0.9460\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.1753 - accuracy: 0.9453\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.1779 - accuracy: 0.9455\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.1735 - accuracy: 0.9442\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.1744 - accuracy: 0.9453\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.1749 - accuracy: 0.9449\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.1787 - accuracy: 0.9435\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.1772 - accuracy: 0.9448\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.1772 - accuracy: 0.9441\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.1757 - accuracy: 0.9473\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.1774 - accuracy: 0.9449\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.1752 - accuracy: 0.9452\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.1744 - accuracy: 0.9453\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.1754 - accuracy: 0.9457\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.1740 - accuracy: 0.9451\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.1768 - accuracy: 0.9449\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.1734 - accuracy: 0.9452\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.1749 - accuracy: 0.9442\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.1727 - accuracy: 0.9468\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.1719 - accuracy: 0.9480\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.1725 - accuracy: 0.9456\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.1758 - accuracy: 0.9454\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.1722 - accuracy: 0.9465\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.1701 - accuracy: 0.9468\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.1711 - accuracy: 0.9478\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.1699 - accuracy: 0.9460\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.1736 - accuracy: 0.9476\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.1738 - accuracy: 0.9449\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.1685 - accuracy: 0.9478\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.1734 - accuracy: 0.9462\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.1709 - accuracy: 0.9472\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.1693 - accuracy: 0.9474\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.1700 - accuracy: 0.9475\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.1691 - accuracy: 0.9474\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.1712 - accuracy: 0.9463\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.1660 - accuracy: 0.9499\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.1673 - accuracy: 0.9469\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.1680 - accuracy: 0.9472\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.1691 - accuracy: 0.9474\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.1685 - accuracy: 0.9464\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.1721 - accuracy: 0.9468\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.1648 - accuracy: 0.9507\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.1666 - accuracy: 0.9469\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.1715 - accuracy: 0.9478\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.1681 - accuracy: 0.9484\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.1645 - accuracy: 0.9501\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.1676 - accuracy: 0.9481\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.1676 - accuracy: 0.9469\n",
      "5512/5512 [==============================] - 1s 106us/sample - loss: 0.3984 - accuracy: 0.8487\n",
      "Test_Accuracy: 84.87%\n",
      "5512/5512 [==============================] - 0s 75us/sample - loss: 0.3984 - accuracy: 0.8487\n",
      "4410/4410 [==============================] - 0s 76us/sample - loss: 0.4056 - accuracy: 0.8401\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 1.1689 - accuracy: 0.5080\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.7137 - accuracy: 0.5145\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.6930 - accuracy: 0.5417\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.6685 - accuracy: 0.5994\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.6511 - accuracy: 0.6306\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.6373 - accuracy: 0.6508\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.5834 - accuracy: 0.6970\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.5204 - accuracy: 0.7555\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.4314 - accuracy: 0.8210\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.3679 - accuracy: 0.8669\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.3419 - accuracy: 0.8804\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.3098 - accuracy: 0.8960\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.2980 - accuracy: 0.8998\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.2838 - accuracy: 0.9035\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.2817 - accuracy: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.2673 - accuracy: 0.9107\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.2781 - accuracy: 0.9032\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.2679 - accuracy: 0.9101\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.2703 - accuracy: 0.9100\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.2630 - accuracy: 0.9130\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.2568 - accuracy: 0.9138\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.2521 - accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.2501 - accuracy: 0.9167\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.2430 - accuracy: 0.9213\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.2450 - accuracy: 0.9207\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.2461 - accuracy: 0.9195\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.2409 - accuracy: 0.9205\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.2338 - accuracy: 0.9247\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.2433 - accuracy: 0.9203\n",
      "Epoch 30/100\n",
      "22046/22046 - 3s - loss: 0.2370 - accuracy: 0.9247\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.2381 - accuracy: 0.9218\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.2377 - accuracy: 0.9221\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.2338 - accuracy: 0.9250\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.2320 - accuracy: 0.9284\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.2375 - accuracy: 0.9242\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.2361 - accuracy: 0.9239\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.2325 - accuracy: 0.9269\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.2331 - accuracy: 0.9261\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.2342 - accuracy: 0.9275\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.2285 - accuracy: 0.9295\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.2350 - accuracy: 0.9275\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.2269 - accuracy: 0.9297\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.2321 - accuracy: 0.9269\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.2225 - accuracy: 0.9306\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.2220 - accuracy: 0.9331\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.2229 - accuracy: 0.9325\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.2261 - accuracy: 0.9317\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.2280 - accuracy: 0.9294\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.2204 - accuracy: 0.9314\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.2231 - accuracy: 0.9314\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.2188 - accuracy: 0.9321\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.2190 - accuracy: 0.9316\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.2226 - accuracy: 0.9333\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.2177 - accuracy: 0.9325\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.2273 - accuracy: 0.9309\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.2251 - accuracy: 0.9306\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.2169 - accuracy: 0.9332\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.2178 - accuracy: 0.9318\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.2204 - accuracy: 0.9329\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.2175 - accuracy: 0.9326\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.2218 - accuracy: 0.9314\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.2217 - accuracy: 0.9340\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.2166 - accuracy: 0.9338\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.2169 - accuracy: 0.9340\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.2165 - accuracy: 0.9336\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.2140 - accuracy: 0.9351\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.2177 - accuracy: 0.9335\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.2157 - accuracy: 0.9360\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.2159 - accuracy: 0.9338\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.2144 - accuracy: 0.9364\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.2104 - accuracy: 0.9364\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.2158 - accuracy: 0.9344\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.2131 - accuracy: 0.9372\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.2153 - accuracy: 0.9354\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.2162 - accuracy: 0.9339\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.2158 - accuracy: 0.9353\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.2100 - accuracy: 0.9366\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.2148 - accuracy: 0.9349\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.2147 - accuracy: 0.9344\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.2127 - accuracy: 0.9363\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.2161 - accuracy: 0.9368\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.2131 - accuracy: 0.9361\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.2145 - accuracy: 0.9364\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.2149 - accuracy: 0.9362\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.2052 - accuracy: 0.9386\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.2112 - accuracy: 0.9367\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.2115 - accuracy: 0.9367\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.2067 - accuracy: 0.9387\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.2118 - accuracy: 0.9373\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.2185 - accuracy: 0.9369\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.2103 - accuracy: 0.9363\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.2099 - accuracy: 0.9350\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.2109 - accuracy: 0.9374\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.2093 - accuracy: 0.9372\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.2117 - accuracy: 0.9367\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.2106 - accuracy: 0.9360\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.2106 - accuracy: 0.9361\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.2089 - accuracy: 0.9373\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.2129 - accuracy: 0.9353\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.2057 - accuracy: 0.9389\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.3035 - accuracy: 0.9013\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.2975 - accuracy: 0.9030\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.2963 - accuracy: 0.9060\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.2950 - accuracy: 0.9022\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.2776 - accuracy: 0.9103\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.2776 - accuracy: 0.9136\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.2766 - accuracy: 0.9109\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.2778 - accuracy: 0.9084\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.2754 - accuracy: 0.9163\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.2705 - accuracy: 0.9123\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 4s - loss: 0.2529 - accuracy: 0.9229\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.2400 - accuracy: 0.9278\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.2357 - accuracy: 0.9265\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.2297 - accuracy: 0.9282\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.2260 - accuracy: 0.9303\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.2248 - accuracy: 0.9299\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.2248 - accuracy: 0.9309\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.2280 - accuracy: 0.9300\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.2145 - accuracy: 0.9348\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.2186 - accuracy: 0.9329\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.2216 - accuracy: 0.9322\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.2159 - accuracy: 0.9338\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.2169 - accuracy: 0.9328\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.2129 - accuracy: 0.9339\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.2141 - accuracy: 0.9361\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.2219 - accuracy: 0.9320\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.2186 - accuracy: 0.9347\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.2141 - accuracy: 0.9339\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.2150 - accuracy: 0.9349\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.2169 - accuracy: 0.9333\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.2161 - accuracy: 0.9338\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.2135 - accuracy: 0.9345\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.2138 - accuracy: 0.9351\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.2141 - accuracy: 0.9343\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.2152 - accuracy: 0.9343\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.2128 - accuracy: 0.9350\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.2128 - accuracy: 0.9351\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.2128 - accuracy: 0.9346\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.2059 - accuracy: 0.9383\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.2098 - accuracy: 0.9357\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.2100 - accuracy: 0.9369\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.2174 - accuracy: 0.9355\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.2093 - accuracy: 0.9371\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.2108 - accuracy: 0.9356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.2159 - accuracy: 0.9347\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.2125 - accuracy: 0.9357\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.2084 - accuracy: 0.9376\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.2105 - accuracy: 0.9379\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.2099 - accuracy: 0.9348\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.2088 - accuracy: 0.9369\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.2065 - accuracy: 0.9376\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.2101 - accuracy: 0.9356\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.2098 - accuracy: 0.9366\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.2111 - accuracy: 0.9353\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.2117 - accuracy: 0.9370\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.2070 - accuracy: 0.9375\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.2087 - accuracy: 0.9367\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.2080 - accuracy: 0.9359\n",
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.2074 - accuracy: 0.9362\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.2122 - accuracy: 0.9356\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.2072 - accuracy: 0.9371\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.2087 - accuracy: 0.9362\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.2117 - accuracy: 0.9364\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.2056 - accuracy: 0.9382\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.2079 - accuracy: 0.9381\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.2094 - accuracy: 0.9371\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.2078 - accuracy: 0.9362\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.2088 - accuracy: 0.9365\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.2061 - accuracy: 0.9366\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.2057 - accuracy: 0.9383\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.2097 - accuracy: 0.9379\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.2086 - accuracy: 0.9390\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.2011 - accuracy: 0.9393\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.2087 - accuracy: 0.9359\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.2148 - accuracy: 0.9352\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.2042 - accuracy: 0.9379\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.2063 - accuracy: 0.9364\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.2071 - accuracy: 0.9367\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.2044 - accuracy: 0.9384\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.2041 - accuracy: 0.9370\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.2070 - accuracy: 0.9373\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.2070 - accuracy: 0.9374\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.2017 - accuracy: 0.9372\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.2076 - accuracy: 0.9381\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.2068 - accuracy: 0.9381\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.2050 - accuracy: 0.9381\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.2059 - accuracy: 0.9366\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.2004 - accuracy: 0.9386\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.2068 - accuracy: 0.9394\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.2083 - accuracy: 0.9373\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.2061 - accuracy: 0.9380\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.2057 - accuracy: 0.9385\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.2056 - accuracy: 0.9380\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.2061 - accuracy: 0.9371\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.2031 - accuracy: 0.9366\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.2029 - accuracy: 0.9385\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.2057 - accuracy: 0.9368\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.2094 - accuracy: 0.9364\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.2040 - accuracy: 0.9360\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.1996 - accuracy: 0.9401\n",
      "5512/5512 [==============================] - 1s 95us/sample - loss: 0.6996 - accuracy: 0.6214\n",
      "Test_Accuracy: 62.14%\n",
      "5512/5512 [==============================] - 0s 78us/sample - loss: 0.6996 - accuracy: 0.6214\n",
      "4410/4410 [==============================] - 0s 76us/sample - loss: 0.7068 - accuracy: 0.6227\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22046 samples\n",
      "Epoch 1/100\n",
      "22046/22046 - 4s - loss: 1.4792 - accuracy: 0.4976\n",
      "Epoch 2/100\n",
      "22046/22046 - 3s - loss: 0.7218 - accuracy: 0.5025\n",
      "Epoch 3/100\n",
      "22046/22046 - 3s - loss: 0.7092 - accuracy: 0.4993\n",
      "Epoch 4/100\n",
      "22046/22046 - 3s - loss: 0.7088 - accuracy: 0.4970\n",
      "Epoch 5/100\n",
      "22046/22046 - 3s - loss: 0.7081 - accuracy: 0.5052\n",
      "Epoch 6/100\n",
      "22046/22046 - 3s - loss: 0.7080 - accuracy: 0.5068\n",
      "Epoch 7/100\n",
      "22046/22046 - 3s - loss: 0.7092 - accuracy: 0.4925\n",
      "Epoch 8/100\n",
      "22046/22046 - 3s - loss: 0.7079 - accuracy: 0.5008\n",
      "Epoch 9/100\n",
      "22046/22046 - 3s - loss: 0.7087 - accuracy: 0.4981\n",
      "Epoch 10/100\n",
      "22046/22046 - 3s - loss: 0.7049 - accuracy: 0.5061\n",
      "Epoch 11/100\n",
      "22046/22046 - 3s - loss: 0.6925 - accuracy: 0.5389\n",
      "Epoch 12/100\n",
      "22046/22046 - 3s - loss: 0.6323 - accuracy: 0.6416\n",
      "Epoch 13/100\n",
      "22046/22046 - 3s - loss: 0.5809 - accuracy: 0.6993\n",
      "Epoch 14/100\n",
      "22046/22046 - 3s - loss: 0.5518 - accuracy: 0.7326\n",
      "Epoch 15/100\n",
      "22046/22046 - 3s - loss: 0.5209 - accuracy: 0.7598\n",
      "Epoch 16/100\n",
      "22046/22046 - 3s - loss: 0.4995 - accuracy: 0.7812\n",
      "Epoch 17/100\n",
      "22046/22046 - 3s - loss: 0.4798 - accuracy: 0.7994\n",
      "Epoch 18/100\n",
      "22046/22046 - 3s - loss: 0.4621 - accuracy: 0.8141\n",
      "Epoch 19/100\n",
      "22046/22046 - 3s - loss: 0.4430 - accuracy: 0.8264\n",
      "Epoch 20/100\n",
      "22046/22046 - 3s - loss: 0.4307 - accuracy: 0.8365\n",
      "Epoch 21/100\n",
      "22046/22046 - 3s - loss: 0.4212 - accuracy: 0.8405\n",
      "Epoch 22/100\n",
      "22046/22046 - 3s - loss: 0.4127 - accuracy: 0.8480\n",
      "Epoch 23/100\n",
      "22046/22046 - 3s - loss: 0.4068 - accuracy: 0.8518\n",
      "Epoch 24/100\n",
      "22046/22046 - 3s - loss: 0.4052 - accuracy: 0.8524\n",
      "Epoch 25/100\n",
      "22046/22046 - 3s - loss: 0.3999 - accuracy: 0.8575\n",
      "Epoch 26/100\n",
      "22046/22046 - 3s - loss: 0.3979 - accuracy: 0.8568\n",
      "Epoch 27/100\n",
      "22046/22046 - 3s - loss: 0.3887 - accuracy: 0.8615\n",
      "Epoch 28/100\n",
      "22046/22046 - 3s - loss: 0.3909 - accuracy: 0.8622\n",
      "Epoch 29/100\n",
      "22046/22046 - 3s - loss: 0.3816 - accuracy: 0.8660\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22046/22046 - 3s - loss: 0.3755 - accuracy: 0.8734\n",
      "Epoch 31/100\n",
      "22046/22046 - 3s - loss: 0.3721 - accuracy: 0.8690\n",
      "Epoch 32/100\n",
      "22046/22046 - 3s - loss: 0.3635 - accuracy: 0.8745\n",
      "Epoch 33/100\n",
      "22046/22046 - 3s - loss: 0.3649 - accuracy: 0.8775\n",
      "Epoch 34/100\n",
      "22046/22046 - 3s - loss: 0.3549 - accuracy: 0.8778\n",
      "Epoch 35/100\n",
      "22046/22046 - 3s - loss: 0.3516 - accuracy: 0.8830\n",
      "Epoch 36/100\n",
      "22046/22046 - 3s - loss: 0.3564 - accuracy: 0.8837\n",
      "Epoch 37/100\n",
      "22046/22046 - 3s - loss: 0.3473 - accuracy: 0.8834\n",
      "Epoch 38/100\n",
      "22046/22046 - 3s - loss: 0.3484 - accuracy: 0.8837\n",
      "Epoch 39/100\n",
      "22046/22046 - 3s - loss: 0.3452 - accuracy: 0.8843\n",
      "Epoch 40/100\n",
      "22046/22046 - 3s - loss: 0.3421 - accuracy: 0.8895\n",
      "Epoch 41/100\n",
      "22046/22046 - 3s - loss: 0.3427 - accuracy: 0.8862\n",
      "Epoch 42/100\n",
      "22046/22046 - 3s - loss: 0.3407 - accuracy: 0.8878\n",
      "Epoch 43/100\n",
      "22046/22046 - 3s - loss: 0.3338 - accuracy: 0.8888\n",
      "Epoch 44/100\n",
      "22046/22046 - 3s - loss: 0.3386 - accuracy: 0.8876\n",
      "Epoch 45/100\n",
      "22046/22046 - 3s - loss: 0.3428 - accuracy: 0.8868\n",
      "Epoch 46/100\n",
      "22046/22046 - 3s - loss: 0.3376 - accuracy: 0.8892\n",
      "Epoch 47/100\n",
      "22046/22046 - 3s - loss: 0.3340 - accuracy: 0.8898\n",
      "Epoch 48/100\n",
      "22046/22046 - 3s - loss: 0.3348 - accuracy: 0.8911\n",
      "Epoch 49/100\n",
      "22046/22046 - 3s - loss: 0.3395 - accuracy: 0.8881\n",
      "Epoch 50/100\n",
      "22046/22046 - 3s - loss: 0.3408 - accuracy: 0.8874\n",
      "Epoch 51/100\n",
      "22046/22046 - 3s - loss: 0.3307 - accuracy: 0.8917\n",
      "Epoch 52/100\n",
      "22046/22046 - 3s - loss: 0.3424 - accuracy: 0.8866\n",
      "Epoch 53/100\n",
      "22046/22046 - 3s - loss: 0.3334 - accuracy: 0.8929\n",
      "Epoch 54/100\n",
      "22046/22046 - 3s - loss: 0.3376 - accuracy: 0.8920\n",
      "Epoch 55/100\n",
      "22046/22046 - 3s - loss: 0.3416 - accuracy: 0.8902\n",
      "Epoch 56/100\n",
      "22046/22046 - 3s - loss: 0.3325 - accuracy: 0.8910\n",
      "Epoch 57/100\n",
      "22046/22046 - 3s - loss: 0.3215 - accuracy: 0.8958\n",
      "Epoch 58/100\n",
      "22046/22046 - 3s - loss: 0.3312 - accuracy: 0.8926\n",
      "Epoch 59/100\n",
      "22046/22046 - 3s - loss: 0.3318 - accuracy: 0.8935\n",
      "Epoch 60/100\n",
      "22046/22046 - 3s - loss: 0.3278 - accuracy: 0.8910\n",
      "Epoch 61/100\n",
      "22046/22046 - 3s - loss: 0.3317 - accuracy: 0.8920\n",
      "Epoch 62/100\n",
      "22046/22046 - 3s - loss: 0.3268 - accuracy: 0.8928\n",
      "Epoch 63/100\n",
      "22046/22046 - 3s - loss: 0.3302 - accuracy: 0.8951\n",
      "Epoch 64/100\n",
      "22046/22046 - 3s - loss: 0.3247 - accuracy: 0.8934\n",
      "Epoch 65/100\n",
      "22046/22046 - 3s - loss: 0.3245 - accuracy: 0.8959\n",
      "Epoch 66/100\n",
      "22046/22046 - 3s - loss: 0.3165 - accuracy: 0.8971\n",
      "Epoch 67/100\n",
      "22046/22046 - 3s - loss: 0.3293 - accuracy: 0.8962\n",
      "Epoch 68/100\n",
      "22046/22046 - 3s - loss: 0.3230 - accuracy: 0.8968\n",
      "Epoch 69/100\n",
      "22046/22046 - 3s - loss: 0.3277 - accuracy: 0.8925\n",
      "Epoch 70/100\n",
      "22046/22046 - 3s - loss: 0.3273 - accuracy: 0.8941\n",
      "Epoch 71/100\n",
      "22046/22046 - 3s - loss: 0.3322 - accuracy: 0.8908\n",
      "Epoch 72/100\n",
      "22046/22046 - 3s - loss: 0.3236 - accuracy: 0.8942\n",
      "Epoch 73/100\n",
      "22046/22046 - 3s - loss: 0.3217 - accuracy: 0.8945\n",
      "Epoch 74/100\n",
      "22046/22046 - 3s - loss: 0.3247 - accuracy: 0.8953\n",
      "Epoch 75/100\n",
      "22046/22046 - 3s - loss: 0.3266 - accuracy: 0.8934\n",
      "Epoch 76/100\n",
      "22046/22046 - 3s - loss: 0.3268 - accuracy: 0.8949\n",
      "Epoch 77/100\n",
      "22046/22046 - 3s - loss: 0.3310 - accuracy: 0.8925\n",
      "Epoch 78/100\n",
      "22046/22046 - 3s - loss: 0.3176 - accuracy: 0.8954\n",
      "Epoch 79/100\n",
      "22046/22046 - 3s - loss: 0.3205 - accuracy: 0.8968\n",
      "Epoch 80/100\n",
      "22046/22046 - 3s - loss: 0.3248 - accuracy: 0.8967\n",
      "Epoch 81/100\n",
      "22046/22046 - 3s - loss: 0.3191 - accuracy: 0.8973\n",
      "Epoch 82/100\n",
      "22046/22046 - 3s - loss: 0.3217 - accuracy: 0.8950\n",
      "Epoch 83/100\n",
      "22046/22046 - 3s - loss: 0.3190 - accuracy: 0.8978\n",
      "Epoch 84/100\n",
      "22046/22046 - 3s - loss: 0.3226 - accuracy: 0.8966\n",
      "Epoch 85/100\n",
      "22046/22046 - 3s - loss: 0.3155 - accuracy: 0.8998\n",
      "Epoch 86/100\n",
      "22046/22046 - 3s - loss: 0.3131 - accuracy: 0.8999\n",
      "Epoch 87/100\n",
      "22046/22046 - 3s - loss: 0.3176 - accuracy: 0.9016\n",
      "Epoch 88/100\n",
      "22046/22046 - 3s - loss: 0.3125 - accuracy: 0.8992\n",
      "Epoch 89/100\n",
      "22046/22046 - 3s - loss: 0.3103 - accuracy: 0.9027\n",
      "Epoch 90/100\n",
      "22046/22046 - 3s - loss: 0.3058 - accuracy: 0.8998\n",
      "Epoch 91/100\n",
      "22046/22046 - 3s - loss: 0.3113 - accuracy: 0.8991\n",
      "Epoch 92/100\n",
      "22046/22046 - 3s - loss: 0.3147 - accuracy: 0.8986\n",
      "Epoch 93/100\n",
      "22046/22046 - 3s - loss: 0.3133 - accuracy: 0.8999\n",
      "Epoch 94/100\n",
      "22046/22046 - 3s - loss: 0.3133 - accuracy: 0.9028\n",
      "Epoch 95/100\n",
      "22046/22046 - 3s - loss: 0.3081 - accuracy: 0.9023\n",
      "Epoch 96/100\n",
      "22046/22046 - 3s - loss: 0.3108 - accuracy: 0.9026\n",
      "Epoch 97/100\n",
      "22046/22046 - 3s - loss: 0.3162 - accuracy: 0.9005\n",
      "Epoch 98/100\n",
      "22046/22046 - 3s - loss: 0.3054 - accuracy: 0.9029\n",
      "Epoch 99/100\n",
      "22046/22046 - 3s - loss: 0.3085 - accuracy: 0.9008\n",
      "Epoch 100/100\n",
      "22046/22046 - 3s - loss: 0.3115 - accuracy: 0.9007\n",
      "Train on 17636 samples\n",
      "Epoch 1/10\n",
      "17636/17636 - 3s - loss: 0.4308 - accuracy: 0.8381\n",
      "Epoch 2/10\n",
      "17636/17636 - 3s - loss: 0.4067 - accuracy: 0.8544\n",
      "Epoch 3/10\n",
      "17636/17636 - 3s - loss: 0.3967 - accuracy: 0.8580\n",
      "Epoch 4/10\n",
      "17636/17636 - 3s - loss: 0.3983 - accuracy: 0.8560\n",
      "Epoch 5/10\n",
      "17636/17636 - 3s - loss: 0.3891 - accuracy: 0.8642\n",
      "Epoch 6/10\n",
      "17636/17636 - 3s - loss: 0.3804 - accuracy: 0.8660\n",
      "Epoch 7/10\n",
      "17636/17636 - 3s - loss: 0.3820 - accuracy: 0.8673\n",
      "Epoch 8/10\n",
      "17636/17636 - 3s - loss: 0.3742 - accuracy: 0.8746\n",
      "Epoch 9/10\n",
      "17636/17636 - 3s - loss: 0.3868 - accuracy: 0.8628\n",
      "Epoch 10/10\n",
      "17636/17636 - 3s - loss: 0.3751 - accuracy: 0.8671\n",
      "Train on 17636 samples\n",
      "Epoch 1/90\n",
      "17636/17636 - 3s - loss: 0.3458 - accuracy: 0.8913\n",
      "Epoch 2/90\n",
      "17636/17636 - 3s - loss: 0.3367 - accuracy: 0.8928\n",
      "Epoch 3/90\n",
      "17636/17636 - 3s - loss: 0.3249 - accuracy: 0.8965\n",
      "Epoch 4/90\n",
      "17636/17636 - 3s - loss: 0.3260 - accuracy: 0.8970\n",
      "Epoch 5/90\n",
      "17636/17636 - 3s - loss: 0.3175 - accuracy: 0.9004\n",
      "Epoch 6/90\n",
      "17636/17636 - 3s - loss: 0.3244 - accuracy: 0.8950\n",
      "Epoch 7/90\n",
      "17636/17636 - 3s - loss: 0.3215 - accuracy: 0.8987\n",
      "Epoch 8/90\n",
      "17636/17636 - 3s - loss: 0.3090 - accuracy: 0.8980\n",
      "Epoch 9/90\n",
      "17636/17636 - 3s - loss: 0.3174 - accuracy: 0.8993\n",
      "Epoch 10/90\n",
      "17636/17636 - 3s - loss: 0.3094 - accuracy: 0.9002\n",
      "Epoch 11/90\n",
      "17636/17636 - 3s - loss: 0.3017 - accuracy: 0.9015\n",
      "Epoch 12/90\n",
      "17636/17636 - 3s - loss: 0.3065 - accuracy: 0.9018\n",
      "Epoch 13/90\n",
      "17636/17636 - 3s - loss: 0.3109 - accuracy: 0.9021\n",
      "Epoch 14/90\n",
      "17636/17636 - 3s - loss: 0.3130 - accuracy: 0.9035\n",
      "Epoch 15/90\n",
      "17636/17636 - 3s - loss: 0.3099 - accuracy: 0.9020\n",
      "Epoch 16/90\n",
      "17636/17636 - 3s - loss: 0.3171 - accuracy: 0.8999\n",
      "Epoch 17/90\n",
      "17636/17636 - 3s - loss: 0.3060 - accuracy: 0.9028\n",
      "Epoch 18/90\n",
      "17636/17636 - 3s - loss: 0.3075 - accuracy: 0.9024\n",
      "Epoch 19/90\n",
      "17636/17636 - 3s - loss: 0.3104 - accuracy: 0.9015\n",
      "Epoch 20/90\n",
      "17636/17636 - 3s - loss: 0.3060 - accuracy: 0.9037\n",
      "Epoch 21/90\n",
      "17636/17636 - 3s - loss: 0.3073 - accuracy: 0.9016\n",
      "Epoch 22/90\n",
      "17636/17636 - 3s - loss: 0.3136 - accuracy: 0.9034\n",
      "Epoch 23/90\n",
      "17636/17636 - 3s - loss: 0.3087 - accuracy: 0.9016\n",
      "Epoch 24/90\n",
      "17636/17636 - 3s - loss: 0.3018 - accuracy: 0.9031\n",
      "Epoch 25/90\n",
      "17636/17636 - 3s - loss: 0.3006 - accuracy: 0.9046\n",
      "Epoch 26/90\n",
      "17636/17636 - 3s - loss: 0.3076 - accuracy: 0.9030\n",
      "Epoch 27/90\n",
      "17636/17636 - 3s - loss: 0.3009 - accuracy: 0.9021\n",
      "Epoch 28/90\n",
      "17636/17636 - 3s - loss: 0.3140 - accuracy: 0.9040\n",
      "Epoch 29/90\n",
      "17636/17636 - 3s - loss: 0.3033 - accuracy: 0.9034\n",
      "Epoch 30/90\n",
      "17636/17636 - 3s - loss: 0.3027 - accuracy: 0.9043\n",
      "Epoch 31/90\n",
      "17636/17636 - 3s - loss: 0.3031 - accuracy: 0.9049\n",
      "Epoch 32/90\n",
      "17636/17636 - 3s - loss: 0.3015 - accuracy: 0.9044\n",
      "Epoch 33/90\n",
      "17636/17636 - 3s - loss: 0.2961 - accuracy: 0.9060\n",
      "Epoch 34/90\n",
      "17636/17636 - 3s - loss: 0.3040 - accuracy: 0.9048\n",
      "Epoch 35/90\n",
      "17636/17636 - 3s - loss: 0.3049 - accuracy: 0.9052\n",
      "Epoch 36/90\n",
      "17636/17636 - 3s - loss: 0.3081 - accuracy: 0.9052\n",
      "Epoch 37/90\n",
      "17636/17636 - 3s - loss: 0.3047 - accuracy: 0.9070\n",
      "Epoch 38/90\n",
      "17636/17636 - 3s - loss: 0.3049 - accuracy: 0.9036\n",
      "Epoch 39/90\n",
      "17636/17636 - 3s - loss: 0.3030 - accuracy: 0.9039\n",
      "Epoch 40/90\n",
      "17636/17636 - 3s - loss: 0.3014 - accuracy: 0.9044\n",
      "Epoch 41/90\n",
      "17636/17636 - 3s - loss: 0.2918 - accuracy: 0.9088\n",
      "Epoch 42/90\n",
      "17636/17636 - 3s - loss: 0.2999 - accuracy: 0.9047\n",
      "Epoch 43/90\n",
      "17636/17636 - 3s - loss: 0.2955 - accuracy: 0.9058\n",
      "Epoch 44/90\n",
      "17636/17636 - 3s - loss: 0.3035 - accuracy: 0.9055\n",
      "Epoch 45/90\n",
      "17636/17636 - 3s - loss: 0.2972 - accuracy: 0.9078\n",
      "Epoch 46/90\n",
      "17636/17636 - 3s - loss: 0.2974 - accuracy: 0.9068\n",
      "Epoch 47/90\n",
      "17636/17636 - 3s - loss: 0.3045 - accuracy: 0.9032\n",
      "Epoch 48/90\n",
      "17636/17636 - 3s - loss: 0.3033 - accuracy: 0.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/90\n",
      "17636/17636 - 3s - loss: 0.2969 - accuracy: 0.9053\n",
      "Epoch 50/90\n",
      "17636/17636 - 3s - loss: 0.2981 - accuracy: 0.9073\n",
      "Epoch 51/90\n",
      "17636/17636 - 3s - loss: 0.2979 - accuracy: 0.9087\n",
      "Epoch 52/90\n",
      "17636/17636 - 3s - loss: 0.3049 - accuracy: 0.9042\n",
      "Epoch 53/90\n",
      "17636/17636 - 3s - loss: 0.2907 - accuracy: 0.9072\n",
      "Epoch 54/90\n",
      "17636/17636 - 3s - loss: 0.2961 - accuracy: 0.9089\n",
      "Epoch 55/90\n",
      "17636/17636 - 3s - loss: 0.2969 - accuracy: 0.9075\n",
      "Epoch 56/90\n",
      "17636/17636 - 3s - loss: 0.3034 - accuracy: 0.9056\n",
      "Epoch 57/90\n",
      "17636/17636 - 3s - loss: 0.3034 - accuracy: 0.9044\n",
      "Epoch 58/90\n",
      "17636/17636 - 3s - loss: 0.3017 - accuracy: 0.9067\n",
      "Epoch 59/90\n",
      "17636/17636 - 3s - loss: 0.2935 - accuracy: 0.9083\n",
      "Epoch 60/90\n",
      "17636/17636 - 3s - loss: 0.2990 - accuracy: 0.9081\n",
      "Epoch 61/90\n",
      "17636/17636 - 3s - loss: 0.2963 - accuracy: 0.9086\n",
      "Epoch 62/90\n",
      "17636/17636 - 3s - loss: 0.2921 - accuracy: 0.9085\n",
      "Epoch 63/90\n",
      "17636/17636 - 3s - loss: 0.2867 - accuracy: 0.9094\n",
      "Epoch 64/90\n",
      "17636/17636 - 3s - loss: 0.2994 - accuracy: 0.9071\n",
      "Epoch 65/90\n",
      "17636/17636 - 3s - loss: 0.2990 - accuracy: 0.9068\n",
      "Epoch 66/90\n",
      "17636/17636 - 3s - loss: 0.2994 - accuracy: 0.9044\n",
      "Epoch 67/90\n",
      "17636/17636 - 3s - loss: 0.2962 - accuracy: 0.9079\n",
      "Epoch 68/90\n",
      "17636/17636 - 3s - loss: 0.2962 - accuracy: 0.9041\n",
      "Epoch 69/90\n",
      "17636/17636 - 3s - loss: 0.3008 - accuracy: 0.9076\n",
      "Epoch 70/90\n",
      "17636/17636 - 3s - loss: 0.2899 - accuracy: 0.9079\n",
      "Epoch 71/90\n",
      "17636/17636 - 3s - loss: 0.2984 - accuracy: 0.9070\n",
      "Epoch 72/90\n",
      "17636/17636 - 3s - loss: 0.2877 - accuracy: 0.9092\n",
      "Epoch 73/90\n",
      "17636/17636 - 3s - loss: 0.2892 - accuracy: 0.9076\n",
      "Epoch 74/90\n",
      "17636/17636 - 3s - loss: 0.2896 - accuracy: 0.9089\n",
      "Epoch 75/90\n",
      "17636/17636 - 3s - loss: 0.2959 - accuracy: 0.9085\n",
      "Epoch 76/90\n",
      "17636/17636 - 3s - loss: 0.2920 - accuracy: 0.9068\n",
      "Epoch 77/90\n",
      "17636/17636 - 3s - loss: 0.3010 - accuracy: 0.9065\n",
      "Epoch 78/90\n",
      "17636/17636 - 3s - loss: 0.2896 - accuracy: 0.9081\n",
      "Epoch 79/90\n",
      "17636/17636 - 3s - loss: 0.2951 - accuracy: 0.9069\n",
      "Epoch 80/90\n",
      "17636/17636 - 3s - loss: 0.2957 - accuracy: 0.9067\n",
      "Epoch 81/90\n",
      "17636/17636 - 3s - loss: 0.2981 - accuracy: 0.9064\n",
      "Epoch 82/90\n",
      "17636/17636 - 3s - loss: 0.2939 - accuracy: 0.9074\n",
      "Epoch 83/90\n",
      "17636/17636 - 3s - loss: 0.2882 - accuracy: 0.9102\n",
      "Epoch 84/90\n",
      "17636/17636 - 3s - loss: 0.3003 - accuracy: 0.9070\n",
      "Epoch 85/90\n",
      "17636/17636 - 3s - loss: 0.2975 - accuracy: 0.9068\n",
      "Epoch 86/90\n",
      "17636/17636 - 3s - loss: 0.3036 - accuracy: 0.9062\n",
      "Epoch 87/90\n",
      "17636/17636 - 3s - loss: 0.2943 - accuracy: 0.9071\n",
      "Epoch 88/90\n",
      "17636/17636 - 3s - loss: 0.2871 - accuracy: 0.9100\n",
      "Epoch 89/90\n",
      "17636/17636 - 3s - loss: 0.2936 - accuracy: 0.9066\n",
      "Epoch 90/90\n",
      "17636/17636 - 3s - loss: 0.2980 - accuracy: 0.9060\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.9724 - accuracy: 0.4875\n",
      "Test_Accuracy: 48.75%\n",
      "5512/5512 [==============================] - 0s 76us/sample - loss: 0.9724 - accuracy: 0.4875\n",
      "4410/4410 [==============================] - 0s 76us/sample - loss: 0.9541 - accuracy: 0.5009\n"
     ]
    }
   ],
   "source": [
    "#regulization_list = [0, 0.0000000001, 0.000000001, 0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1,10]\n",
    "dropout_list = np.arange(0,1,0.05)\n",
    "# probability axis values \n",
    "prob = []\n",
    "# loss axis values \n",
    "loss = []\n",
    "loss_valid = []\n",
    "history = []\n",
    "history_ddl = []\n",
    "for i in dropout_list:\n",
    "    classifier = tf.keras.Sequential()\n",
    "    classifier.add(Convolution2D(32, (3, 3), input_shape = (SIZE, SIZE, 3), activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\n",
    "    classifier.add(BatchNormalization(axis = -1))\n",
    "    classifier.add(Dropout(i))\n",
    "    classifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\n",
    "    classifier.add(BatchNormalization(axis = -1))\n",
    "    classifier.add(Dropout(i))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(  activation = 'relu', units=512))\n",
    "    classifier.add(BatchNormalization(axis = -1))\n",
    "    classifier.add(Dropout(i))\n",
    "    classifier.add(Dense( activation = 'relu', units=256))\n",
    "    classifier.add(BatchNormalization(axis = -1))\n",
    "    classifier.add(Dropout(i))\n",
    "    classifier.add(Dense(activation = 'sigmoid', units=2))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    print(classifier.summary())\n",
    "    \n",
    "    opt1 = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    \n",
    "    history.append( classifier.fit(np.array(x_train), \n",
    "                         y_train, \n",
    "                         batch_size = 64, \n",
    "                         verbose = 2, \n",
    "                         epochs = 100, \n",
    "                         validation_split = 0,\n",
    "                         shuffle = False))\n",
    "    \n",
    "    classifier.compile(optimizer = opt1, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    history_ddl.append(classifier.fit(np.array(x_train_ddl), \n",
    "                         y_train_ddl, \n",
    "                         batch_size = 64, \n",
    "                         verbose = 2, \n",
    "                         epochs = 10, \n",
    "                         validation_split = 0,\n",
    "                         shuffle = False))\n",
    "    \n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    history_ddl.append(classifier.fit(np.array(x_train_ddl), \n",
    "                         y_train_ddl, \n",
    "                         batch_size = 64, \n",
    "                         verbose = 2, \n",
    "                         epochs = 90, \n",
    "                         validation_split = 0,\n",
    "                         shuffle = False))\n",
    "\n",
    "    print(\"Test_Accuracy: {:.2f}%\".format(classifier.evaluate(np.array(x_test), np.array(y_test))[1]*100))\n",
    "    loss.append(classifier.evaluate(np.array(x_test), np.array(y_test))[0])\n",
    "    loss_valid.append(classifier.evaluate(np.array( x_validate_ddl), np.array( y_validate_ddl))[0])\n",
    "   # print(classifier.evaluate(np.array(x_test), np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pygL8qKhY7Qh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8119747349993536, 0.6242696954266276, 0.5571881031668515, 0.5904983920952368, 0.48016685016823496, 0.40384472893737383, 0.3838563253274741, 0.3589152513609017, 0.33530619757359187, 0.3923213223193256, 0.23435328397457184, 0.2337525154199351, 0.20399826747724847, 0.21000733408882283, 0.16066424313970504, 0.2013226959784076, 0.2677756637464587, 0.3984359386437863, 0.69957963492943, 0.9724144558429026]\n",
      "[0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "val_loss = []\n",
    "train_loss = []\n",
    "print(dropout_list)\n",
    "print()\n",
    "for i in history:\n",
    "    train_loss.append(i.history['loss'][99])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9500000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'dropout rate')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dropout_list, loss,'o-',label='test_loss')\n",
    "print(dropout_list[19])\n",
    "plt.plot(dropout_list, train_loss,'x-',label='train_loss')\n",
    "plt.plot(dropout_list, loss_valid,'*-',label='val loss')\n",
    "plt.legend()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('dropout rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EE496_Malaria_Deteection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
