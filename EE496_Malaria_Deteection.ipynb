{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVi1d71PgYYW"
   },
   "source": [
    "This is the KERAS CNN implementation for the MALARIA CELL IMAGES DATASET\n",
    "\n",
    "Breakdown of this notebook:\n",
    "\n",
    "Loading the dataset: Load the data and import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QtfOemEYgPwh",
    "outputId": "83392fec-23c6-47a5-c14c-516368524e62"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# For CNN model creation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxHah_83jLly"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 34CD-A57C\n",
      "\n",
      " Directory of C:\\SPB_Data\\ee496\n",
      "\n",
      "04/10/2020  08:41 AM    <DIR>          .\n",
      "04/10/2020  08:41 AM    <DIR>          ..\n",
      "04/10/2020  08:41 AM    <DIR>          .ipynb_checkpoints\n",
      "04/07/2020  05:26 PM    <DIR>          cell_images\n",
      "04/10/2020  08:41 AM           115,486 EE496_Malaria_Deteection-Copy1.ipynb\n",
      "04/10/2020  08:41 AM           115,486 EE496_Malaria_Deteection.ipynb\n",
      "               2 File(s)        230,972 bytes\n",
      "               4 Dir(s)  173,270,511,616 bytes free\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!dir\n",
    "os.path.isdir('.\\\\cell_images\\\\cell_images\\\\Parasitized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRgyHuQhk893"
   },
   "outputs": [],
   "source": [
    "infected = os.listdir('.\\\\cell_images\\\\cell_images\\\\Parasitized') \n",
    "uninfected = os.listdir('.\\\\cell_images\\\\cell_images\\\\Uninfected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "X-t95fumlkiG",
    "outputId": "f9ea2b8a-eee2-4ca5-dce1-83668f36eb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in infected:\n",
    "    try:\n",
    "    \n",
    "        image = cv2.imread(\".\\\\cell_images\\\\cell_images\\\\Parasitized\\\\\"+i)\n",
    "        image_array = Image.fromarray(image , 'RGB')\n",
    "        resize_img = image_array.resize((64 , 64))\n",
    "        data.append(np.array(resize_img))\n",
    "        label = to_categorical(1, num_classes=2)\n",
    "        labels.append(label)\n",
    "        \n",
    "    except AttributeError:\n",
    "        print('')\n",
    "    \n",
    "for u in uninfected:\n",
    "    try:\n",
    "        \n",
    "        image = cv2.imread(\".\\\\cell_images\\\\cell_images\\\\Uninfected\\\\\"+u)\n",
    "        image_array = Image.fromarray(image , 'RGB')\n",
    "        resize_img = image_array.resize((64 , 64))\n",
    "        data.append(np.array(resize_img))\n",
    "        label = to_categorical(0, num_classes=2)\n",
    "        labels.append(label)\n",
    "        \n",
    "    except AttributeError:\n",
    "        print('')\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "WSB6IS52HFcg",
    "outputId": "671fa62b-31f5-48cf-d1ca-4246d13b8b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BXEHl8GQhXDJ",
    "outputId": "0f1f5312-4c06-42a6-baf9-5b52d9c6bf79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22046, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "  x_train, x_test = train_test_split(data, test_size=0.2, random_state=1,shuffle = True)\n",
    "  y_train, y_test = train_test_split(labels, test_size=0.2, random_state=1)\n",
    "  print(np.array(x_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n-oXJVMrhrea",
    "outputId": "a8e7d519-f81d-4822-a800-ad9af1198f3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 6s - loss: 0.4037 - accuracy: 0.8191 - val_loss: 1.5383 - val_accuracy: 0.7705\n",
      "Epoch 2/30\n",
      "19841/19841 - 3s - loss: 0.2157 - accuracy: 0.9176 - val_loss: 0.2294 - val_accuracy: 0.9197\n",
      "Epoch 3/30\n",
      "19841/19841 - 3s - loss: 0.1826 - accuracy: 0.9288 - val_loss: 0.2150 - val_accuracy: 0.9220\n",
      "Epoch 4/30\n",
      "19841/19841 - 3s - loss: 0.1648 - accuracy: 0.9369 - val_loss: 0.1945 - val_accuracy: 0.9279\n",
      "Epoch 5/30\n",
      "19841/19841 - 3s - loss: 0.1459 - accuracy: 0.9437 - val_loss: 0.1742 - val_accuracy: 0.9424\n",
      "Epoch 6/30\n",
      "19841/19841 - 3s - loss: 0.1276 - accuracy: 0.9502 - val_loss: 0.1711 - val_accuracy: 0.9438\n",
      "Epoch 7/30\n",
      "19841/19841 - 3s - loss: 0.1129 - accuracy: 0.9544 - val_loss: 0.1794 - val_accuracy: 0.9406\n",
      "Epoch 8/30\n",
      "19841/19841 - 3s - loss: 0.0987 - accuracy: 0.9606 - val_loss: 0.6142 - val_accuracy: 0.7769\n",
      "Epoch 9/30\n",
      "19841/19841 - 3s - loss: 0.0881 - accuracy: 0.9651 - val_loss: 0.1614 - val_accuracy: 0.9510\n",
      "Epoch 10/30\n",
      "19841/19841 - 3s - loss: 0.0765 - accuracy: 0.9690 - val_loss: 0.1924 - val_accuracy: 0.9442\n",
      "Epoch 11/30\n",
      "19841/19841 - 3s - loss: 0.0675 - accuracy: 0.9725 - val_loss: 0.2268 - val_accuracy: 0.9488\n",
      "Epoch 12/30\n",
      "19841/19841 - 3s - loss: 0.0600 - accuracy: 0.9747 - val_loss: 0.1768 - val_accuracy: 0.9465\n",
      "Epoch 13/30\n",
      "19841/19841 - 3s - loss: 0.0535 - accuracy: 0.9775 - val_loss: 0.1998 - val_accuracy: 0.9338\n",
      "Epoch 14/30\n",
      "19841/19841 - 3s - loss: 0.0500 - accuracy: 0.9789 - val_loss: 0.2081 - val_accuracy: 0.9560\n",
      "Epoch 15/30\n",
      "19841/19841 - 3s - loss: 0.0384 - accuracy: 0.9828 - val_loss: 0.3137 - val_accuracy: 0.9256\n",
      "Epoch 16/30\n",
      "19841/19841 - 3s - loss: 0.0396 - accuracy: 0.9829 - val_loss: 0.2319 - val_accuracy: 0.9515\n",
      "Epoch 17/30\n",
      "19841/19841 - 3s - loss: 0.0328 - accuracy: 0.9852 - val_loss: 0.2125 - val_accuracy: 0.9551\n",
      "Epoch 18/30\n",
      "19841/19841 - 3s - loss: 0.0283 - accuracy: 0.9877 - val_loss: 0.2160 - val_accuracy: 0.9510\n",
      "Epoch 19/30\n",
      "19841/19841 - 3s - loss: 0.0294 - accuracy: 0.9865 - val_loss: 0.1749 - val_accuracy: 0.9596\n",
      "Epoch 20/30\n",
      "19841/19841 - 3s - loss: 0.0252 - accuracy: 0.9890 - val_loss: 0.2034 - val_accuracy: 0.9447\n",
      "Epoch 21/30\n",
      "19841/19841 - 3s - loss: 0.0247 - accuracy: 0.9893 - val_loss: 0.1981 - val_accuracy: 0.9551\n",
      "Epoch 22/30\n",
      "19841/19841 - 3s - loss: 0.0244 - accuracy: 0.9902 - val_loss: 0.2982 - val_accuracy: 0.9011\n",
      "Epoch 23/30\n",
      "19841/19841 - 3s - loss: 0.0296 - accuracy: 0.9883 - val_loss: 0.2243 - val_accuracy: 0.9519\n",
      "Epoch 24/30\n",
      "19841/19841 - 3s - loss: 0.0190 - accuracy: 0.9917 - val_loss: 0.2196 - val_accuracy: 0.9492\n",
      "Epoch 25/30\n",
      "19841/19841 - 3s - loss: 0.0155 - accuracy: 0.9933 - val_loss: 0.3014 - val_accuracy: 0.9424\n",
      "Epoch 26/30\n",
      "19841/19841 - 3s - loss: 0.0188 - accuracy: 0.9921 - val_loss: 0.4049 - val_accuracy: 0.8825\n",
      "Epoch 27/30\n",
      "19841/19841 - 3s - loss: 0.0180 - accuracy: 0.9925 - val_loss: 0.2188 - val_accuracy: 0.9560\n",
      "Epoch 28/30\n",
      "19841/19841 - 3s - loss: 0.0165 - accuracy: 0.9931 - val_loss: 0.2309 - val_accuracy: 0.9451\n",
      "Epoch 29/30\n",
      "19841/19841 - 3s - loss: 0.0124 - accuracy: 0.9946 - val_loss: 0.2085 - val_accuracy: 0.9596\n",
      "Epoch 30/30\n",
      "19841/19841 - 3s - loss: 0.0159 - accuracy: 0.9935 - val_loss: 0.2133 - val_accuracy: 0.9578\n",
      "5512/5512 [==============================] - 1s 102us/sample - loss: 0.2457 - accuracy: 0.9528\n",
      "Test_Accuracy: 95.28%\n",
      "5512/5512 [==============================] - 0s 89us/sample - loss: 0.2457 - accuracy: 0.9528\n",
      "5512/5512 [==============================] - 0s 90us/sample - loss: 0.2457 - accuracy: 0.9528\n",
      "[0.24569157453476728, 0.9528302]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 0.4341 - accuracy: 0.7987 - val_loss: 4.1040 - val_accuracy: 0.5773\n",
      "Epoch 2/30\n",
      "19841/19841 - 3s - loss: 0.2238 - accuracy: 0.9161 - val_loss: 0.3544 - val_accuracy: 0.9016\n",
      "Epoch 3/30\n",
      "19841/19841 - 3s - loss: 0.1827 - accuracy: 0.9334 - val_loss: 0.2037 - val_accuracy: 0.9306\n",
      "Epoch 4/30\n",
      "19841/19841 - 3s - loss: 0.1612 - accuracy: 0.9402 - val_loss: 0.2382 - val_accuracy: 0.9166\n",
      "Epoch 5/30\n",
      "19841/19841 - 3s - loss: 0.1469 - accuracy: 0.9446 - val_loss: 0.3154 - val_accuracy: 0.8531\n",
      "Epoch 6/30\n",
      "19841/19841 - 3s - loss: 0.1334 - accuracy: 0.9491 - val_loss: 0.1949 - val_accuracy: 0.9388\n",
      "Epoch 7/30\n",
      "19841/19841 - 3s - loss: 0.1140 - accuracy: 0.9552 - val_loss: 0.2019 - val_accuracy: 0.9383\n",
      "Epoch 8/30\n",
      "19841/19841 - 3s - loss: 0.0978 - accuracy: 0.9611 - val_loss: 0.1819 - val_accuracy: 0.9429\n",
      "Epoch 9/30\n",
      "19841/19841 - 3s - loss: 0.0824 - accuracy: 0.9661 - val_loss: 0.2737 - val_accuracy: 0.8807\n",
      "Epoch 10/30\n",
      "19841/19841 - 3s - loss: 0.0738 - accuracy: 0.9703 - val_loss: 0.1756 - val_accuracy: 0.9524\n",
      "Epoch 11/30\n",
      "19841/19841 - 3s - loss: 0.0668 - accuracy: 0.9720 - val_loss: 0.2236 - val_accuracy: 0.9247\n",
      "Epoch 12/30\n",
      "19841/19841 - 3s - loss: 0.0597 - accuracy: 0.9741 - val_loss: 0.2315 - val_accuracy: 0.9451\n",
      "Epoch 13/30\n",
      "19841/19841 - 3s - loss: 0.0518 - accuracy: 0.9772 - val_loss: 0.2542 - val_accuracy: 0.9451\n",
      "Epoch 14/30\n",
      "19841/19841 - 3s - loss: 0.0477 - accuracy: 0.9790 - val_loss: 0.5904 - val_accuracy: 0.8798\n",
      "Epoch 15/30\n",
      "19841/19841 - 3s - loss: 0.0402 - accuracy: 0.9825 - val_loss: 0.3068 - val_accuracy: 0.8912\n",
      "Epoch 16/30\n",
      "19841/19841 - 3s - loss: 0.0427 - accuracy: 0.9823 - val_loss: 0.2841 - val_accuracy: 0.9406\n",
      "Epoch 17/30\n",
      "19841/19841 - 3s - loss: 0.0350 - accuracy: 0.9841 - val_loss: 0.2244 - val_accuracy: 0.9478\n",
      "Epoch 18/30\n",
      "19841/19841 - 3s - loss: 0.0376 - accuracy: 0.9834 - val_loss: 0.2742 - val_accuracy: 0.9401\n",
      "Epoch 19/30\n",
      "19841/19841 - 3s - loss: 0.0290 - accuracy: 0.9859 - val_loss: 0.2172 - val_accuracy: 0.9542\n",
      "Epoch 20/30\n",
      "19841/19841 - 3s - loss: 0.0252 - accuracy: 0.9887 - val_loss: 0.3449 - val_accuracy: 0.8844\n",
      "Epoch 21/30\n",
      "19841/19841 - 3s - loss: 0.0281 - accuracy: 0.9873 - val_loss: 1.1418 - val_accuracy: 0.5773\n",
      "Epoch 22/30\n",
      "19841/19841 - 3s - loss: 0.0205 - accuracy: 0.9904 - val_loss: 0.2833 - val_accuracy: 0.9410\n",
      "Epoch 23/30\n",
      "19841/19841 - 3s - loss: 0.0249 - accuracy: 0.9900 - val_loss: 0.2153 - val_accuracy: 0.9497\n",
      "Epoch 24/30\n",
      "19841/19841 - 3s - loss: 0.0257 - accuracy: 0.9891 - val_loss: 0.4473 - val_accuracy: 0.9229\n",
      "Epoch 25/30\n",
      "19841/19841 - 3s - loss: 0.0183 - accuracy: 0.9914 - val_loss: 0.2541 - val_accuracy: 0.9515\n",
      "Epoch 26/30\n",
      "19841/19841 - 3s - loss: 0.0185 - accuracy: 0.9919 - val_loss: 0.2252 - val_accuracy: 0.9506\n",
      "Epoch 27/30\n",
      "19841/19841 - 3s - loss: 0.0189 - accuracy: 0.9918 - val_loss: 0.3004 - val_accuracy: 0.9211\n",
      "Epoch 28/30\n",
      "19841/19841 - 3s - loss: 0.0218 - accuracy: 0.9911 - val_loss: 0.2269 - val_accuracy: 0.9501\n",
      "Epoch 29/30\n",
      "19841/19841 - 3s - loss: 0.0138 - accuracy: 0.9939 - val_loss: 0.2497 - val_accuracy: 0.9478\n",
      "Epoch 30/30\n",
      "19841/19841 - 3s - loss: 0.0131 - accuracy: 0.9941 - val_loss: 0.2337 - val_accuracy: 0.9506\n",
      "5512/5512 [==============================] - 1s 95us/sample - loss: 0.2967 - accuracy: 0.9443\n",
      "Test_Accuracy: 94.43%\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.2967 - accuracy: 0.9443\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.2967 - accuracy: 0.9443\n",
      "[0.29668290945005177, 0.94430333]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 0.3772 - accuracy: 0.8383 - val_loss: 0.3200 - val_accuracy: 0.8925\n",
      "Epoch 2/30\n",
      "19841/19841 - 3s - loss: 0.2080 - accuracy: 0.9238 - val_loss: 0.3559 - val_accuracy: 0.8848\n",
      "Epoch 3/30\n",
      "19841/19841 - 3s - loss: 0.1699 - accuracy: 0.9369 - val_loss: 0.1944 - val_accuracy: 0.9315\n",
      "Epoch 4/30\n",
      "19841/19841 - 3s - loss: 0.1453 - accuracy: 0.9454 - val_loss: 0.2097 - val_accuracy: 0.9197\n",
      "Epoch 5/30\n",
      "19841/19841 - 3s - loss: 0.1265 - accuracy: 0.9533 - val_loss: 0.1608 - val_accuracy: 0.9478\n",
      "Epoch 6/30\n",
      "19841/19841 - 3s - loss: 0.1071 - accuracy: 0.9590 - val_loss: 0.1645 - val_accuracy: 0.9442\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 0.0962 - accuracy: 0.9620 - val_loss: 0.1576 - val_accuracy: 0.9492\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 0.0939 - accuracy: 0.9637 - val_loss: 0.1621 - val_accuracy: 0.9438\n",
      "Epoch 9/30\n",
      "19841/19841 - 3s - loss: 0.0758 - accuracy: 0.9699 - val_loss: 0.2089 - val_accuracy: 0.9397\n",
      "Epoch 10/30\n",
      "19841/19841 - 3s - loss: 0.0712 - accuracy: 0.9710 - val_loss: 0.1619 - val_accuracy: 0.9510\n",
      "Epoch 11/30\n",
      "19841/19841 - 4s - loss: 0.0622 - accuracy: 0.9754 - val_loss: 0.2927 - val_accuracy: 0.9420\n",
      "Epoch 12/30\n",
      "19841/19841 - 3s - loss: 0.0521 - accuracy: 0.9784 - val_loss: 0.2097 - val_accuracy: 0.9506\n",
      "Epoch 13/30\n",
      "19841/19841 - 3s - loss: 0.0457 - accuracy: 0.9816 - val_loss: 0.1934 - val_accuracy: 0.9492\n",
      "Epoch 14/30\n",
      "19841/19841 - 3s - loss: 0.0417 - accuracy: 0.9837 - val_loss: 0.2260 - val_accuracy: 0.9451\n",
      "Epoch 15/30\n",
      "19841/19841 - 3s - loss: 0.0379 - accuracy: 0.9837 - val_loss: 0.2301 - val_accuracy: 0.9351\n",
      "Epoch 16/30\n",
      "19841/19841 - 3s - loss: 0.0358 - accuracy: 0.9849 - val_loss: 0.2201 - val_accuracy: 0.9510\n",
      "Epoch 17/30\n",
      "19841/19841 - 3s - loss: 0.0334 - accuracy: 0.9863 - val_loss: 0.2004 - val_accuracy: 0.9528\n",
      "Epoch 18/30\n",
      "19841/19841 - 3s - loss: 0.0248 - accuracy: 0.9885 - val_loss: 0.2259 - val_accuracy: 0.9469\n",
      "Epoch 19/30\n",
      "19841/19841 - 3s - loss: 0.0315 - accuracy: 0.9862 - val_loss: 0.1997 - val_accuracy: 0.9556\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.0268 - accuracy: 0.9885 - val_loss: 0.2142 - val_accuracy: 0.9374\n",
      "Epoch 21/30\n",
      "19841/19841 - 3s - loss: 0.0232 - accuracy: 0.9899 - val_loss: 0.1859 - val_accuracy: 0.9556\n",
      "Epoch 22/30\n",
      "19841/19841 - 3s - loss: 0.0203 - accuracy: 0.9909 - val_loss: 0.1869 - val_accuracy: 0.9483\n",
      "Epoch 23/30\n",
      "19841/19841 - 3s - loss: 0.0181 - accuracy: 0.9921 - val_loss: 0.2488 - val_accuracy: 0.9515\n",
      "Epoch 24/30\n",
      "19841/19841 - 3s - loss: 0.0190 - accuracy: 0.9916 - val_loss: 0.1941 - val_accuracy: 0.9501\n",
      "Epoch 25/30\n",
      "19841/19841 - 3s - loss: 0.0184 - accuracy: 0.9920 - val_loss: 0.1872 - val_accuracy: 0.9537\n",
      "Epoch 26/30\n",
      "19841/19841 - 4s - loss: 0.0200 - accuracy: 0.9919 - val_loss: 0.2642 - val_accuracy: 0.9528\n",
      "Epoch 27/30\n",
      "19841/19841 - 3s - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.2429 - val_accuracy: 0.9510\n",
      "Epoch 28/30\n",
      "19841/19841 - 3s - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.2379 - val_accuracy: 0.9524\n",
      "Epoch 29/30\n",
      "19841/19841 - 3s - loss: 0.0154 - accuracy: 0.9941 - val_loss: 0.2062 - val_accuracy: 0.9488\n",
      "Epoch 30/30\n",
      "19841/19841 - 3s - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.2404 - val_accuracy: 0.9587\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.2827 - accuracy: 0.9510s - loss: 0.2569 - accura\n",
      "Test_Accuracy: 95.10%\n",
      "5512/5512 [==============================] - 1s 100us/sample - loss: 0.2827 - accuracy: 0.9510\n",
      "5512/5512 [==============================] - 1s 107us/sample - loss: 0.2827 - accuracy: 0.9510\n",
      "[0.28265402074377777, 0.95101595]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 0.4158 - accuracy: 0.8072 - val_loss: 0.9945 - val_accuracy: 0.8181\n",
      "Epoch 2/30\n",
      "19841/19841 - 3s - loss: 0.2092 - accuracy: 0.9208 - val_loss: 0.3263 - val_accuracy: 0.9066\n",
      "Epoch 3/30\n",
      "19841/19841 - 4s - loss: 0.1833 - accuracy: 0.9313 - val_loss: 0.3173 - val_accuracy: 0.9116\n",
      "Epoch 4/30\n",
      "19841/19841 - 4s - loss: 0.1623 - accuracy: 0.9399 - val_loss: 0.2517 - val_accuracy: 0.9184\n",
      "Epoch 5/30\n",
      "19841/19841 - 4s - loss: 0.1475 - accuracy: 0.9438 - val_loss: 0.2337 - val_accuracy: 0.9197\n",
      "Epoch 6/30\n",
      "19841/19841 - 4s - loss: 0.1360 - accuracy: 0.9481 - val_loss: 0.3360 - val_accuracy: 0.9161\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 0.1174 - accuracy: 0.9544 - val_loss: 0.2822 - val_accuracy: 0.9270\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 0.1064 - accuracy: 0.9570 - val_loss: 0.1645 - val_accuracy: 0.9401\n",
      "Epoch 9/30\n",
      "19841/19841 - 4s - loss: 0.0957 - accuracy: 0.9625 - val_loss: 0.1984 - val_accuracy: 0.9429\n",
      "Epoch 10/30\n",
      "19841/19841 - 4s - loss: 0.0846 - accuracy: 0.9650 - val_loss: 0.2356 - val_accuracy: 0.9383\n",
      "Epoch 11/30\n",
      "19841/19841 - 4s - loss: 0.0725 - accuracy: 0.9693 - val_loss: 0.1920 - val_accuracy: 0.9506\n",
      "Epoch 12/30\n",
      "19841/19841 - 4s - loss: 0.0635 - accuracy: 0.9725 - val_loss: 0.1600 - val_accuracy: 0.9474\n",
      "Epoch 13/30\n",
      "19841/19841 - 4s - loss: 0.0601 - accuracy: 0.9736 - val_loss: 0.2131 - val_accuracy: 0.9383\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 0.0536 - accuracy: 0.9767 - val_loss: 0.1812 - val_accuracy: 0.9451\n",
      "Epoch 15/30\n",
      "19841/19841 - 3s - loss: 0.0480 - accuracy: 0.9797 - val_loss: 0.2588 - val_accuracy: 0.9315\n",
      "Epoch 16/30\n",
      "19841/19841 - 4s - loss: 0.0440 - accuracy: 0.9805 - val_loss: 0.2878 - val_accuracy: 0.9379\n",
      "Epoch 17/30\n",
      "19841/19841 - 4s - loss: 0.0418 - accuracy: 0.9825 - val_loss: 0.1994 - val_accuracy: 0.9483\n",
      "Epoch 18/30\n",
      "19841/19841 - 4s - loss: 0.0358 - accuracy: 0.9838 - val_loss: 0.3073 - val_accuracy: 0.9388\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 0.0307 - accuracy: 0.9858 - val_loss: 0.2305 - val_accuracy: 0.9483\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.0268 - accuracy: 0.9888 - val_loss: 0.2025 - val_accuracy: 0.9501\n",
      "Epoch 21/30\n",
      "19841/19841 - 4s - loss: 0.0274 - accuracy: 0.9883 - val_loss: 0.2277 - val_accuracy: 0.9551\n",
      "Epoch 22/30\n",
      "19841/19841 - 4s - loss: 0.0326 - accuracy: 0.9860 - val_loss: 0.2307 - val_accuracy: 0.9474\n",
      "Epoch 23/30\n",
      "19841/19841 - 3s - loss: 0.0251 - accuracy: 0.9894 - val_loss: 0.1974 - val_accuracy: 0.9556\n",
      "Epoch 24/30\n",
      "19841/19841 - 3s - loss: 0.0221 - accuracy: 0.9902 - val_loss: 0.2482 - val_accuracy: 0.9447\n",
      "Epoch 25/30\n",
      "19841/19841 - 3s - loss: 0.0221 - accuracy: 0.9909 - val_loss: 0.2971 - val_accuracy: 0.9465\n",
      "Epoch 26/30\n",
      "19841/19841 - 3s - loss: 0.0160 - accuracy: 0.9929 - val_loss: 0.2301 - val_accuracy: 0.9469\n",
      "Epoch 27/30\n",
      "19841/19841 - 3s - loss: 0.0164 - accuracy: 0.9926 - val_loss: 0.2840 - val_accuracy: 0.9002\n",
      "Epoch 28/30\n",
      "19841/19841 - 3s - loss: 0.0243 - accuracy: 0.9900 - val_loss: 0.3253 - val_accuracy: 0.9397\n",
      "Epoch 29/30\n",
      "19841/19841 - 3s - loss: 0.0246 - accuracy: 0.9899 - val_loss: 0.2134 - val_accuracy: 0.9424\n",
      "Epoch 30/30\n",
      "19841/19841 - 3s - loss: 0.0198 - accuracy: 0.9922 - val_loss: 0.2589 - val_accuracy: 0.9488\n",
      "5512/5512 [==============================] - 1s 98us/sample - loss: 0.2861 - accuracy: 0.9483\n",
      "Test_Accuracy: 94.83%\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.2861 - accuracy: 0.9483\n",
      "5512/5512 [==============================] - 1s 98us/sample - loss: 0.2861 - accuracy: 0.9483\n",
      "[0.2860603167419288, 0.94829464]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 0.4468 - accuracy: 0.7977 - val_loss: 0.8260 - val_accuracy: 0.8313\n",
      "Epoch 2/30\n",
      "19841/19841 - 4s - loss: 0.2320 - accuracy: 0.9118 - val_loss: 0.5410 - val_accuracy: 0.8531\n",
      "Epoch 3/30\n",
      "19841/19841 - 4s - loss: 0.1948 - accuracy: 0.9275 - val_loss: 0.2781 - val_accuracy: 0.8862\n",
      "Epoch 4/30\n",
      "19841/19841 - 4s - loss: 0.1673 - accuracy: 0.9372 - val_loss: 0.2164 - val_accuracy: 0.9111\n",
      "Epoch 5/30\n",
      "19841/19841 - 4s - loss: 0.1528 - accuracy: 0.9422 - val_loss: 0.2841 - val_accuracy: 0.8952\n",
      "Epoch 6/30\n",
      "19841/19841 - 4s - loss: 0.1354 - accuracy: 0.9470 - val_loss: 0.3016 - val_accuracy: 0.9134\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 0.1159 - accuracy: 0.9549 - val_loss: 0.2407 - val_accuracy: 0.9175\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 0.1029 - accuracy: 0.9603 - val_loss: 0.1546 - val_accuracy: 0.9533\n",
      "Epoch 9/30\n",
      "19841/19841 - 4s - loss: 0.0897 - accuracy: 0.9637 - val_loss: 0.2683 - val_accuracy: 0.9324\n",
      "Epoch 10/30\n",
      "19841/19841 - 4s - loss: 0.0789 - accuracy: 0.9652 - val_loss: 0.2198 - val_accuracy: 0.9324\n",
      "Epoch 11/30\n",
      "19841/19841 - 3s - loss: 0.0725 - accuracy: 0.9689 - val_loss: 0.1578 - val_accuracy: 0.9492\n",
      "Epoch 12/30\n",
      "19841/19841 - 3s - loss: 0.0641 - accuracy: 0.9713 - val_loss: 0.2435 - val_accuracy: 0.9256\n",
      "Epoch 13/30\n",
      "19841/19841 - 3s - loss: 0.0547 - accuracy: 0.9757 - val_loss: 0.1811 - val_accuracy: 0.9510\n",
      "Epoch 14/30\n",
      "19841/19841 - 3s - loss: 0.0505 - accuracy: 0.9772 - val_loss: 0.2161 - val_accuracy: 0.9546\n",
      "Epoch 15/30\n",
      "19841/19841 - 3s - loss: 0.0429 - accuracy: 0.9806 - val_loss: 0.2044 - val_accuracy: 0.9492\n",
      "Epoch 16/30\n",
      "19841/19841 - 3s - loss: 0.0450 - accuracy: 0.9792 - val_loss: 0.1787 - val_accuracy: 0.9537\n",
      "Epoch 17/30\n",
      "19841/19841 - 4s - loss: 0.0393 - accuracy: 0.9827 - val_loss: 0.2276 - val_accuracy: 0.9474\n",
      "Epoch 18/30\n",
      "19841/19841 - 3s - loss: 0.0391 - accuracy: 0.9826 - val_loss: 0.2674 - val_accuracy: 0.9410\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 0.0394 - accuracy: 0.9824 - val_loss: 0.2200 - val_accuracy: 0.9528\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.0326 - accuracy: 0.9848 - val_loss: 0.2016 - val_accuracy: 0.9501\n",
      "Epoch 21/30\n",
      "19841/19841 - 3s - loss: 0.0243 - accuracy: 0.9888 - val_loss: 0.2724 - val_accuracy: 0.9415\n",
      "Epoch 22/30\n",
      "19841/19841 - 3s - loss: 0.0313 - accuracy: 0.9869 - val_loss: 0.2754 - val_accuracy: 0.9365\n",
      "Epoch 23/30\n",
      "19841/19841 - 3s - loss: 0.0327 - accuracy: 0.9863 - val_loss: 0.2141 - val_accuracy: 0.9546\n",
      "Epoch 24/30\n",
      "19841/19841 - 3s - loss: 0.0267 - accuracy: 0.9893 - val_loss: 0.1743 - val_accuracy: 0.9605\n",
      "Epoch 25/30\n",
      "19841/19841 - 4s - loss: 0.0269 - accuracy: 0.9892 - val_loss: 0.2037 - val_accuracy: 0.9519\n",
      "Epoch 26/30\n",
      "19841/19841 - 4s - loss: 0.0218 - accuracy: 0.9907 - val_loss: 0.2160 - val_accuracy: 0.9583\n",
      "Epoch 27/30\n",
      "19841/19841 - 3s - loss: 0.0186 - accuracy: 0.9916 - val_loss: 0.2402 - val_accuracy: 0.9587\n",
      "Epoch 28/30\n",
      "19841/19841 - 4s - loss: 0.0212 - accuracy: 0.9915 - val_loss: 0.2095 - val_accuracy: 0.9560\n",
      "Epoch 29/30\n",
      "19841/19841 - 4s - loss: 0.0198 - accuracy: 0.9917 - val_loss: 0.2697 - val_accuracy: 0.9379\n",
      "Epoch 30/30\n",
      "19841/19841 - 4s - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.2027 - val_accuracy: 0.9542\n",
      "5512/5512 [==============================] - 1s 101us/sample - loss: 0.2298 - accuracy: 0.9479\n",
      "Test_Accuracy: 94.79%\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.2298 - accuracy: 0.9479\n",
      "5512/5512 [==============================] - 1s 98us/sample - loss: 0.2298 - accuracy: 0.9479\n",
      "[0.22977451944023544, 0.94793177]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 0.4353 - accuracy: 0.7988 - val_loss: 0.2820 - val_accuracy: 0.9098\n",
      "Epoch 2/30\n",
      "19841/19841 - 4s - loss: 0.2202 - accuracy: 0.9190 - val_loss: 0.2705 - val_accuracy: 0.9220\n",
      "Epoch 3/30\n",
      "19841/19841 - 4s - loss: 0.1888 - accuracy: 0.9311 - val_loss: 0.2282 - val_accuracy: 0.9252\n",
      "Epoch 4/30\n",
      "19841/19841 - 4s - loss: 0.1666 - accuracy: 0.9389 - val_loss: 0.1905 - val_accuracy: 0.9324\n",
      "Epoch 5/30\n",
      "19841/19841 - 4s - loss: 0.1397 - accuracy: 0.9480 - val_loss: 0.1581 - val_accuracy: 0.9478\n",
      "Epoch 6/30\n",
      "19841/19841 - 4s - loss: 0.1214 - accuracy: 0.9545 - val_loss: 0.1570 - val_accuracy: 0.9447\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 0.1069 - accuracy: 0.9602 - val_loss: 0.1691 - val_accuracy: 0.9506\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 0.0943 - accuracy: 0.9645 - val_loss: 0.1822 - val_accuracy: 0.9365\n",
      "Epoch 9/30\n",
      "19841/19841 - 4s - loss: 0.0840 - accuracy: 0.9690 - val_loss: 0.1637 - val_accuracy: 0.9510\n",
      "Epoch 10/30\n",
      "19841/19841 - 4s - loss: 0.0798 - accuracy: 0.9700 - val_loss: 0.1726 - val_accuracy: 0.9451\n",
      "Epoch 11/30\n",
      "19841/19841 - 4s - loss: 0.0655 - accuracy: 0.9742 - val_loss: 0.2317 - val_accuracy: 0.9324\n",
      "Epoch 12/30\n",
      "19841/19841 - 4s - loss: 0.0591 - accuracy: 0.9757 - val_loss: 0.2006 - val_accuracy: 0.9510\n",
      "Epoch 13/30\n",
      "19841/19841 - 4s - loss: 0.0640 - accuracy: 0.9758 - val_loss: 0.2172 - val_accuracy: 0.9551\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 0.0546 - accuracy: 0.9795 - val_loss: 0.1979 - val_accuracy: 0.9474\n",
      "Epoch 15/30\n",
      "19841/19841 - 4s - loss: 0.0491 - accuracy: 0.9822 - val_loss: 0.1981 - val_accuracy: 0.9488\n",
      "Epoch 16/30\n",
      "19841/19841 - 3s - loss: 0.0466 - accuracy: 0.9834 - val_loss: 0.1894 - val_accuracy: 0.9546\n",
      "Epoch 17/30\n",
      "19841/19841 - 3s - loss: 0.0443 - accuracy: 0.9837 - val_loss: 0.2086 - val_accuracy: 0.9537\n",
      "Epoch 18/30\n",
      "19841/19841 - 4s - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.2514 - val_accuracy: 0.9406\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 0.0358 - accuracy: 0.9886 - val_loss: 0.2270 - val_accuracy: 0.9542\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.2090 - val_accuracy: 0.9533\n",
      "Epoch 21/30\n",
      "19841/19841 - 3s - loss: 0.0420 - accuracy: 0.9866 - val_loss: 0.2778 - val_accuracy: 0.9397\n",
      "Epoch 22/30\n",
      "19841/19841 - 4s - loss: 0.0377 - accuracy: 0.9888 - val_loss: 0.1962 - val_accuracy: 0.9596\n",
      "Epoch 23/30\n",
      "19841/19841 - 4s - loss: 0.0316 - accuracy: 0.9911 - val_loss: 0.3459 - val_accuracy: 0.9152\n",
      "Epoch 24/30\n",
      "19841/19841 - 3s - loss: 0.0312 - accuracy: 0.9920 - val_loss: 0.2109 - val_accuracy: 0.9578\n",
      "Epoch 25/30\n",
      "19841/19841 - 4s - loss: 0.0309 - accuracy: 0.9917 - val_loss: 0.2217 - val_accuracy: 0.9533\n",
      "Epoch 26/30\n",
      "19841/19841 - 3s - loss: 0.0304 - accuracy: 0.9927 - val_loss: 0.2281 - val_accuracy: 0.9528\n",
      "Epoch 27/30\n",
      "19841/19841 - 4s - loss: 0.0318 - accuracy: 0.9927 - val_loss: 0.2594 - val_accuracy: 0.9596\n",
      "Epoch 28/30\n",
      "19841/19841 - 4s - loss: 0.0405 - accuracy: 0.9896 - val_loss: 0.2166 - val_accuracy: 0.9483\n",
      "Epoch 29/30\n",
      "19841/19841 - 4s - loss: 0.0285 - accuracy: 0.9940 - val_loss: 0.2488 - val_accuracy: 0.9587\n",
      "Epoch 30/30\n",
      "19841/19841 - 4s - loss: 0.0319 - accuracy: 0.9934 - val_loss: 0.2117 - val_accuracy: 0.9578\n",
      "5512/5512 [==============================] - 1s 120us/sample - loss: 0.2635 - accuracy: 0.9523\n",
      "Test_Accuracy: 95.23%\n",
      "5512/5512 [==============================] - 1s 109us/sample - loss: 0.2635 - accuracy: 0.9523\n",
      "5512/5512 [==============================] - 1s 100us/sample - loss: 0.2635 - accuracy: 0.9523\n",
      "[0.26345260602155773, 0.95228595]\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 0.4380 - accuracy: 0.8033 - val_loss: 0.4637 - val_accuracy: 0.8839\n",
      "Epoch 2/30\n",
      "19841/19841 - 4s - loss: 0.2339 - accuracy: 0.9193 - val_loss: 0.3443 - val_accuracy: 0.8925\n",
      "Epoch 3/30\n",
      "19841/19841 - 4s - loss: 0.2012 - accuracy: 0.9314 - val_loss: 0.3449 - val_accuracy: 0.8893\n",
      "Epoch 4/30\n",
      "19841/19841 - 4s - loss: 0.1860 - accuracy: 0.9360 - val_loss: 0.2494 - val_accuracy: 0.9252\n",
      "Epoch 5/30\n",
      "19841/19841 - 4s - loss: 0.1694 - accuracy: 0.9455 - val_loss: 0.2416 - val_accuracy: 0.9265\n",
      "Epoch 6/30\n",
      "19841/19841 - 3s - loss: 0.1545 - accuracy: 0.9501 - val_loss: 0.2107 - val_accuracy: 0.9401\n",
      "Epoch 7/30\n",
      "19841/19841 - 3s - loss: 0.1408 - accuracy: 0.9563 - val_loss: 0.3285 - val_accuracy: 0.9111\n",
      "Epoch 8/30\n",
      "19841/19841 - 3s - loss: 0.1290 - accuracy: 0.9607 - val_loss: 0.2162 - val_accuracy: 0.9306\n",
      "Epoch 9/30\n",
      "19841/19841 - 4s - loss: 0.1260 - accuracy: 0.9614 - val_loss: 0.3535 - val_accuracy: 0.9238\n",
      "Epoch 10/30\n",
      "19841/19841 - 4s - loss: 0.1233 - accuracy: 0.9640 - val_loss: 0.2076 - val_accuracy: 0.9492\n",
      "Epoch 11/30\n",
      "19841/19841 - 3s - loss: 0.1136 - accuracy: 0.9673 - val_loss: 0.2355 - val_accuracy: 0.9546\n",
      "Epoch 12/30\n",
      "19841/19841 - 4s - loss: 0.1076 - accuracy: 0.9721 - val_loss: 0.2174 - val_accuracy: 0.9469\n",
      "Epoch 13/30\n",
      "19841/19841 - 4s - loss: 0.1076 - accuracy: 0.9734 - val_loss: 0.2446 - val_accuracy: 0.9342\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 0.1035 - accuracy: 0.9756 - val_loss: 0.2038 - val_accuracy: 0.9501\n",
      "Epoch 15/30\n",
      "19841/19841 - 3s - loss: 0.1007 - accuracy: 0.9776 - val_loss: 0.2865 - val_accuracy: 0.9406\n",
      "Epoch 16/30\n",
      "19841/19841 - 3s - loss: 0.0938 - accuracy: 0.9802 - val_loss: 0.2673 - val_accuracy: 0.9465\n",
      "Epoch 17/30\n",
      "19841/19841 - 4s - loss: 0.0975 - accuracy: 0.9805 - val_loss: 0.2483 - val_accuracy: 0.9478\n",
      "Epoch 18/30\n",
      "19841/19841 - 4s - loss: 0.0943 - accuracy: 0.9820 - val_loss: 0.2687 - val_accuracy: 0.9515\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 0.0916 - accuracy: 0.9839 - val_loss: 0.2587 - val_accuracy: 0.9510\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.0969 - accuracy: 0.9829 - val_loss: 0.2551 - val_accuracy: 0.9524\n",
      "Epoch 21/30\n",
      "19841/19841 - 4s - loss: 0.0928 - accuracy: 0.9859 - val_loss: 0.2781 - val_accuracy: 0.9420\n",
      "Epoch 22/30\n",
      "19841/19841 - 4s - loss: 0.0881 - accuracy: 0.9883 - val_loss: 0.2876 - val_accuracy: 0.9506\n",
      "Epoch 23/30\n",
      "19841/19841 - 4s - loss: 0.0948 - accuracy: 0.9863 - val_loss: 0.2336 - val_accuracy: 0.9533\n",
      "Epoch 24/30\n",
      "19841/19841 - 4s - loss: 0.0889 - accuracy: 0.9891 - val_loss: 0.2707 - val_accuracy: 0.9537\n",
      "Epoch 25/30\n",
      "19841/19841 - 4s - loss: 0.0904 - accuracy: 0.9888 - val_loss: 0.2407 - val_accuracy: 0.9519\n",
      "Epoch 26/30\n",
      "19841/19841 - 3s - loss: 0.0913 - accuracy: 0.9890 - val_loss: 0.2872 - val_accuracy: 0.9569\n",
      "Epoch 27/30\n",
      "19841/19841 - 3s - loss: 0.0842 - accuracy: 0.9918 - val_loss: 0.2884 - val_accuracy: 0.9546\n",
      "Epoch 28/30\n",
      "19841/19841 - 3s - loss: 0.0869 - accuracy: 0.9908 - val_loss: 0.2746 - val_accuracy: 0.9605\n",
      "Epoch 29/30\n",
      "19841/19841 - 3s - loss: 0.0878 - accuracy: 0.9905 - val_loss: 0.2551 - val_accuracy: 0.9506\n",
      "Epoch 30/30\n",
      "19841/19841 - 3s - loss: 0.0884 - accuracy: 0.9906 - val_loss: 0.2464 - val_accuracy: 0.9515\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.2912 - accuracy: 0.9468\n",
      "Test_Accuracy: 94.68%\n",
      "5512/5512 [==============================] - 1s 100us/sample - loss: 0.2912 - accuracy: 0.9468\n",
      "5512/5512 [==============================] - 1s 95us/sample - loss: 0.2912 - accuracy: 0.9468\n",
      "[0.29117429094234987, 0.94684327]\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 0.5718 - accuracy: 0.8016 - val_loss: 0.8795 - val_accuracy: 0.8490\n",
      "Epoch 2/30\n",
      "19841/19841 - 4s - loss: 0.3663 - accuracy: 0.9190 - val_loss: 0.4936 - val_accuracy: 0.9057\n",
      "Epoch 3/30\n",
      "19841/19841 - 4s - loss: 0.3135 - accuracy: 0.9341 - val_loss: 0.3730 - val_accuracy: 0.9338\n",
      "Epoch 4/30\n",
      "19841/19841 - 4s - loss: 0.2900 - accuracy: 0.9374 - val_loss: 0.2779 - val_accuracy: 0.9365\n",
      "Epoch 5/30\n",
      "19841/19841 - 4s - loss: 0.2597 - accuracy: 0.9454 - val_loss: 0.2927 - val_accuracy: 0.9283\n",
      "Epoch 6/30\n",
      "19841/19841 - 4s - loss: 0.2427 - accuracy: 0.9495 - val_loss: 0.5655 - val_accuracy: 0.7628\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 0.2340 - accuracy: 0.9538 - val_loss: 0.4270 - val_accuracy: 0.8871\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 0.2233 - accuracy: 0.9584 - val_loss: 0.3257 - val_accuracy: 0.9274\n",
      "Epoch 9/30\n",
      "19841/19841 - 4s - loss: 0.2248 - accuracy: 0.9598 - val_loss: 0.3049 - val_accuracy: 0.9438\n",
      "Epoch 10/30\n",
      "19841/19841 - 3s - loss: 0.2228 - accuracy: 0.9627 - val_loss: 0.3337 - val_accuracy: 0.9293\n",
      "Epoch 11/30\n",
      "19841/19841 - 4s - loss: 0.2226 - accuracy: 0.9635 - val_loss: 0.2709 - val_accuracy: 0.9533\n",
      "Epoch 12/30\n",
      "19841/19841 - 4s - loss: 0.2105 - accuracy: 0.9687 - val_loss: 0.3184 - val_accuracy: 0.9392\n",
      "Epoch 13/30\n",
      "19841/19841 - 3s - loss: 0.2179 - accuracy: 0.9687 - val_loss: 0.3905 - val_accuracy: 0.9152\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 0.2175 - accuracy: 0.9714 - val_loss: 0.3492 - val_accuracy: 0.9442\n",
      "Epoch 15/30\n",
      "19841/19841 - 4s - loss: 0.2185 - accuracy: 0.9728 - val_loss: 0.2958 - val_accuracy: 0.9506\n",
      "Epoch 16/30\n",
      "19841/19841 - 4s - loss: 0.2199 - accuracy: 0.9734 - val_loss: 0.3201 - val_accuracy: 0.9524\n",
      "Epoch 17/30\n",
      "19841/19841 - 4s - loss: 0.2225 - accuracy: 0.9735 - val_loss: 0.5415 - val_accuracy: 0.8585\n",
      "Epoch 18/30\n",
      "19841/19841 - 4s - loss: 0.2226 - accuracy: 0.9763 - val_loss: 0.3370 - val_accuracy: 0.9515\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 0.2214 - accuracy: 0.9764 - val_loss: 0.3314 - val_accuracy: 0.9519\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.2198 - accuracy: 0.9781 - val_loss: 0.3309 - val_accuracy: 0.9587\n",
      "Epoch 21/30\n",
      "19841/19841 - 4s - loss: 0.2136 - accuracy: 0.9795 - val_loss: 0.3221 - val_accuracy: 0.9519\n",
      "Epoch 22/30\n",
      "19841/19841 - 4s - loss: 0.2006 - accuracy: 0.9818 - val_loss: 0.3237 - val_accuracy: 0.9596\n",
      "Epoch 23/30\n",
      "19841/19841 - 4s - loss: 0.2080 - accuracy: 0.9809 - val_loss: 0.3166 - val_accuracy: 0.9528\n",
      "Epoch 24/30\n",
      "19841/19841 - 3s - loss: 0.2056 - accuracy: 0.9812 - val_loss: 0.3064 - val_accuracy: 0.9615\n",
      "Epoch 25/30\n",
      "19841/19841 - 3s - loss: 0.2050 - accuracy: 0.9803 - val_loss: 0.3210 - val_accuracy: 0.9510\n",
      "Epoch 26/30\n",
      "19841/19841 - 3s - loss: 0.2021 - accuracy: 0.9830 - val_loss: 0.3533 - val_accuracy: 0.9483\n",
      "Epoch 27/30\n",
      "19841/19841 - 3s - loss: 0.2028 - accuracy: 0.9839 - val_loss: 0.3240 - val_accuracy: 0.9465\n",
      "Epoch 28/30\n",
      "19841/19841 - 4s - loss: 0.2065 - accuracy: 0.9832 - val_loss: 0.3395 - val_accuracy: 0.9506\n",
      "Epoch 29/30\n",
      "19841/19841 - 4s - loss: 0.1901 - accuracy: 0.9854 - val_loss: 0.3510 - val_accuracy: 0.9528\n",
      "Epoch 30/30\n",
      "19841/19841 - 4s - loss: 0.2061 - accuracy: 0.9816 - val_loss: 0.3234 - val_accuracy: 0.9569\n",
      "5512/5512 [==============================] - 1s 100us/sample - loss: 0.3506 - accuracy: 0.9525\n",
      "Test_Accuracy: 95.25%\n",
      "5512/5512 [==============================] - 1s 100us/sample - loss: 0.3506 - accuracy: 0.9525\n",
      "5512/5512 [==============================] - 1s 113us/sample - loss: 0.3506 - accuracy: 0.9525\n",
      "[0.35062505458366716, 0.9524673]\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 1.4601 - accuracy: 0.7756 - val_loss: 2.1192 - val_accuracy: 0.7542\n",
      "Epoch 2/30\n",
      "19841/19841 - 4s - loss: 0.6839 - accuracy: 0.9155 - val_loss: 0.7691 - val_accuracy: 0.8807\n",
      "Epoch 3/30\n",
      "19841/19841 - 3s - loss: 0.4636 - accuracy: 0.9229 - val_loss: 0.4199 - val_accuracy: 0.9147\n",
      "Epoch 4/30\n",
      "19841/19841 - 4s - loss: 0.3796 - accuracy: 0.9260 - val_loss: 0.3496 - val_accuracy: 0.9243\n",
      "Epoch 5/30\n",
      "19841/19841 - 3s - loss: 0.3314 - accuracy: 0.9317 - val_loss: 0.3020 - val_accuracy: 0.9320\n",
      "Epoch 6/30\n",
      "19841/19841 - 3s - loss: 0.3156 - accuracy: 0.9316 - val_loss: 0.3581 - val_accuracy: 0.9215\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 0.2957 - accuracy: 0.9364 - val_loss: 0.3355 - val_accuracy: 0.9147\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 0.2823 - accuracy: 0.9426 - val_loss: 0.2796 - val_accuracy: 0.9478\n",
      "Epoch 9/30\n",
      "19841/19841 - 4s - loss: 0.2745 - accuracy: 0.9464 - val_loss: 0.2617 - val_accuracy: 0.9506\n",
      "Epoch 10/30\n",
      "19841/19841 - 3s - loss: 0.2728 - accuracy: 0.9482 - val_loss: 0.2440 - val_accuracy: 0.9560\n",
      "Epoch 11/30\n",
      "19841/19841 - 4s - loss: 0.2675 - accuracy: 0.9500 - val_loss: 0.2495 - val_accuracy: 0.9565\n",
      "Epoch 12/30\n",
      "19841/19841 - 4s - loss: 0.2703 - accuracy: 0.9502 - val_loss: 0.2793 - val_accuracy: 0.9433\n",
      "Epoch 13/30\n",
      "19841/19841 - 4s - loss: 0.2733 - accuracy: 0.9521 - val_loss: 0.2477 - val_accuracy: 0.9601\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 0.2637 - accuracy: 0.9546 - val_loss: 0.2705 - val_accuracy: 0.9542\n",
      "Epoch 15/30\n",
      "19841/19841 - 4s - loss: 0.2829 - accuracy: 0.9531 - val_loss: 0.2899 - val_accuracy: 0.9528\n",
      "Epoch 16/30\n",
      "19841/19841 - 4s - loss: 0.2731 - accuracy: 0.9548 - val_loss: 0.2641 - val_accuracy: 0.9587\n",
      "Epoch 17/30\n",
      "19841/19841 - 3s - loss: 0.2608 - accuracy: 0.9566 - val_loss: 0.2612 - val_accuracy: 0.9592\n",
      "Epoch 18/30\n",
      "19841/19841 - 4s - loss: 0.2680 - accuracy: 0.9558 - val_loss: 0.2708 - val_accuracy: 0.9488\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 0.2571 - accuracy: 0.9571 - val_loss: 0.2542 - val_accuracy: 0.9587\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.2674 - accuracy: 0.9567 - val_loss: 0.2703 - val_accuracy: 0.9565\n",
      "Epoch 21/30\n",
      "19841/19841 - 4s - loss: 0.2631 - accuracy: 0.9572 - val_loss: 0.2712 - val_accuracy: 0.9556\n",
      "Epoch 22/30\n",
      "19841/19841 - 4s - loss: 0.2679 - accuracy: 0.9582 - val_loss: 0.2703 - val_accuracy: 0.9519\n",
      "Epoch 23/30\n",
      "19841/19841 - 4s - loss: 0.2580 - accuracy: 0.9583 - val_loss: 0.3768 - val_accuracy: 0.9025\n",
      "Epoch 24/30\n",
      "19841/19841 - 4s - loss: 0.2642 - accuracy: 0.9590 - val_loss: 0.2844 - val_accuracy: 0.9528\n",
      "Epoch 25/30\n",
      "19841/19841 - 3s - loss: 0.2592 - accuracy: 0.9595 - val_loss: 0.2668 - val_accuracy: 0.9565\n",
      "Epoch 26/30\n",
      "19841/19841 - 4s - loss: 0.2589 - accuracy: 0.9627 - val_loss: 0.2798 - val_accuracy: 0.9556\n",
      "Epoch 27/30\n",
      "19841/19841 - 4s - loss: 0.2513 - accuracy: 0.9618 - val_loss: 0.2840 - val_accuracy: 0.9519\n",
      "Epoch 28/30\n",
      "19841/19841 - 3s - loss: 0.2457 - accuracy: 0.9639 - val_loss: 0.2819 - val_accuracy: 0.9442\n",
      "Epoch 29/30\n",
      "19841/19841 - 4s - loss: 0.2522 - accuracy: 0.9615 - val_loss: 0.2840 - val_accuracy: 0.9515\n",
      "Epoch 30/30\n",
      "19841/19841 - 4s - loss: 0.2470 - accuracy: 0.9624 - val_loss: 0.2731 - val_accuracy: 0.9510\n",
      "5512/5512 [==============================] - 1s 102us/sample - loss: 0.2926 - accuracy: 0.9470\n",
      "Test_Accuracy: 94.70%\n",
      "5512/5512 [==============================] - 1s 96us/sample - loss: 0.2926 - accuracy: 0.9470\n",
      "5512/5512 [==============================] - 1s 108us/sample - loss: 0.2926 - accuracy: 0.9470\n",
      "[0.29261166532084626, 0.9470247]\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 6s - loss: 3.2912 - accuracy: 0.7424 - val_loss: 3.2758 - val_accuracy: 0.5864\n",
      "Epoch 2/30\n",
      "19841/19841 - 3s - loss: 0.6369 - accuracy: 0.9028 - val_loss: 0.7214 - val_accuracy: 0.7937\n",
      "Epoch 3/30\n",
      "19841/19841 - 3s - loss: 0.4929 - accuracy: 0.9165 - val_loss: 0.4868 - val_accuracy: 0.9252\n",
      "Epoch 4/30\n",
      "19841/19841 - 3s - loss: 0.4637 - accuracy: 0.9269 - val_loss: 0.4564 - val_accuracy: 0.9116\n",
      "Epoch 5/30\n",
      "19841/19841 - 3s - loss: 0.4587 - accuracy: 0.9319 - val_loss: 0.6744 - val_accuracy: 0.8762\n",
      "Epoch 6/30\n",
      "19841/19841 - 3s - loss: 0.4583 - accuracy: 0.9397 - val_loss: 0.5332 - val_accuracy: 0.9424\n",
      "Epoch 7/30\n",
      "19841/19841 - 3s - loss: 0.4703 - accuracy: 0.9444 - val_loss: 0.5289 - val_accuracy: 0.9179\n",
      "Epoch 8/30\n",
      "19841/19841 - 3s - loss: 0.4764 - accuracy: 0.9467 - val_loss: 0.5179 - val_accuracy: 0.9438\n",
      "Epoch 9/30\n",
      "19841/19841 - 3s - loss: 0.4770 - accuracy: 0.9471 - val_loss: 0.5556 - val_accuracy: 0.9456\n",
      "Epoch 10/30\n",
      "19841/19841 - 3s - loss: 0.4989 - accuracy: 0.9490 - val_loss: 0.5067 - val_accuracy: 0.9556\n",
      "Epoch 11/30\n",
      "19841/19841 - 3s - loss: 0.4566 - accuracy: 0.9506 - val_loss: 0.5531 - val_accuracy: 0.9510\n",
      "Epoch 12/30\n",
      "19841/19841 - 3s - loss: 0.4585 - accuracy: 0.9520 - val_loss: 0.4155 - val_accuracy: 0.9610\n",
      "Epoch 13/30\n",
      "19841/19841 - 4s - loss: 0.4786 - accuracy: 0.9500 - val_loss: 0.5511 - val_accuracy: 0.9542\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 0.4525 - accuracy: 0.9515 - val_loss: 0.4746 - val_accuracy: 0.9578\n",
      "Epoch 15/30\n",
      "19841/19841 - 4s - loss: 0.4586 - accuracy: 0.9520 - val_loss: 0.4774 - val_accuracy: 0.9596\n",
      "Epoch 16/30\n",
      "19841/19841 - 4s - loss: 0.4479 - accuracy: 0.9523 - val_loss: 0.4383 - val_accuracy: 0.9569\n",
      "Epoch 17/30\n",
      "19841/19841 - 4s - loss: 0.4439 - accuracy: 0.9528 - val_loss: 0.6107 - val_accuracy: 0.8871\n",
      "Epoch 18/30\n",
      "19841/19841 - 3s - loss: 0.4602 - accuracy: 0.9507 - val_loss: 0.5111 - val_accuracy: 0.9578\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 0.4562 - accuracy: 0.9521 - val_loss: 0.5184 - val_accuracy: 0.9469\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.4363 - accuracy: 0.9526 - val_loss: 0.4792 - val_accuracy: 0.9542\n",
      "Epoch 21/30\n",
      "19841/19841 - 4s - loss: 0.4379 - accuracy: 0.9520 - val_loss: 0.4835 - val_accuracy: 0.9492\n",
      "Epoch 22/30\n",
      "19841/19841 - 3s - loss: 0.4306 - accuracy: 0.9528 - val_loss: 0.4612 - val_accuracy: 0.9515\n",
      "Epoch 23/30\n",
      "19841/19841 - 4s - loss: 0.4122 - accuracy: 0.9533 - val_loss: 0.4175 - val_accuracy: 0.9451\n",
      "Epoch 24/30\n",
      "19841/19841 - 3s - loss: 0.4211 - accuracy: 0.9529 - val_loss: 0.7452 - val_accuracy: 0.7506\n",
      "Epoch 25/30\n",
      "19841/19841 - 3s - loss: 0.4331 - accuracy: 0.9545 - val_loss: 0.4110 - val_accuracy: 0.9610\n",
      "Epoch 26/30\n",
      "19841/19841 - 4s - loss: 0.4010 - accuracy: 0.9535 - val_loss: 0.4666 - val_accuracy: 0.9524\n",
      "Epoch 27/30\n",
      "19841/19841 - 4s - loss: 0.3950 - accuracy: 0.9528 - val_loss: 0.4330 - val_accuracy: 0.9596\n",
      "Epoch 28/30\n",
      "19841/19841 - 4s - loss: 0.4298 - accuracy: 0.9529 - val_loss: 0.3811 - val_accuracy: 0.9601\n",
      "Epoch 29/30\n",
      "19841/19841 - 4s - loss: 0.3995 - accuracy: 0.9532 - val_loss: 0.4388 - val_accuracy: 0.9524\n",
      "Epoch 30/30\n",
      "19841/19841 - 4s - loss: 0.4077 - accuracy: 0.9537 - val_loss: 0.4345 - val_accuracy: 0.9646\n",
      "5512/5512 [==============================] - 1s 104us/sample - loss: 0.4517 - accuracy: 0.9568\n",
      "Test_Accuracy: 95.68%\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.4517 - accuracy: 0.9568\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 0.4517 - accuracy: 0.9568\n",
      "[0.4516639039028539, 0.9568215]\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 8.0975 - accuracy: 0.7810 - val_loss: 1.7240 - val_accuracy: 0.5991\n",
      "Epoch 2/30\n",
      "19841/19841 - 4s - loss: 0.8480 - accuracy: 0.9000 - val_loss: 1.0656 - val_accuracy: 0.8354\n",
      "Epoch 3/30\n",
      "19841/19841 - 4s - loss: 0.9081 - accuracy: 0.9083 - val_loss: 1.2047 - val_accuracy: 0.8494\n",
      "Epoch 4/30\n",
      "19841/19841 - 3s - loss: 0.9901 - accuracy: 0.9156 - val_loss: 1.0329 - val_accuracy: 0.8771\n",
      "Epoch 5/30\n",
      "19841/19841 - 4s - loss: 1.0466 - accuracy: 0.9205 - val_loss: 1.0305 - val_accuracy: 0.9270\n",
      "Epoch 6/30\n",
      "19841/19841 - 4s - loss: 1.0013 - accuracy: 0.9253 - val_loss: 1.3212 - val_accuracy: 0.8372\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 1.0180 - accuracy: 0.9347 - val_loss: 0.9913 - val_accuracy: 0.9184\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 1.0532 - accuracy: 0.9356 - val_loss: 1.2570 - val_accuracy: 0.9252\n",
      "Epoch 9/30\n",
      "19841/19841 - 3s - loss: 1.0480 - accuracy: 0.9384 - val_loss: 1.2685 - val_accuracy: 0.9356\n",
      "Epoch 10/30\n",
      "19841/19841 - 4s - loss: 1.0129 - accuracy: 0.9442 - val_loss: 2.3907 - val_accuracy: 0.4952\n",
      "Epoch 11/30\n",
      "19841/19841 - 4s - loss: 0.9938 - accuracy: 0.9449 - val_loss: 1.1206 - val_accuracy: 0.9488\n",
      "Epoch 12/30\n",
      "19841/19841 - 3s - loss: 1.0618 - accuracy: 0.9459 - val_loss: 1.3386 - val_accuracy: 0.7039\n",
      "Epoch 13/30\n",
      "19841/19841 - 4s - loss: 0.9824 - accuracy: 0.9464 - val_loss: 1.1106 - val_accuracy: 0.9361\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 0.9689 - accuracy: 0.9460 - val_loss: 1.2272 - val_accuracy: 0.9474\n",
      "Epoch 15/30\n",
      "19841/19841 - 4s - loss: 0.9053 - accuracy: 0.9479 - val_loss: 0.8439 - val_accuracy: 0.9351\n",
      "Epoch 16/30\n",
      "19841/19841 - 4s - loss: 0.9120 - accuracy: 0.9470 - val_loss: 1.0289 - val_accuracy: 0.9320\n",
      "Epoch 17/30\n",
      "19841/19841 - 4s - loss: 0.9764 - accuracy: 0.9464 - val_loss: 1.0149 - val_accuracy: 0.9324\n",
      "Epoch 18/30\n",
      "19841/19841 - 3s - loss: 0.9172 - accuracy: 0.9479 - val_loss: 1.0907 - val_accuracy: 0.9578\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 0.9461 - accuracy: 0.9485 - val_loss: 1.2700 - val_accuracy: 0.9497\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 0.9827 - accuracy: 0.9481 - val_loss: 1.1510 - val_accuracy: 0.9175\n",
      "Epoch 21/30\n",
      "19841/19841 - 4s - loss: 0.9568 - accuracy: 0.9465 - val_loss: 2.0312 - val_accuracy: 0.5102\n",
      "Epoch 22/30\n",
      "19841/19841 - 4s - loss: 0.8760 - accuracy: 0.9482 - val_loss: 1.0107 - val_accuracy: 0.9488\n",
      "Epoch 23/30\n",
      "19841/19841 - 4s - loss: 0.9100 - accuracy: 0.9486 - val_loss: 0.9208 - val_accuracy: 0.9451\n",
      "Epoch 24/30\n",
      "19841/19841 - 4s - loss: 0.9424 - accuracy: 0.9489 - val_loss: 1.1606 - val_accuracy: 0.9565\n",
      "Epoch 25/30\n",
      "19841/19841 - 4s - loss: 0.8590 - accuracy: 0.9492 - val_loss: 1.1749 - val_accuracy: 0.9510\n",
      "Epoch 26/30\n",
      "19841/19841 - 4s - loss: 0.9357 - accuracy: 0.9481 - val_loss: 0.9631 - val_accuracy: 0.9578\n",
      "Epoch 27/30\n",
      "19841/19841 - 4s - loss: 0.9003 - accuracy: 0.9497 - val_loss: 0.9793 - val_accuracy: 0.8916\n",
      "Epoch 28/30\n",
      "19841/19841 - 4s - loss: 0.9104 - accuracy: 0.9498 - val_loss: 1.1488 - val_accuracy: 0.9166\n",
      "Epoch 29/30\n",
      "19841/19841 - 4s - loss: 0.8690 - accuracy: 0.9490 - val_loss: 0.8888 - val_accuracy: 0.9501\n",
      "Epoch 30/30\n",
      "19841/19841 - 4s - loss: 0.8918 - accuracy: 0.9505 - val_loss: 0.9797 - val_accuracy: 0.9537\n",
      "5512/5512 [==============================] - 1s 107us/sample - loss: 0.9836 - accuracy: 0.9503\n",
      "Test_Accuracy: 95.03%\n",
      "5512/5512 [==============================] - 1s 101us/sample - loss: 0.9836 - accuracy: 0.9503\n",
      "5512/5512 [==============================] - 1s 103us/sample - loss: 0.9836 - accuracy: 0.9503\n",
      "[0.9835766942303827, 0.95029026]\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 5s - loss: 55.9162 - accuracy: 0.7510 - val_loss: 1.4917 - val_accuracy: 0.6825\n",
      "Epoch 2/30\n",
      "19841/19841 - 4s - loss: 1.3639 - accuracy: 0.8722 - val_loss: 1.3185 - val_accuracy: 0.8118\n",
      "Epoch 3/30\n",
      "19841/19841 - 4s - loss: 1.4749 - accuracy: 0.8940 - val_loss: 1.5544 - val_accuracy: 0.7932\n",
      "Epoch 4/30\n",
      "19841/19841 - 4s - loss: 1.6262 - accuracy: 0.9026 - val_loss: 1.6932 - val_accuracy: 0.7673\n",
      "Epoch 5/30\n",
      "19841/19841 - 4s - loss: 1.7189 - accuracy: 0.9116 - val_loss: 2.1292 - val_accuracy: 0.7773\n",
      "Epoch 6/30\n",
      "19841/19841 - 4s - loss: 1.8090 - accuracy: 0.9199 - val_loss: 2.0097 - val_accuracy: 0.8776\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 1.7404 - accuracy: 0.9254 - val_loss: 1.7124 - val_accuracy: 0.9229\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 1.8247 - accuracy: 0.9303 - val_loss: 1.8271 - val_accuracy: 0.9293\n",
      "Epoch 9/30\n",
      "19841/19841 - 4s - loss: 1.8642 - accuracy: 0.9338 - val_loss: 2.1211 - val_accuracy: 0.9410\n",
      "Epoch 10/30\n",
      "19841/19841 - 4s - loss: 1.9347 - accuracy: 0.9342 - val_loss: 1.9959 - val_accuracy: 0.9388\n",
      "Epoch 11/30\n",
      "19841/19841 - 4s - loss: 1.9598 - accuracy: 0.9359 - val_loss: 2.3559 - val_accuracy: 0.9333\n",
      "Epoch 12/30\n",
      "19841/19841 - 4s - loss: 1.9253 - accuracy: 0.9368 - val_loss: 2.2391 - val_accuracy: 0.9497\n",
      "Epoch 13/30\n",
      "19841/19841 - 4s - loss: 1.9553 - accuracy: 0.9386 - val_loss: 2.1107 - val_accuracy: 0.9519\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 1.9285 - accuracy: 0.9381 - val_loss: 2.0175 - val_accuracy: 0.9229\n",
      "Epoch 15/30\n",
      "19841/19841 - 4s - loss: 1.8887 - accuracy: 0.9394 - val_loss: 1.7713 - val_accuracy: 0.9465\n",
      "Epoch 16/30\n",
      "19841/19841 - 4s - loss: 1.9289 - accuracy: 0.9395 - val_loss: 1.8241 - val_accuracy: 0.9247\n",
      "Epoch 17/30\n",
      "19841/19841 - 4s - loss: 1.9331 - accuracy: 0.9390 - val_loss: 1.6495 - val_accuracy: 0.9497\n",
      "Epoch 18/30\n",
      "19841/19841 - 4s - loss: 1.9568 - accuracy: 0.9389 - val_loss: 1.4849 - val_accuracy: 0.9510\n",
      "Epoch 19/30\n",
      "19841/19841 - 4s - loss: 1.8684 - accuracy: 0.9393 - val_loss: 1.9004 - val_accuracy: 0.9356\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 1.9391 - accuracy: 0.9403 - val_loss: 1.8116 - val_accuracy: 0.9483\n",
      "Epoch 21/30\n",
      "19841/19841 - 4s - loss: 1.9237 - accuracy: 0.9400 - val_loss: 1.6314 - val_accuracy: 0.9451\n",
      "Epoch 22/30\n",
      "19841/19841 - 4s - loss: 1.8288 - accuracy: 0.9408 - val_loss: 2.1570 - val_accuracy: 0.4934\n",
      "Epoch 23/30\n",
      "19841/19841 - 4s - loss: 1.8674 - accuracy: 0.9421 - val_loss: 1.8877 - val_accuracy: 0.9365\n",
      "Epoch 24/30\n",
      "19841/19841 - 4s - loss: 1.9041 - accuracy: 0.9399 - val_loss: 1.9827 - val_accuracy: 0.9474\n",
      "Epoch 25/30\n",
      "19841/19841 - 4s - loss: 1.8366 - accuracy: 0.9431 - val_loss: 1.7949 - val_accuracy: 0.9320\n",
      "Epoch 26/30\n",
      "19841/19841 - 4s - loss: 1.8513 - accuracy: 0.9426 - val_loss: 1.9505 - val_accuracy: 0.7927\n",
      "Epoch 27/30\n",
      "19841/19841 - 4s - loss: 1.7749 - accuracy: 0.9433 - val_loss: 1.9533 - val_accuracy: 0.9451\n",
      "Epoch 28/30\n",
      "19841/19841 - 4s - loss: 1.8517 - accuracy: 0.9416 - val_loss: 1.9992 - val_accuracy: 0.9315\n",
      "Epoch 29/30\n",
      "19841/19841 - 4s - loss: 1.7976 - accuracy: 0.9436 - val_loss: 2.1983 - val_accuracy: 0.9551\n",
      "Epoch 30/30\n",
      "19841/19841 - 4s - loss: 1.8254 - accuracy: 0.9449 - val_loss: 2.1809 - val_accuracy: 0.9098\n",
      "5512/5512 [==============================] - 1s 102us/sample - loss: 2.1886 - accuracy: 0.8970\n",
      "Test_Accuracy: 89.70%\n",
      "5512/5512 [==============================] - 1s 102us/sample - loss: 2.1886 - accuracy: 0.8970\n",
      "5512/5512 [==============================] - 1s 94us/sample - loss: 2.1886 - accuracy: 0.8970\n",
      "[2.188570158228992, 0.8969521]\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 31, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,357,090\n",
      "Trainable params: 3,355,426\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19841 samples, validate on 2205 samples\n",
      "Epoch 1/30\n",
      "19841/19841 - 6s - loss: 542.3596 - accuracy: 0.7278 - val_loss: 0.9552 - val_accuracy: 0.7805\n",
      "Epoch 2/30\n",
      "19841/19841 - 4s - loss: 0.8587 - accuracy: 0.8424 - val_loss: 1.0351 - val_accuracy: 0.8141\n",
      "Epoch 3/30\n",
      "19841/19841 - 4s - loss: 1.0295 - accuracy: 0.8573 - val_loss: 1.1293 - val_accuracy: 0.7823\n",
      "Epoch 4/30\n",
      "19841/19841 - 4s - loss: 1.2692 - accuracy: 0.8690 - val_loss: 1.3713 - val_accuracy: 0.8308\n",
      "Epoch 5/30\n",
      "19841/19841 - 3s - loss: 1.4981 - accuracy: 0.8857 - val_loss: 1.6120 - val_accuracy: 0.7615\n",
      "Epoch 6/30\n",
      "19841/19841 - 4s - loss: 1.7656 - accuracy: 0.9025 - val_loss: 1.7507 - val_accuracy: 0.7116\n",
      "Epoch 7/30\n",
      "19841/19841 - 4s - loss: 1.9818 - accuracy: 0.9128 - val_loss: 2.2733 - val_accuracy: 0.4898\n",
      "Epoch 8/30\n",
      "19841/19841 - 4s - loss: 2.2355 - accuracy: 0.9187 - val_loss: 2.2915 - val_accuracy: 0.7288\n",
      "Epoch 9/30\n",
      "19841/19841 - 4s - loss: 2.4308 - accuracy: 0.9221 - val_loss: 2.3130 - val_accuracy: 0.8413\n",
      "Epoch 10/30\n",
      "19841/19841 - 4s - loss: 2.5152 - accuracy: 0.9259 - val_loss: 2.7624 - val_accuracy: 0.8617\n",
      "Epoch 11/30\n",
      "19841/19841 - 4s - loss: 2.8958 - accuracy: 0.9264 - val_loss: 2.3971 - val_accuracy: 0.8971\n",
      "Epoch 12/30\n",
      "19841/19841 - 4s - loss: 3.1003 - accuracy: 0.9267 - val_loss: 2.7561 - val_accuracy: 0.8907\n",
      "Epoch 13/30\n",
      "19841/19841 - 4s - loss: 3.4860 - accuracy: 0.9273 - val_loss: 3.2364 - val_accuracy: 0.8971\n",
      "Epoch 14/30\n",
      "19841/19841 - 4s - loss: 3.4648 - accuracy: 0.9283 - val_loss: 3.0872 - val_accuracy: 0.8785\n",
      "Epoch 15/30\n",
      "19841/19841 - 4s - loss: 4.0426 - accuracy: 0.9293 - val_loss: 3.1672 - val_accuracy: 0.9088\n",
      "Epoch 16/30\n",
      "19841/19841 - 3s - loss: 3.9724 - accuracy: 0.9296 - val_loss: 3.1588 - val_accuracy: 0.9283\n",
      "Epoch 17/30\n",
      "19841/19841 - 3s - loss: 4.0692 - accuracy: 0.9295 - val_loss: 3.3472 - val_accuracy: 0.9007\n",
      "Epoch 18/30\n",
      "19841/19841 - 3s - loss: 3.9736 - accuracy: 0.9293 - val_loss: 3.2788 - val_accuracy: 0.9184\n",
      "Epoch 19/30\n",
      "19841/19841 - 3s - loss: 3.9504 - accuracy: 0.9297 - val_loss: 2.9674 - val_accuracy: 0.9252\n",
      "Epoch 20/30\n",
      "19841/19841 - 4s - loss: 3.9292 - accuracy: 0.9294 - val_loss: 3.1392 - val_accuracy: 0.9079\n",
      "Epoch 21/30\n",
      "19841/19841 - 3s - loss: 3.9043 - accuracy: 0.9301 - val_loss: 3.3886 - val_accuracy: 0.8866\n",
      "Epoch 22/30\n",
      "19841/19841 - 3s - loss: 3.8701 - accuracy: 0.9306 - val_loss: 3.7109 - val_accuracy: 0.9156\n",
      "Epoch 23/30\n",
      "19841/19841 - 4s - loss: 3.8834 - accuracy: 0.9330 - val_loss: 3.6522 - val_accuracy: 0.8544\n",
      "Epoch 24/30\n",
      "19841/19841 - 4s - loss: 3.7310 - accuracy: 0.9336 - val_loss: 3.3328 - val_accuracy: 0.9002\n",
      "Epoch 25/30\n",
      "19841/19841 - 4s - loss: 3.7626 - accuracy: 0.9342 - val_loss: 3.0232 - val_accuracy: 0.9152\n",
      "Epoch 26/30\n",
      "19841/19841 - 4s - loss: 3.8133 - accuracy: 0.9338 - val_loss: 3.0126 - val_accuracy: 0.9197\n",
      "Epoch 27/30\n",
      "19841/19841 - 4s - loss: 3.5632 - accuracy: 0.9329 - val_loss: 3.9162 - val_accuracy: 0.8776\n",
      "Epoch 28/30\n",
      "19841/19841 - 4s - loss: 3.5747 - accuracy: 0.9340 - val_loss: 2.8244 - val_accuracy: 0.8045\n",
      "Epoch 29/30\n",
      "19841/19841 - 4s - loss: 3.8848 - accuracy: 0.9353 - val_loss: 3.1093 - val_accuracy: 0.4975\n",
      "Epoch 30/30\n",
      "19841/19841 - 4s - loss: 3.7236 - accuracy: 0.9349 - val_loss: 3.1913 - val_accuracy: 0.9465\n",
      "5512/5512 [==============================] - 1s 97us/sample - loss: 3.1952 - accuracy: 0.9432\n",
      "Test_Accuracy: 94.32%\n",
      "5512/5512 [==============================] - 1s 94us/sample - loss: 3.1952 - accuracy: 0.9432\n",
      "5512/5512 [==============================] - 1s 102us/sample - loss: 3.1952 - accuracy: 0.9432\n",
      "[3.1952175080170653, 0.94321483]\n"
     ]
    }
   ],
   "source": [
    "regulization_list = [0, 0.0000000001, 0.000000001, 0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1,10]\n",
    "# probability axis values \n",
    "prob = []\n",
    "# loss axis values \n",
    "loss = []\n",
    "for i in regulization_list:\n",
    "    classifier = tf.keras.Sequential()\n",
    "    classifier.add(Convolution2D(32, (3, 3), input_shape = (SIZE, SIZE, 3), activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\n",
    "    classifier.add(BatchNormalization(axis = -1))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\n",
    "    classifier.add(BatchNormalization(axis = -1))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense( kernel_regularizer=l2(i),  activation = 'relu', units=512))\n",
    "    classifier.add(BatchNormalization(axis = -1))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(kernel_regularizer=l2(i),  activation = 'relu', units=256))\n",
    "    classifier.add(BatchNormalization(axis = -1))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(Dense(kernel_regularizer=l2(i), activation = 'sigmoid', units=2))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    print(classifier.summary())\n",
    "\n",
    "    history = classifier.fit(np.array(x_train), \n",
    "                         y_train, \n",
    "                         batch_size = 64, \n",
    "                         verbose = 2, \n",
    "                         epochs = 30, \n",
    "                         validation_split = 0.1,\n",
    "                         shuffle = False)\n",
    "\n",
    "    print(\"Test_Accuracy: {:.2f}%\".format(classifier.evaluate(np.array(x_test), np.array(y_test))[1]*100))\n",
    "    loss.append(classifier.evaluate(np.array(x_test), np.array(y_test))[0])\n",
    "    print(classifier.evaluate(np.array(x_test), np.array(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pygL8qKhY7Qh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24569157453476728, 0.29668290945005177, 0.28265402074377777, 0.2860603167419288, 0.22977451944023544, 0.26345260602155773, 0.29117429094234987, 0.35062505458366716, 0.29261166532084626, 0.4516639039028539, 0.9835766942303827, 2.188570158228992, 3.1952175080170653]\n",
      "[0, 1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "print(regulization_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x229ebf82488>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(regulization_list, loss,'o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EE496_Malaria_Deteection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
