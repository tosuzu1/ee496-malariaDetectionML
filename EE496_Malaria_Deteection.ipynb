{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE496_Malaria_Deteection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tosuzu1/ee496-malariaDetectionML/blob/master/EE496_Malaria_Deteection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVi1d71PgYYW",
        "colab_type": "text"
      },
      "source": [
        "This is the KERAS CNN implementation for the MALARIA CELL IMAGES DATASET\n",
        "\n",
        "Breakdown of this notebook:\n",
        "\n",
        "Loading the dataset: Load the data and import the libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtfOemEYgPwh",
        "colab_type": "code",
        "outputId": "83392fec-23c6-47a5-c14c-516368524e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "# For CNN model creation\n",
        "import keras\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "SIZE = 64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvL_rdVEgj5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This section is to import files from kaggle into collab\n",
        "from google.colab import files\n",
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload kaggle API key file\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxHah_83jLly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFwnrAX0iorA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downlaod data for the nyc_taxi_trip_duration challenge\n",
        "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhfxR_OWkbws",
        "colab_type": "code",
        "outputId": "566480be-b13f-4b7e-cd45-f73611e12733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with ZipFile('cell-images-for-detecting-malaria.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cell_images  cell-images-for-detecting-malaria.zip  kaggle.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRgyHuQhk893",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infected = os.listdir('./cell_images/cell_images/Parasitized/') \n",
        "uninfected = os.listdir('./cell_images/cell_images/Uninfected/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-t95fumlkiG",
        "colab_type": "code",
        "outputId": "f9ea2b8a-eee2-4ca5-dce1-83668f36eb66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for i in infected:\n",
        "    try:\n",
        "    \n",
        "        image = cv2.imread(\"./cell_images/cell_images/Parasitized/\"+i)\n",
        "        image_array = Image.fromarray(image , 'RGB')\n",
        "        resize_img = image_array.resize((64 , 64))\n",
        "        data.append(np.array(resize_img))\n",
        "        label = to_categorical(1, num_classes=2)\n",
        "        labels.append(label)\n",
        "        \n",
        "    except AttributeError:\n",
        "        print('')\n",
        "    \n",
        "for u in uninfected:\n",
        "    try:\n",
        "        \n",
        "        image = cv2.imread(\"./cell_images/cell_images/Uninfected/\"+u)\n",
        "        image_array = Image.fromarray(image , 'RGB')\n",
        "        resize_img = image_array.resize((64 , 64))\n",
        "        data.append(np.array(resize_img))\n",
        "        label = to_categorical(0, num_classes=2)\n",
        "        labels.append(label)\n",
        "        \n",
        "    except AttributeError:\n",
        "        print('')\n",
        "\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSB6IS52HFcg",
        "colab_type": "code",
        "outputId": "671fa62b-31f5-48cf-d1ca-4246d13b8b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-oXJVMrhrea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regulization_list = [0, 0.0000000001, 0.000000001, 0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
        "# probability axis values \n",
        "prob = []\n",
        "# loss axis values \n",
        "loss = []\n",
        "for i in regulization_list:\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Convolution2D(32, (3, 3), kernal_regularizer=l1(i), bias_regularizer=l1(i), input_shape = (SIZE, SIZE, 3), activation = 'relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\n",
        "  classifier.add(BatchNormalization(axis = -1))\n",
        "  classifier.add(Dropout(0.2))\n",
        "  classifier.add(Convolution2D(32, (3, 3), kernal_regularizer=l1(i), bias_regularizer=l1(i), activation = 'relu'))\n",
        "  classifier.add(MaxPooling2D(pool_size = (2, 2), data_format=\"channels_last\"))\n",
        "  classifier.add(BatchNormalization(axis = -1))\n",
        "  classifier.add(Dropout(0.2))\n",
        "  classifier.add(Flatten())\n",
        "  classifier.add(Dense(kernal_regularizer=l1(i), bias_regularizer=l1(i), activation = 'relu', units=512))\n",
        "  classifier.add(BatchNormalization(axis = -1))\n",
        "  classifier.add(Dropout(0.2))\n",
        "  classifier.add(Dense(kernal_regularizer=l2(i), bias_regularizer=l2(i), activation = 'relu', units=256))\n",
        "  classifier.add(BatchNormalization(axis = -1))\n",
        "  classifier.add(Dropout(0.2))\n",
        "  classifier.add(Dense(kernal_regularizer=l1_l2(i), bias_regularizer=l1_l2(i), activation = 'sigmoid', units=2))\n",
        "  classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  print(classifier.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXEHl8GQhXDJ",
        "colab_type": "code",
        "outputId": "0f1f5312-4c06-42a6-baf9-5b52d9c6bf79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "  x_train, x_test = train_test_split(data, test_size=0.2, random_state=1,shuffle = True)\n",
        "  y_train, y_test = train_test_split(labels, test_size=0.2, random_state=1)\n",
        "  print(np.array(x_train).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22046, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBiAcex4hRxm",
        "colab_type": "code",
        "outputId": "6c519b3f-f119-4e0d-e85c-c68346ac3952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "  history = classifier.fit(np.array(x_train), \n",
        "                         y_train, \n",
        "                         batch_size = 64, \n",
        "                         verbose = 2, \n",
        "                         epochs = 30, \n",
        "                         validation_split = 0.1,\n",
        "                         shuffle = False)\n",
        "                         \n",
        "  print(\"Test_Accuracy: {:.2f}%\".format(classifier.evaluate(np.array(x_test), np.array(y_test))[1]*100))\n",
        "  loss.append(classifier.evaluate(np.array(x_test), np.array(y_test))[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 19841 samples, validate on 2205 samples\n",
            "Epoch 1/50\n",
            " - 113s - loss: 0.0117 - acc: 0.9952 - val_loss: 0.2172 - val_acc: 0.9596\n",
            "Epoch 2/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pygL8qKhY7Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "  \n",
        "ax1.plot(loss, prob)    \n",
        "ax1.xlabel('Regret') \n",
        "ax1.ylabel('Probability')    \n",
        "ax1.title('Probability vs. Regret')   \n",
        "ax1.show()\n",
        "\n",
        "ax2.plot(regulization_list, loss)    \n",
        "ax2.xlabel('Lamda') \n",
        "ax2.ylabel('Regret')    \n",
        "ax2.title('Regret vs. Lamda')   \n",
        "ax2.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}